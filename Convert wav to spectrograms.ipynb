{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Convert wav to spectrograms.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMSJPa4J6XgnB87066caJNT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CxyOCSbJBOHg"},"source":["# Convert .wav to spectrograms"]},{"cell_type":"markdown","metadata":{"id":"TyJ5jn-SBq8r"},"source":["Based on https://medium.com/analytics-vidhya/how-to-classify-sounds-using-pytorch-27c9f2d4d714\n"]},{"cell_type":"markdown","metadata":{"id":"hBc6RnAWCzIg"},"source":["# Final code"]},{"cell_type":"markdown","metadata":{"id":"HIXFG6WPd50n"},"source":["Credits: # https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/audio_preprocessing_tutorial.ipynb#scrollTo=RIl-u3baEABA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3TjcI2OhDln5","executionInfo":{"status":"ok","timestamp":1616878739621,"user_tz":240,"elapsed":131506,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"f23e0149-d346-4656-f188-d6427c553320"},"source":["!pip3 install torchaudio\n","!pip install torch"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torchaudio\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 5.5MB/s \n","\u001b[?25hCollecting torch==1.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/74/6fc9dee50f7c93d6b7d9644554bdc9692f3023fa5d1de779666e6bf8ae76/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1MB)\n","\u001b[K     |████████████████████████████████| 804.1MB 22kB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n","\u001b[31mERROR: torchvision 0.9.0+cu101 has requirement torch==1.8.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.9.0 has requirement torch==1.8.0, but you'll have torch 1.8.1 which is incompatible.\u001b[0m\n","Installing collected packages: torch, torchaudio\n","  Found existing installation: torch 1.8.0+cu101\n","    Uninstalling torch-1.8.0+cu101:\n","      Successfully uninstalled torch-1.8.0+cu101\n","Successfully installed torch-1.8.1 torchaudio-0.8.1\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VdFuLt2gF5yo","executionInfo":{"status":"ok","timestamp":1616878857629,"user_tz":240,"elapsed":37992,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"41fc7445-9100-4311-a6b0-313fe4531ab8"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4JmOiQDcDg6W","executionInfo":{"status":"ok","timestamp":1616878860035,"user_tz":240,"elapsed":861,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["import torch\n","import torchaudio\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JTYY9zmhHsQ-"},"source":["Code from # https://pytorch.org/tutorials/beginner/audio_preprocessing_tutorial.html\n"]},{"cell_type":"code","metadata":{"id":"LILJCb5fE-Qr","executionInfo":{"status":"ok","timestamp":1616878860877,"user_tz":240,"elapsed":287,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["def plot_waveform(waveform, sample_rate, path, filename, xlim=None, ylim=None):\n","  title = \"Waveform: {}\".format(filename)\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].plot(time_axis, waveform[c], linewidth=1)\n","    axes[c].grid(True)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","    if ylim:\n","      axes[c].set_ylim(ylim)\n","  figure.suptitle(title)\n","\n","  fig1 = plt.gcf()\n","  plt.show(block=False)\n","  fig1.savefig(f'{path}/{filename}_waveform.png')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"z6GE3tWHHNow","executionInfo":{"status":"ok","timestamp":1616878864409,"user_tz":240,"elapsed":265,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["def plot_specgram(waveform, sample_rate, path, filename, xlim=None):\n","  title = \"Spectrogram: {}\".format(filename)\n","  waveform = waveform.numpy()\n","\n","  num_channels, num_frames = waveform.shape\n","  time_axis = torch.arange(0, num_frames) / sample_rate\n","\n","  figure, axes = plt.subplots(num_channels, 1)\n","  if num_channels == 1:\n","    axes = [axes]\n","  for c in range(num_channels):\n","    axes[c].specgram(waveform[c], Fs=sample_rate)\n","    if num_channels > 1:\n","      axes[c].set_ylabel(f'Channel {c+1}')\n","    if xlim:\n","      axes[c].set_xlim(xlim)\n","  figure.suptitle(title)\n","\n","  fig1 = plt.gcf()\n","  plt.show(block=False)\n","  fig1.savefig(f'{path}/{filename}_specgram.png')\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"AGIrCWspFlZv","executionInfo":{"status":"ok","timestamp":1616878866029,"user_tz":240,"elapsed":240,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["def process_recording(base_path, wav_filename, plot_waveform=False):\n","  wav_path = f'{base_path}/{wav_filename}'\n","  waveform, sample_rate = torchaudio.load(wav_path)\n","\n","  filename = wav_filename.replace(\".wav\", \"\")\n","  if plot_waveform:\n","    plot_waveform(waveform=waveform, sample_rate=sample_rate, path=base_path, filename=filename)\n","  plot_specgram(waveform=waveform, sample_rate=sample_rate, path=base_path, filename=filename)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"mXuziLNREHoI","executionInfo":{"status":"ok","timestamp":1616878922984,"user_tz":240,"elapsed":246,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["def process_recordings_folder(folder_name):\n","  with os.scandir(folder_name) as entries:\n","    for entry in entries:\n","      if entry.is_file():\n","        filename = entry.name\n","        if filename.endswith('.wav'):\n","          print(f\"processing: {filename}\")\n","          \n","          process_recording(base_path=folder_name, wav_filename=filename)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"hJi7CmaXf8Yw","executionInfo":{"status":"ok","timestamp":1616879108443,"user_tz":240,"elapsed":230,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["base_path = '/content/gdrive/MyDrive/CMU/11785_Intro_to_Deep_Learning/DL_Group_Project/Dataset/'\n","folders = [\n","           'Marta_Recordings',\n","           'Mansi_Recordings/Complex',\n","           'Mansi_Recordings/Steady_State',\n","           'Sreedhar_Recordings',\n","           'Sreenidhi_Recordings'\n","]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1CwEddziKbUeWeMPSFdxFZMODxANgkZja"},"id":"3OQ60IQOGUrR","executionInfo":{"status":"ok","timestamp":1616879201689,"user_tz":240,"elapsed":92476,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"f22f786b-6af2-41a3-f8fb-1063bd2ade30"},"source":["for folder in folders:\n","  process_recordings_folder(f\"{base_path}/{folder}\")"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"S4BPJd74ePxH"},"source":["# Other Resources"]},{"cell_type":"markdown","metadata":{"id":"m8ty0u0TePrp"},"source":["Some other resources checked to generate the plots"]},{"cell_type":"markdown","metadata":{"id":"zIrNv671Bywj"},"source":["**1. First we will load the audio file.** From the directory having n number of sounds files, we will try to load 2–3 out of them using torchaudio.load first. torchaudio supports sound files of format ‘.wav’ and ‘.mp3’ which is used to give waveform and sample rate of the sound file. Waveform consists of frequencies of the sound per frame in an array format whereas the sample rate determines the frequency at which the waveform can be represented"]},{"cell_type":"code","metadata":{"id":"PIudnVxHBqeR"},"source":["import torchaudio\n","waveform, sample_rate = torchaudio.load(\"_PATH OF THE AUDIO FILE_\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"u1nsO3eTB8n5"},"source":["**2. Normalize all the shape of waveforms to one size.** After loading the file, check the shape of the waveform using waveform.size()[0] . If it’s value is more than 1 , then we will have to normalize it using"]},{"cell_type":"code","metadata":{"id":"YtHspSpkBNbi"},"source":["from pydub import AudioSegment\n","waveform = AudioSegment.from_mp3(_PATH OF THE AUDIO FILE_)\n","waveform = waveform.set_channels(1)\n","waveform = waveform.get_array_of_samples()\n","waveform = torch.tensor(waveform, dtype = torch.float)\n","waveform = torch.reshape(waveform, (1,waveform.shape[0])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TjLMsE2mCCqI"},"source":["**3. Change the waveform to Spectrogram, Mel Spectrogram or, MFCC.** Now we will change waveform into Spectrogram(a visual representation of the spectrum of frequencies of a signal as it varies with time) using"]},{"cell_type":"code","metadata":{"id":"lKhnpSO4CGeV"},"source":["Spectrogram = torchaudio.transforms.Spectrogram()(waveform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9NKZ84mJCJP9"},"source":["or, mel spectrogram(a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency) using"]},{"cell_type":"code","metadata":{"id":"gYuXgNyECLsY"},"source":["Mel_Spectrogram = torchaudio.transforms.MelSpectrogram()(waveform)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_YBMLGVJCOe2"},"source":["or, MFCC(Mel-frequency cepstral coefficients (MFCCs) are coefficients that collectively make up an mel-frequency cepstrum. Mel-frequency cepstrum is a representation of the short-term power spectrum of a sound, based on a linear cosine transform of a log power spectrum on a nonlinear mel scale of frequency) using"]},{"cell_type":"code","metadata":{"id":"dSP5e7riCRwJ"},"source":["n_fft = 400.0\n","frame_length = n_fft / sample_rate * 1000.0\n","frame_shift = frame_length / 2.0\n","\n","params = {\n","    \"channel\": 0,\n","    \"dither\": 0.0,\n","    \"window_type\": \"hanning\",\n","    \"frame_length\": frame_length,\n","    \"frame_shift\": frame_shift,\n","    \"remove_dc_offset\": False,\n","    \"round_to_power_of_two\": False,\n","    \"sample_frequency\": sample_rate,\n","}\n","mfcc = torchaudio.compliance.kaldi.mfcc(waveform, **params)"],"execution_count":null,"outputs":[]}]}