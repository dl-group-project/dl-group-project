{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Front-end: per sound detector and final classifier.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMW9in3ZNlJ5lyzkJq6+Zlh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"pQ0m9yaDqUnF"},"source":["# Front-end: per sound detector and final classifier"]},{"cell_type":"markdown","metadata":{"id":"OGkn63w8y0ah"},"source":["Make the code flexible so it can be trained on more recordings/sounds/classes"]},{"cell_type":"markdown","metadata":{"id":"W_kHjiaAqb9s"},"source":["## 1. Generating dataset (per recording)"]},{"cell_type":"code","metadata":{"id":"sqZgT1CsqUJh"},"source":["# 1. generate melspectrograms (40 features per 10ms frame) -> save as .npy"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsIjD77mqpcD"},"source":["# 2. generate the labels (silence vs sound) per 10ms frame using google VAD -> save as .npy"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmgukhuSqx7q"},"source":["## 2. Training shallow detectors (per phoneme + one for silence)"]},{"cell_type":"code","metadata":{"id":"kfuL_8QGq1YH"},"source":["# 1. per phoneme (+ one model for silence), build a shallow detector"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CDSPTFwWydOt"},"source":["# 2. we load all the recording .npy files, and we only set the label=1 for that \n","# particular phoneme, all the other phonemes (and silence) will get the label=0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cjufuS7xrDHJ"},"source":["# 3. train a shallow network (2 layers: 1 hidden + 1 output) that classifies the dataset"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"I9GqVO8UrMoo"},"source":["# 4. save models"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lL7OCrVerPeA"},"source":["## 3. Train final classifier (output classes: different phonemes + silence)"]},{"cell_type":"code","metadata":{"id":"RgQs7LLcrSNR"},"source":["# 1. load dataset (all the .npy files for all recordings)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lq-2cov2rZ_g"},"source":["# 2. train a classifier network that combines the X detectors (initialize with \n","# the weights from point 2) + hidden layer + output (softmax layer)"],"execution_count":null,"outputs":[]}]}