{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AutoEncoder_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBlc7nMCmsgI"
      },
      "source": [
        "Reference: geeksforgeeks.org/ml-classifying-data-using-an-auto-encoder/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFJAYFGDIrCt"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.manifold import TSNE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model, Sequential\n",
        "from keras import regularizers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOcRCtElmer9"
      },
      "source": [
        "# Load data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBIxXUq_myJY"
      },
      "source": [
        "def tsne_plot(x, y):\n",
        "      \n",
        "    # Setting the plotting background\n",
        "    sns.set(style =\"whitegrid\")\n",
        "      \n",
        "    tsne = TSNE(n_components = 2, random_state = 0)\n",
        "      \n",
        "    # Reducing the dimensionality of the data\n",
        "    X_transformed = tsne.fit_transform(x)\n",
        "  \n",
        "    plt.figure(figsize =(12, 8))\n",
        "      \n",
        "    # Building the scatter plot\n",
        "    plt.scatter(X_transformed[np.where(y == 0), 0], \n",
        "                X_transformed[np.where(y == 0), 1],\n",
        "                marker ='o', color ='y', linewidth ='1',\n",
        "                alpha = 0.8, label ='Normal')\n",
        "    plt.scatter(X_transformed[np.where(y == 1), 0],\n",
        "                X_transformed[np.where(y == 1), 1],\n",
        "                marker ='o', color ='k', linewidth ='1',\n",
        "                alpha = 0.8, label ='Fraud')\n",
        "  \n",
        "    # Specifying the location of the legend\n",
        "    plt.legend(loc ='best')\n",
        "      \n",
        "    # Plotting the reduced data\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMhrlDR-m23u"
      },
      "source": [
        "# Building the Input Layer\n",
        "input_layer = Input(shape =(X.shape[1], ))\n",
        "  \n",
        "# Building the Encoder network\n",
        "encoded = Dense(100, activation ='tanh',\n",
        "                activity_regularizer = regularizers.l1(10e-5))(input_layer)\n",
        "encoded = Dense(50, activation ='tanh',\n",
        "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
        "encoded = Dense(25, activation ='tanh',\n",
        "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
        "encoded = Dense(12, activation ='tanh',\n",
        "                activity_regularizer = regularizers.l1(10e-5))(encoded)\n",
        "encoded = Dense(6, activation ='relu')(encoded)\n",
        "  \n",
        "# Building the Decoder network\n",
        "decoded = Dense(12, activation ='tanh')(encoded)\n",
        "decoded = Dense(25, activation ='tanh')(decoded)\n",
        "decoded = Dense(50, activation ='tanh')(decoded)\n",
        "decoded = Dense(100, activation ='tanh')(decoded)\n",
        "  \n",
        "# Building the Output Layer\n",
        "output_layer = Dense(X.shape[1], activation ='relu')(decoded)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_8gE0shm7OH"
      },
      "source": [
        "# Defining the parameters of the Auto-encoder network\n",
        "autoencoder = Model(input_layer, output_layer)\n",
        "autoencoder.compile(optimizer =\"adadelta\", loss =\"mse\")\n",
        "  \n",
        "# Training the Auto-encoder network\n",
        "autoencoder.fit(X_normal_scaled, X_normal_scaled, \n",
        "                batch_size = 16, epochs = 10, \n",
        "                shuffle = True, validation_split = 0.20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2e1-mF8Pm9qh"
      },
      "source": [
        "hidden_representation = Sequential()\n",
        "hidden_representation.add(autoencoder.layers[0])\n",
        "hidden_representation.add(autoencoder.layers[1])\n",
        "hidden_representation.add(autoencoder.layers[2])\n",
        "hidden_representation.add(autoencoder.layers[3])\n",
        "hidden_representation.add(autoencoder.layers[4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3XWIPX2nCnK"
      },
      "source": [
        "# Separating the points encoded by the Auto-encoder as normal and fraud\n",
        "normal_hidden_rep = hidden_representation.predict(X_normal_scaled)\n",
        "fraud_hidden_rep = hidden_representation.predict(X_fraud_scaled)\n",
        "  \n",
        "# Combining the encoded points into a single table \n",
        "encoded_X = np.append(normal_hidden_rep, fraud_hidden_rep, axis = 0)\n",
        "y_normal = np.zeros(normal_hidden_rep.shape[0])\n",
        "y_fraud = np.ones(fraud_hidden_rep.shape[0])\n",
        "encoded_y = np.append(y_normal, y_fraud)\n",
        "  \n",
        "# Plotting the encoded points\n",
        "tsne_plot(encoded_X, encoded_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtsXue8cnGsf"
      },
      "source": [
        "# Splitting the encoded data for linear classification\n",
        "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(encoded_X, encoded_y, test_size = 0.2)\n",
        "  \n",
        "# Splitting the original data for non-linear classification\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwAN3KZsnKJp"
      },
      "source": [
        "Try Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYqhtRjdnMYz"
      },
      "source": [
        "Try SVM"
      ]
    }
  ]
}