{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autoencoder_Pytorch.ipynb","provenance":[],"authorship_tag":"ABX9TyP5+lI6a6QOtmIQHMmbqLsH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YY7VphWScKX8"},"source":["# Autoencoder"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T-TLHia4kB5c","executionInfo":{"status":"ok","timestamp":1618340346897,"user_tz":240,"elapsed":325,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"3e266ce0-f89f-4ad3-ccc3-4b03ee860492"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FtwMvQ_NkCUZ","executionInfo":{"status":"ok","timestamp":1618339841469,"user_tz":240,"elapsed":369,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["drivepath = '/content/gdrive/MyDrive/Spring_2021/11785_Intro_to_Deep_Learning/DL_Group_Project/Dataset/Hw1p2_frames'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"CfR5If-XkGEW","executionInfo":{"status":"ok","timestamp":1618340353067,"user_tz":240,"elapsed":338,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["phoneme = \"SIL\""],"execution_count":36,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hMFlJc1mcOYf"},"source":["Reference: https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1\n"]},{"cell_type":"code","metadata":{"id":"8N9ghkTucOMc"},"source":["!pip install torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9pF6KgBe65u","executionInfo":{"status":"ok","timestamp":1618339892190,"user_tz":240,"elapsed":703,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"s1LSbxifcJv5","executionInfo":{"status":"ok","timestamp":1618339892854,"user_tz":240,"elapsed":206,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["class AE(nn.Module):\n","    def __init__(self, in_features):\n","        super().__init__()\n","        self.encoder_hidden_layer = nn.Linear(\n","            in_features=in_features, out_features=128\n","        )\n","        self.encoder_output_layer = nn.Linear(\n","            in_features=128, out_features=128\n","        )\n","        self.decoder_hidden_layer = nn.Linear(\n","            in_features=128, out_features=128\n","        )\n","        self.decoder_output_layer = nn.Linear(\n","            in_features=128, out_features=in_features\n","        )\n","\n","    def forward(self, features):\n","        activation = self.encoder_hidden_layer(features)\n","        activation = torch.relu(activation)\n","\n","        code = self.encoder_output_layer(activation)\n","        code = torch.relu(code)\n","\n","        activation = self.decoder_hidden_layer(code)\n","        activation = torch.relu(activation)\n","\n","        activation = self.decoder_output_layer(activation)\n","        reconstructed = torch.relu(activation)\n","        \n","        return reconstructed"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wdMIHrpucXuQ"},"source":["Explaining some of the components in the code snippet above,\n","\n","*   The torch.nn.Linear layer creates a linear function (Î¸x + b), with its parameters initialized (by default) with He/Kaiming uniform initialization, as it can be confirmed here. This means we will call an activation/non-linearity for such layers.\n","*   The in_features parameter dictates the feature size of the input tensor to a particular layer, e.g. in self.encoder_hidden_layer, it accepts an input tensor with the size of [N, input_shape] where N is the number of examples, and input_shape is the number of features in one example.\n","*   The out_features parameter dictates the feature size of the output tensor of a particular layer. Hence, in the self.decoder_output_layer, the feature size is kwargs[\"input_shape\"], denoting that it reconstructs the original data input.\n","*   The forward() function defines the forward pass for a model, similar to call in tf.keras.Model. This is the function invoked when we pass input tensors to an instantiated object of a torch.nn.Module class.\n","\n"]},{"cell_type":"code","metadata":{"id":"hpXIoW-5chqV","executionInfo":{"status":"ok","timestamp":1618339923128,"user_tz":240,"elapsed":219,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["#  use gpu if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# create a model from `AE` autoencoder class\n","# load it to the specified device, either gpu or cpu\n","model = AE(in_features=40).to(device)\n","\n","# create an optimizer object\n","# Adam optimizer with learning rate 1e-3\n","optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n","\n","# mean-squared error loss\n","criterion = nn.MSELoss()"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"nw7ebhocjsuU","executionInfo":{"status":"ok","timestamp":1618339926489,"user_tz":240,"elapsed":572,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["class PhonemeDataset(Dataset):\n","    def __init__(self, x_path):\n","        # shapes of x in x_path: (timestep, 40)\n","        self.X = np.load(x_path, allow_pickle=True)\n","\n","    # number of rows in the dataset\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # get a row at an index\n","    def __getitem__(self, index):\n","        x = torch.Tensor(self.X[index])\n","    \n","        return x"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfUpWU01cnhJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1618340359029,"user_tz":240,"elapsed":2324,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"e78b4c1b-e31e-4aae-d447-a0c8d6012646"},"source":["train_dataset = PhonemeDataset(f\"{drivepath}/{phoneme}.npy\")  # TODO: rename to train_{phoneme}.npy\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True\n",")"],"execution_count":37,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"tVX7YUBnkbcI"},"source":["test_dataset = PhonemeDataset(f\"{drivepath}/test_{phoneme}.npy\")\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=32, shuffle=False, num_workers=4\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nSYrezbgk8Xn","executionInfo":{"status":"ok","timestamp":1618340360932,"user_tz":240,"elapsed":864,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"d1fa451d-3b78-4f7a-bd7d-cadfef6330ab"},"source":["epochs = 50\n","print(len(train_loader))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["264389\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WkS4tIbMcrsc","colab":{"base_uri":"https://localhost:8080/"},"outputId":"b104e491-3caf-4ed8-9f60-ec0b665e16dc"},"source":["for epoch in range(epochs):\n","    loss = 0\n","    for batch_features in train_loader:\n","        # load it to the active device\n","        batch_features = batch_features.view(-1, 40).to(device)\n","        \n","        # reset the gradients back to zero\n","        # PyTorch accumulates gradients on subsequent backward passes\n","        optimizer.zero_grad()\n","        \n","        # compute reconstructions\n","        outputs = model(batch_features)\n","        \n","        # compute training reconstruction loss\n","        train_loss = criterion(outputs, batch_features)\n","        \n","        # compute accumulated gradients\n","        train_loss.backward()\n","        \n","        # perform parameter update based on current gradients\n","        optimizer.step()\n","        \n","        # add the mini-batch training loss to epoch loss\n","        loss += train_loss.item()\n","    \n","    # compute the epoch training loss\n","    loss = loss / len(train_loader)\n","    \n","    # display the epoch training loss\n","    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"stream","text":["epoch : 1/50, loss = 88.116689\n","epoch : 2/50, loss = 88.102177\n","epoch : 3/50, loss = 88.100266\n","epoch : 4/50, loss = 88.099162\n","epoch : 5/50, loss = 88.098444\n"],"name":"stdout"}]}]}