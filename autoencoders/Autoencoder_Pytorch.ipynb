{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Autoencoder_Pytorch.ipynb","provenance":[],"authorship_tag":"ABX9TyPLOY7KdYBcFiL36rO3unvc"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"YY7VphWScKX8"},"source":["# Autoencoder"]},{"cell_type":"markdown","metadata":{"id":"hMFlJc1mcOYf"},"source":["Reference: https://medium.com/pytorch/implementing-an-autoencoder-in-pytorch-19baa22647d1\n"]},{"cell_type":"code","metadata":{"id":"8N9ghkTucOMc"},"source":["!pip install torch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u9pF6KgBe65u"},"source":["import torch"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wdMIHrpucXuQ"},"source":["Explaining some of the components in the code snippet above,\n","\n","*   The torch.nn.Linear layer creates a linear function (Î¸x + b), with its parameters initialized (by default) with He/Kaiming uniform initialization, as it can be confirmed here. This means we will call an activation/non-linearity for such layers.\n","*   The in_features parameter dictates the feature size of the input tensor to a particular layer, e.g. in self.encoder_hidden_layer, it accepts an input tensor with the size of [N, input_shape] where N is the number of examples, and input_shape is the number of features in one example.\n","*   The out_features parameter dictates the feature size of the output tensor of a particular layer. Hence, in the self.decoder_output_layer, the feature size is kwargs[\"input_shape\"], denoting that it reconstructs the original data input.\n","*   The forward() function defines the forward pass for a model, similar to call in tf.keras.Model. This is the function invoked when we pass input tensors to an instantiated object of a torch.nn.Module class.\n","\n"]},{"cell_type":"code","metadata":{"id":"s1LSbxifcJv5"},"source":["class AE(nn.Module):\n","    def __init__(self, **kwargs):\n","        super().__init__()\n","        self.encoder_hidden_layer = nn.Linear(\n","            in_features=kwargs[\"input_shape\"], out_features=128\n","        )\n","        self.encoder_output_layer = nn.Linear(\n","            in_features=128, out_features=128\n","        )\n","        self.decoder_hidden_layer = nn.Linear(\n","            in_features=128, out_features=128\n","        )\n","        self.decoder_output_layer = nn.Linear(\n","            in_features=128, out_features=kwargs[\"input_shape\"]\n","        )\n","\n","    def forward(self, features):\n","        activation = self.encoder_hidden_layer(features)\n","        activation = torch.relu(activation)\n","\n","        code = self.encoder_output_layer(activation)\n","        code = torch.relu(code)\n","\n","        activation = self.decoder_hidden_layer(code)\n","        activation = torch.relu(activation)\n","\n","        activation = self.decoder_output_layer(activation)\n","        reconstructed = torch.relu(activation)\n","        \n","        return reconstructed"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hpXIoW-5chqV"},"source":["#  use gpu if available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# create a model from `AE` autoencoder class\n","# load it to the specified device, either gpu or cpu\n","model = AE(input_shape=784).to(device)\n","\n","# create an optimizer object\n","# Adam optimizer with learning rate 1e-3\n","optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","\n","# mean-squared error loss\n","criterion = nn.MSELoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfUpWU01cnhJ"},"source":["# TODO: replace this with our speech data\n","transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n","\n","train_dataset = torchvision.datasets.MNIST(\n","    root=\"~/torch_datasets\", train=True, transform=transform, download=True\n",")\n","\n","test_dataset = torchvision.datasets.MNIST(\n","    root=\"~/torch_datasets\", train=False, transform=transform, download=True\n",")\n","\n","train_loader = torch.utils.data.DataLoader(\n","    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\n",")\n","\n","test_loader = torch.utils.data.DataLoader(\n","    test_dataset, batch_size=32, shuffle=False, num_workers=4\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WkS4tIbMcrsc"},"source":["for epoch in range(epochs):\n","    loss = 0\n","    for batch_features, _ in train_loader:\n","        # reshape mini-batch data to [N, 784] matrix\n","        # load it to the active device\n","        batch_features = batch_features.view(-1, 784).to(device)\n","        \n","        # reset the gradients back to zero\n","        # PyTorch accumulates gradients on subsequent backward passes\n","        optimizer.zero_grad()\n","        \n","        # compute reconstructions\n","        outputs = model(batch_features)\n","        \n","        # compute training reconstruction loss\n","        train_loss = criterion(outputs, batch_features)\n","        \n","        # compute accumulated gradients\n","        train_loss.backward()\n","        \n","        # perform parameter update based on current gradients\n","        optimizer.step()\n","        \n","        # add the mini-batch training loss to epoch loss\n","        loss += train_loss.item()\n","    \n","    # compute the epoch training loss\n","    loss = loss / len(train_loader)\n","    \n","    # display the epoch training loss\n","    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"],"execution_count":null,"outputs":[]}]}