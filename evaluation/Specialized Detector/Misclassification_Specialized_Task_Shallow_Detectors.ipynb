{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Updated Specialized Task Shallow Detectors.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0m9yaDqUnF"
      },
      "source": [
        "# Specialized Task Shallow Detectors\n",
        "\n",
        "*   Using latest email from Baker\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7elo3dEOZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5169202-5638-4fc6-b32e-e97483b5a13f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQF8XwhESvy"
      },
      "source": [
        "drivepath = '/content/gdrive/MyDrive/DL_Group_Project'\n",
        "datapath = '/content/gdrive/MyDrive/preprocessed_data/preprocessed_data'\n",
        "output_path = f'{drivepath}/experiments/specialized_detectors/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0sSLZGvAcnu"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPNjU3GMS7A"
      },
      "source": [
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_SIZE = 128\n",
        "MODEL_VERSION = 1\n",
        "LEARNING_RATE = 0.01\n",
        "LOGISTIC_THRESHOLD = 0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlpeV6MJHvzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376b7b51-10f9-4945-b031-e94176661e79"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 8 if cuda else 0\n",
        "DEVICE = \"cuda\" if cuda else \"cpu\"\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyjik86CAAE9"
      },
      "source": [
        "DEBUG = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYfqte6xK-6"
      },
      "source": [
        "class SpecializedDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, datapath, mode, task_name, phonemes_class_0, phonemes_class_1):\n",
        "      \"\"\"\n",
        "      phonemes_class_0: list of phoneme names for class 0\n",
        "      phonemes_class_1: list of phoneme names for class 1\n",
        "      \"\"\"\n",
        "      complete_features = np.zeros((1, 40))  # eliminate this row\n",
        "      complete_labels = np.zeros((1))  # eliminate this row\n",
        "\n",
        "      # go through all files in datapath, check phoneme if class=0 or class=1\n",
        "      # assign that label and discard silence frames\n",
        "      class_0_phonemes_found = []\n",
        "      class_1_phonemes_found = []\n",
        "      with os.scandir(datapath) as entries:\n",
        "        for entry in entries:\n",
        "          if entry.is_file():\n",
        "            if \"features\" in entry.name and mode in entry.name:\n",
        "              phoneme_tag = entry.name.split(\"_\")[0]\n",
        "\n",
        "              # find phoneme in class_0 or class_1 list and assign label\n",
        "              phoneme_class = None\n",
        "              if phoneme_tag in phonemes_class_0:\n",
        "                phoneme_class = 0\n",
        "                class_0_phonemes_found.append(phoneme_tag)\n",
        "              if phoneme_tag in phonemes_class_1:\n",
        "                phoneme_class = 1\n",
        "                class_1_phonemes_found.append(phoneme_tag)\n",
        "\n",
        "              if phoneme_class is None:\n",
        "                print(f\"phoneme '{phoneme_tag}' not found on class 0 nor class 1 lists; skip\") if DEBUG else None\n",
        "                continue\n",
        "\n",
        "              print(f\"phoneme '{phoneme_tag}' is class: {phoneme_class}\") if DEBUG else None\n",
        "\n",
        "              features_filepath = entry.path\n",
        "              labels_filepath = f\"{datapath}/{phoneme_tag}_{mode}_labels.npy\"\n",
        "\n",
        "              phoneme_features = np.load(features_filepath, allow_pickle=True)\n",
        "              phoneme_labels = np.load(labels_filepath, allow_pickle=True)\n",
        "              print(f\"{phoneme_tag} total features: {phoneme_features.shape}\") if DEBUG else None\n",
        "              print(f\"{phoneme_tag} total labels: {phoneme_labels.shape}\") if DEBUG else None\n",
        "\n",
        "              # find frames where label != 0 (non-silence)\n",
        "              non_zero_indexes = phoneme_labels.nonzero()\n",
        "              phoneme_features = phoneme_features[non_zero_indexes]\n",
        "              phoneme_labels = phoneme_labels[non_zero_indexes]\n",
        "              print(f\"{phoneme_tag} no-silence features: {phoneme_features.shape}\") if DEBUG else None\n",
        "              print(f\"{phoneme_tag} no-silence labels: {phoneme_labels.shape}\") if DEBUG else None\n",
        "\n",
        "              phoneme_labels[:] = phoneme_class  # label=class\n",
        "\n",
        "              # stack to phoneme features\n",
        "              complete_features = np.concatenate((complete_features, phoneme_features))\n",
        "              complete_labels = np.concatenate((complete_labels, phoneme_labels))\n",
        "      \n",
        "      self.X = complete_features[1:]\n",
        "      self.Y = complete_labels[1:]\n",
        "      print(f\"[task={task_name}] {self.X.shape} features\")\n",
        "      print(f\"[task={task_name}] {self.Y.shape} labels\")\n",
        "\n",
        "      if sorted(class_0_phonemes_found) != sorted(phonemes_class_0):\n",
        "        raise Exception(f\"class 0 phonemes found ({sorted(class_0_phonemes_found)}) != expected phonemes ({sorted(phonemes_class_0)})\")\n",
        " \n",
        "      if sorted(class_1_phonemes_found) != sorted(phonemes_class_1):\n",
        "        raise Exception(f\"class 1 phonemes found ({sorted(class_1_phonemes_found)}) != expected phonemes ({sorted(phonemes_class_1)})\")\n",
        " \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        " \n",
        "    # get a row at an index\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.X[index]).float()\n",
        "        y = torch.as_tensor(self.Y[index]).float()\n",
        "    \n",
        "        return x,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psP0nwMNE9yv"
      },
      "source": [
        "def make_dataloader(dataset, train, batch_size):\n",
        "  if train:\n",
        "    shuffle = True\n",
        "    drop_last = True\n",
        "  else:\n",
        "    shuffle = False\n",
        "    drop_last = False\n",
        "    \n",
        "  loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                      drop_last=drop_last, shuffle=shuffle,\n",
        "                      pin_memory=True, num_workers=8)\n",
        "  \n",
        "  return loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p_S9L8GWRd"
      },
      "source": [
        "class SpecializedShallowDetector(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden_size, activation):\n",
        "    super(SpecializedShallowDetector, self).__init__()\n",
        "    \n",
        "    self.linear_layer = nn.Linear(in_features=40, out_features=hidden_size)\n",
        "    self.bn_layer = nn.BatchNorm1d(num_features=hidden_size)\n",
        "    self.activation = activation\n",
        "    self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    seq_params = [\n",
        "      self.linear_layer,\n",
        "      self.bn_layer,\n",
        "      self.activation,\n",
        "      self.output_layer,\n",
        "      self.sigmoid\n",
        "    ]\n",
        "\n",
        "    self.network = nn.Sequential(*seq_params)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.network(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2vi_qzCnv8X"
      },
      "source": [
        "## 1. Generating predictions csv for specialized detectors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc_BPAm2n3wt",
        "outputId": "e24df3ee-57ed-4482-8752-756dcc66caaf"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/DL_Group_Project/Utilities\n",
        "from utilities import SPECIALIZED_TASKS\n",
        "%cd /\n",
        "print(SPECIALIZED_TASKS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1qwJK2jyGMl2dPnVFe6JNZvrrG45HoonZ/DL_Group_Project/Utilities\n",
            "/\n",
            "{'1_vowel_vs_consonant': {0: ['EE', 'IH', 'EH', 'AE', 'UH', 'ER', 'AH', 'AW', 'OO', 'UE'], 1: ['FF', 'HH', 'MM', 'NN', 'NG', 'RR', 'SS', 'SH', 'VV', 'WW', 'YY', 'ZZ']}, '3_highvowel_vs_lowvowel': {0: ['EE', 'IH', 'UE', 'OO'], 1: ['AE', 'AH', 'AW']}, '4_voiced_vs_unvoiced_fricatives': {0: ['DH', 'VV', 'ZZ'], 1: ['FF', 'SS', 'SH', 'TH']}, '5_ss_vs_zz': {0: ['SS'], 1: ['ZZ']}, '6_b_vs_p': {0: ['B'], 1: ['P']}, '7_dh_vs_th': {0: ['DH'], 1: ['TH']}, '8_ww_vs_yy': {0: ['WW'], 1: ['YY']}, '9_ee_vs_aw': {0: ['EE'], 1: ['AW']}, '10_ah_vs_aw': {0: ['AH'], 1: ['AW']}, '11_mm_vs_nn': {0: ['MM'], 1: ['NN']}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyXk6y1Uodvb"
      },
      "source": [
        "class ValidateSpecializedDetector():\n",
        "\n",
        "  def __init__(self, task_name, phonemes_class_0, phonemes_class_1):\n",
        "    self.task_name = task_name\n",
        "    self.class_0 = phonemes_class_0\n",
        "    self.class_1 = phonemes_class_0\n",
        "\n",
        "    dev_data = SpecializedDataset(datapath=datapath, mode=\"dev\", \n",
        "                                  task_name=task_name, \n",
        "                                  phonemes_class_0=phonemes_class_0, \n",
        "                                  phonemes_class_1=phonemes_class_1)\n",
        "    self.dev_loader = make_dataloader(dataset=dev_data, train=False, batch_size=BATCH_SIZE)\n",
        "\n",
        "    self.model = SpecializedShallowDetector(hidden_size=HIDDEN_SIZE, \n",
        "                                            activation=nn.LeakyReLU()).to(DEVICE)\n",
        "    self.criterion = nn.BCELoss()\n",
        "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "  \n",
        "  def load_model(self, epoch, model_version = MODEL_VERSION):\n",
        "    self.model_epoch_path = \"{}/models/model_{}_{}_{}\".format(output_path, self.task_name, \n",
        "                                                         model_version, epoch)\n",
        "    checkpoint = torch.load(self.model_epoch_path)\n",
        "    self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    self.scheduler = checkpoint['scheduler_state_dict']\n",
        "    self.model.to(DEVICE)\n",
        "\n",
        "    self.epoch = epoch\n",
        "    self.model_version = model_version\n",
        "\n",
        "    print('loaded model: {}'.format(self.model_epoch_path))\n",
        "\n",
        "  def plot_misclassification(self, df, s):\n",
        "\n",
        "      df['frame'] = df.index\n",
        "\n",
        "      misclass_df = df[df['true_labels']!=df['predictions']]\n",
        "\n",
        "      # gca stands for 'get current axis'\n",
        "      ax = plt.gca()\n",
        "\n",
        "      misclass_df.plot(kind='scatter',x = 'frame', y='true_labels', ax = ax, style=\".\", s = s)\n",
        "      misclass_df.plot(kind='scatter',x = 'frame', y='predictions', color='red', ax = ax, style=\".\", s = s)\n",
        "\n",
        "      title = \"{}\".format(self.task_name)\n",
        "      plt.title(title)\n",
        "      plot_path = \"{}/updated_misclass/plot_{}_{}_{}.png\".format(output_path, self.task_name, \n",
        "                                                         self.model_version, self.epoch)\n",
        "      plt.savefig(plot_path)\n",
        "      print('saved plot: {}'.format(plot_path))\n",
        "      plt.clf()\n",
        "\n",
        "  def plot_true(self, df):\n",
        "\n",
        "      # gca stands for 'get current axis'\n",
        "      ax = plt.gca()\n",
        "\n",
        "      df.plot(kind='line',y='true_labels', ax = ax)\n",
        "\n",
        "      title = \"{}\".format(self.task_name)\n",
        "      plt.title(title)\n",
        "      plot_path = \"{}/updated_misclass/true_labels_{}_{}_{}.png\".format(output_path, self.task_name, \n",
        "                                                         self.model_version, self.epoch)\n",
        "      plt.savefig(plot_path)\n",
        "      print('saved plot: {}'.format(plot_path))\n",
        "      plt.clf()\n",
        "\n",
        "  def evaluate_model_misclassification(self):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      self.model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      total_predictions = 0.0\n",
        "      correct_predictions = 0.0\n",
        "\n",
        "      true_labels = []\n",
        "      predictions = []\n",
        "\n",
        "      example_ct = 0\n",
        "      start_time = time.time()\n",
        "      for batch_idx, (features, targets) in enumerate(self.dev_loader):\n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "        targets = targets.reshape(-1, 1)\n",
        "\n",
        "        example_ct += len(features)\n",
        "\n",
        "        outputs = self.model(features)\n",
        "        outputs = outputs.to(DEVICE)\n",
        "\n",
        "        # check number of correct predictions\n",
        "        output_classes = torch.where(outputs > LOGISTIC_THRESHOLD, 1, 0)  # convert to class labels\n",
        "        total_predictions += len(output_classes)\n",
        "        correct_predictions += torch.sum(targets == output_classes)\n",
        "\n",
        "        loss = self.criterion(outputs, targets).detach()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        true_labels += list(targets.detach().cpu())\n",
        "        predictions += list(output_classes.detach().cpu())\n",
        "      \n",
        "      end_time = time.time()\n",
        "\n",
        "      running_loss /= example_ct\n",
        "      print(f\"testing loss: {running_loss}; time: {end_time - start_time}s\")\n",
        "  \n",
        "      print(classification_report(true_labels, predictions))\n",
        "      print(confusion_matrix(true_labels, predictions))\n",
        "      classification_pd = pd.DataFrame(\n",
        "    {'true_labels': [a.item() for a in true_labels],\n",
        "     'predictions': [a.item() for a in predictions]\n",
        "    })\n",
        "      csv_path = \"{}/updated_misclass/report_{}_{}_{}.csv\".format(output_path, self.task_name, \n",
        "                                                         self.model_version, self.epoch)\n",
        "      classification_pd.to_csv(csv_path, index=True)\n",
        "      if len(classification_pd.index) < 1000:\n",
        "        s = 0.5\n",
        "      else:\n",
        "        s = 0.09\n",
        "      self.plot_misclassification(classification_pd, s)\n",
        "      self.plot_true(classification_pd)\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AI3InJumoW6-",
        "outputId": "b2091b61-af8c-4b06-f380-f378d9d74a5c"
      },
      "source": [
        "not_trained = []\n",
        "for task_name, classes_dict in SPECIALIZED_TASKS.items():\n",
        "  try:\n",
        "    detector = ValidateSpecializedDetector(task_name, classes_dict[0], classes_dict[1])\n",
        "    detector.load_model(epoch = 29, model_version = 1)\n",
        "    detector.evaluate_model_misclassification()\n",
        "  except Exception as e:\n",
        "    not_trained.append((task_name, str(e)))"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[task=1_vowel_vs_consonant] (3307, 40) features\n",
            "[task=1_vowel_vs_consonant] (3307,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_1_vowel_vs_consonant_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.0035523334779983063; time: 0.5781617164611816s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.90      0.83      0.86      1383\n",
            "         1.0       0.88      0.94      0.91      1924\n",
            "\n",
            "    accuracy                           0.89      3307\n",
            "   macro avg       0.89      0.88      0.89      3307\n",
            "weighted avg       0.89      0.89      0.89      3307\n",
            "\n",
            "[[1143  240]\n",
            " [ 120 1804]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_1_vowel_vs_consonant_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_1_vowel_vs_consonant_1_29.png\n",
            "[task=3_highvowel_vs_lowvowel] (1065, 40) features\n",
            "[task=3_highvowel_vs_lowvowel] (1065,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_3_highvowel_vs_lowvowel_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.0029278355654976176; time: 0.4590907096862793s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.89      0.99      0.94       616\n",
            "         1.0       0.99      0.83      0.90       449\n",
            "\n",
            "    accuracy                           0.92      1065\n",
            "   macro avg       0.94      0.91      0.92      1065\n",
            "weighted avg       0.93      0.92      0.92      1065\n",
            "\n",
            "[[611   5]\n",
            " [ 77 372]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_3_highvowel_vs_lowvowel_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_3_highvowel_vs_lowvowel_1_29.png\n",
            "[task=4_voiced_vs_unvoiced_fricatives] (1116, 40) features\n",
            "[task=4_voiced_vs_unvoiced_fricatives] (1116,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_4_voiced_vs_unvoiced_fricatives_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.0038350047510264168; time: 0.4625999927520752s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.81      0.90      0.85       463\n",
            "         1.0       0.92      0.85      0.89       653\n",
            "\n",
            "    accuracy                           0.87      1116\n",
            "   macro avg       0.87      0.88      0.87      1116\n",
            "weighted avg       0.88      0.87      0.87      1116\n",
            "\n",
            "[[415  48]\n",
            " [ 95 558]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_4_voiced_vs_unvoiced_fricatives_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_4_voiced_vs_unvoiced_fricatives_1_29.png\n",
            "[task=5_ss_vs_zz] (321, 40) features\n",
            "[task=5_ss_vs_zz] (321,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_5_ss_vs_zz_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.004418619725609494; time: 0.41211986541748047s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.99      0.91       158\n",
            "         1.0       0.99      0.83      0.90       163\n",
            "\n",
            "    accuracy                           0.91       321\n",
            "   macro avg       0.92      0.91      0.91       321\n",
            "weighted avg       0.92      0.91      0.91       321\n",
            "\n",
            "[[156   2]\n",
            " [ 28 135]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_5_ss_vs_zz_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_5_ss_vs_zz_1_29.png\n",
            "[task=6_b_vs_p] (169, 40) features\n",
            "[task=6_b_vs_p] (169,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_6_b_vs_p_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.008018413062631732; time: 0.39914369583129883s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.74      0.96      0.83        96\n",
            "         1.0       0.91      0.55      0.68        73\n",
            "\n",
            "    accuracy                           0.78       169\n",
            "   macro avg       0.82      0.75      0.76       169\n",
            "weighted avg       0.81      0.78      0.77       169\n",
            "\n",
            "[[92  4]\n",
            " [33 40]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_6_b_vs_p_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_6_b_vs_p_1_29.png\n",
            "[task=7_dh_vs_th] (310, 40) features\n",
            "[task=7_dh_vs_th] (310,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_7_dh_vs_th_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.004478254000986776; time: 0.42003583908081055s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.88      0.78      0.83       138\n",
            "         1.0       0.84      0.92      0.88       172\n",
            "\n",
            "    accuracy                           0.85       310\n",
            "   macro avg       0.86      0.85      0.85       310\n",
            "weighted avg       0.86      0.85      0.85       310\n",
            "\n",
            "[[107  31]\n",
            " [ 14 158]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_7_dh_vs_th_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_7_dh_vs_th_1_29.png\n",
            "[task=8_ww_vs_yy] (310, 40) features\n",
            "[task=8_ww_vs_yy] (310,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_8_ww_vs_yy_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.005077230882260107; time: 0.40673232078552246s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.92      0.84      0.88       155\n",
            "         1.0       0.85      0.92      0.89       155\n",
            "\n",
            "    accuracy                           0.88       310\n",
            "   macro avg       0.88      0.88      0.88       310\n",
            "weighted avg       0.88      0.88      0.88       310\n",
            "\n",
            "[[130  25]\n",
            " [ 12 143]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_8_ww_vs_yy_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_8_ww_vs_yy_1_29.png\n",
            "[task=9_ee_vs_aw] (388, 40) features\n",
            "[task=9_ee_vs_aw] (388,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_9_ee_vs_aw_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.0030441126538939853; time: 0.4337780475616455s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.99      0.96       226\n",
            "         1.0       0.99      0.90      0.94       162\n",
            "\n",
            "    accuracy                           0.95       388\n",
            "   macro avg       0.96      0.94      0.95       388\n",
            "weighted avg       0.95      0.95      0.95       388\n",
            "\n",
            "[[224   2]\n",
            " [ 17 145]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_9_ee_vs_aw_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_9_ee_vs_aw_1_29.png\n",
            "[task=10_ah_vs_aw] (305, 40) features\n",
            "[task=10_ah_vs_aw] (305,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_10_ah_vs_aw_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.0038384346199817343; time: 0.4168875217437744s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.85      0.99      0.92       143\n",
            "         1.0       0.99      0.85      0.91       162\n",
            "\n",
            "    accuracy                           0.91       305\n",
            "   macro avg       0.92      0.92      0.91       305\n",
            "weighted avg       0.93      0.91      0.91       305\n",
            "\n",
            "[[142   1]\n",
            " [ 25 137]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_10_ah_vs_aw_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_10_ah_vs_aw_1_29.png\n",
            "[task=11_mm_vs_nn] (391, 40) features\n",
            "[task=11_mm_vs_nn] (391,) labels\n",
            "loaded model: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//models/model_11_mm_vs_nn_1_29\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.00415665073239285; time: 0.4244225025177002s\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.87      0.96      0.92       191\n",
            "         1.0       0.96      0.86      0.91       200\n",
            "\n",
            "    accuracy                           0.91       391\n",
            "   macro avg       0.92      0.91      0.91       391\n",
            "weighted avg       0.92      0.91      0.91       391\n",
            "\n",
            "[[184   7]\n",
            " [ 27 173]]\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/plot_11_mm_vs_nn_1_29.png\n",
            "saved plot: /content/gdrive/MyDrive/DL_Group_Project/experiments/specialized_detectors//updated_misclass/true_labels_11_mm_vs_nn_1_29.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfB9CBHvp6j"
      },
      "source": [
        "for task_name, error in not_trained:\n",
        "  print(f\"'{task_name}' not trained\")\n",
        "  print(f\"error: {error}\")\n",
        "  print(\"\")"
      ],
      "execution_count": 94,
      "outputs": []
    }
  ]
}