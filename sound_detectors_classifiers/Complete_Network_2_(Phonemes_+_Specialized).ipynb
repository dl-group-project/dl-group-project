{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Complete Network 2 (Phonemes + Specialized).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0m9yaDqUnF"
      },
      "source": [
        "# Frame to Phoneme Classifier\n",
        "Model network 2, includes:\n",
        "*    Pre-trained Phoneme Shallow Detectors (38)\n",
        "*    Pre-trained Specialized Task Classifiers (10)\n",
        "\n",
        "Combines these models into a final linear layer, and outputs phoneme probabilities\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7elo3dEOZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e43f539-9b0b-4854-a567-d91449ab24bd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuW97yYYrDNK"
      },
      "source": [
        "drivepath = '/content/gdrive/MyDrive/DL_Group_Project'\n",
        "specialized_models_path = f'{drivepath}/experiments/specialized_detectors/models'\n",
        "phoneme_models_path = f'{drivepath}/experiments/phoneme_detectors/'\n",
        "datapath = '/content/gdrive/MyDrive/DL_Group_Project/Dataset/Preprocessed_Data'\n",
        "drivepath_final = f'{drivepath}/experiments/complete_network_2/'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNu7076tIgbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1040505b-2f29-42d7-ecef-c616d3b5c7fc"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0sSLZGvAcnu"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPNjU3GMS7A"
      },
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_SIZE_shallow = 128\n",
        "HIDDEN_SIZE_spec = 128\n",
        "MODEL_VERSION = 1\n",
        "LEARNING_RATE = 0.01\n",
        "OTHER_PHONEMES_PERCENT = 0.1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlpeV6MJHvzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c42c4db-b4f4-46ce-f0e3-fa1b4049c591"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 8 if cuda else 0\n",
        "DEVICE = \"cuda\" if cuda else \"cpu\"\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYfqte6xK-6"
      },
      "source": [
        "class PhonemesDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, basepath, mode):\n",
        "      phoneme_features = np.zeros((1, 40))  # eliminate this row\n",
        "      phoneme_labels = np.zeros((1))  # eliminate this row\n",
        "\n",
        "      with os.scandir(basepath) as entries:\n",
        "        for entry in entries:\n",
        "          if entry.is_file():\n",
        "            if \"features\" in entry.name and mode in entry.name:\n",
        "              phoneme_tag = entry.name.split(\"_\")[0]\n",
        "\n",
        "              features_filepath = entry.path\n",
        "              labels_filepath = f\"{basepath}/{phoneme_tag}_{mode}_labels.npy\"\n",
        "\n",
        "              other_phoneme_features = np.load(features_filepath, allow_pickle=True)\n",
        "              other_phoneme_labels = np.load(labels_filepath, allow_pickle=True)\n",
        "              \n",
        "              # stack to phoneme features\n",
        "              phoneme_features = np.concatenate((phoneme_features, other_phoneme_features))\n",
        "              phoneme_labels = np.concatenate((phoneme_labels, other_phoneme_labels))\n",
        "              \n",
        "      self.X = phoneme_features[1:]\n",
        "      self.Y = phoneme_labels[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        " \n",
        "    # get a row at an index\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.X[index]).float()\n",
        "        y = torch.as_tensor(self.Y[index]).long()\n",
        "    \n",
        "        return x,y\n",
        "\n",
        "    def get_phoneme_label_frames(self, phoneme_label):\n",
        "        phoneme_indexes = np.where(self.Y == phoneme_label)\n",
        "        return torch.Tensor(self.X[phoneme_indexes]).float(), torch.as_tensor(self.Y[phoneme_indexes]).long()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psP0nwMNE9yv"
      },
      "source": [
        "def make_dataloader(dataset, train, batch_size):\n",
        "  if train:\n",
        "    shuffle = True\n",
        "    drop_last = True\n",
        "  else:\n",
        "    shuffle = False\n",
        "    drop_last = False\n",
        "    \n",
        "  loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                      drop_last=drop_last, shuffle=shuffle,\n",
        "                      pin_memory=True, num_workers=8)\n",
        "  \n",
        "  return loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p_S9L8GWRd"
      },
      "source": [
        "class PhonemeShallowDetector(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden_size, activation):\n",
        "    super(PhonemeShallowDetector, self).__init__()\n",
        "    \n",
        "    self.linear_layer = nn.Linear(in_features=40, out_features=hidden_size)\n",
        "    self.linear_layer.weight.requires_grad = False\n",
        "    self.linear_layer.requires_grad = False\n",
        "    self.bn_layer = nn.BatchNorm1d(num_features=hidden_size)\n",
        "    self.bn_layer.weight.requires_grad = False\n",
        "    self.bn_layer.requires_grad = False\n",
        "    self.activation = activation\n",
        "    self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "    self.output_layer.weight.requires_grad = False\n",
        "    self.output_layer.requires_grad = False\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    seq_params = [\n",
        "      self.linear_layer,\n",
        "      self.bn_layer,\n",
        "      self.activation,\n",
        "      self.output_layer,\n",
        "      self.sigmoid\n",
        "    ]\n",
        "\n",
        "    self.network = nn.Sequential(*seq_params)      \n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.network(x)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAI4xDfb6XU-"
      },
      "source": [
        "class SpecializedShallowDetector(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden_size, activation):\n",
        "    super(SpecializedShallowDetector, self).__init__()\n",
        "    \n",
        "    self.linear_layer = nn.Linear(in_features=40, out_features=hidden_size)\n",
        "    self.linear_layer.weight.requires_grad = False\n",
        "    self.linear_layer.requires_grad = False\n",
        "    self.bn_layer = nn.BatchNorm1d(num_features=hidden_size)\n",
        "    self.bn_layer.weight.requires_grad = False\n",
        "    self.bn_layer.requires_grad = False\n",
        "    self.activation = activation\n",
        "    self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "    self.output_layer.weight.requires_grad = False\n",
        "    self.output_layer.requires_grad = False\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    seq_params = [\n",
        "      self.linear_layer,\n",
        "      self.bn_layer,\n",
        "      self.activation,\n",
        "      self.output_layer,\n",
        "      self.sigmoid\n",
        "    ]\n",
        "\n",
        "    self.network = nn.Sequential(*seq_params)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.network(x)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z65FZ5qdK5El"
      },
      "source": [
        "class FramePhonemeClassifierModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, phoneme_mapper, specialized_mapper):\n",
        "    super(FramePhonemeClassifierModel, self).__init__()\n",
        "    \n",
        "    self.phoneme_mapper = phoneme_mapper\n",
        "    self.specialized_mapper = specialized_mapper\n",
        "\n",
        "    # generate the SpecializedShallowDetector \n",
        "    specialized_detectors = []\n",
        "    for spec_idx, spec_type in enumerate(self.specialized_mapper):\n",
        "      specialized_detector = SpecializedShallowDetector(hidden_size=HIDDEN_SIZE_spec, \n",
        "                                                        activation=nn.LeakyReLU()).to(DEVICE)\n",
        "      specialized_detectors.append(specialized_detector)\n",
        "\n",
        "    self.specialized_detectors = nn.ModuleList(specialized_detectors)\n",
        "\n",
        "    # generate the PhonemeShallowDetectors \n",
        "    phoneme_detectors = []\n",
        "    for phoneme_index, phoneme_tag in phoneme_mapper.items():\n",
        "      phoneme_detector = PhonemeShallowDetector(hidden_size=HIDDEN_SIZE_shallow, \n",
        "                                                activation=nn.LeakyReLU())\n",
        "      phoneme_detectors.append(phoneme_detector)\n",
        "\n",
        "    self.phoneme_detectors = nn.ModuleList(phoneme_detectors)\n",
        "\n",
        "    self.linear_layer = nn.Linear(in_features=len(phoneme_mapper)+len(specialized_mapper), \n",
        "                                  out_features=len(phoneme_mapper))\n",
        "\n",
        "    self.initialize_specialized_detectors()\n",
        "    self.initialize_shallow_detectors()\n",
        "\n",
        "  def initialize_shallow_detectors(self):\n",
        "    # load weights from shallow detectors pre-trained models\n",
        "    for phoneme_index, phoneme_tag in self.phoneme_mapper.items():\n",
        "      phoneme_shallow_detector = self.phoneme_detectors[phoneme_index]\n",
        "\n",
        "      phoneme_model_path = f\"{phoneme_models_path}/model_{phoneme_tag}_{MODEL_VERSION}_99\"\n",
        "      temp = torch.load(phoneme_model_path)\n",
        "      phoneme_shallow_detector.load_state_dict(temp['model_state_dict'])\n",
        "  \n",
        "  def initialize_specialized_detectors(self):\n",
        "    # load weights from shallow detectors pre-trained models\n",
        "     for spec_idx, spec_type in enumerate(self.specialized_mapper):\n",
        "      specialized_detector = self.specialized_detectors[spec_idx]\n",
        "\n",
        "      spec_model_path = f\"{specialized_models_path}/model_{spec_type}_{MODEL_VERSION}_29\"\n",
        "      temp = torch.load(spec_model_path)\n",
        "      specialized_detector.load_state_dict(temp['model_state_dict'])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    Returns tuple:\n",
        "      final outputs (B, NUM_PHONEMES) and shallow classifier outputs (B, NUM_SHALLOW_DETECTORS)\n",
        "    \"\"\"\n",
        "    shallow_classifier_outputs = []\n",
        "    for phoneme_index, phoneme_tag in self.phoneme_mapper.items():\n",
        "      phoneme_shallow_detector = self.phoneme_detectors[phoneme_index]\n",
        "      # run frame through shallow detector\n",
        "      output = phoneme_shallow_detector(x)\n",
        "      shallow_classifier_outputs.append(output.reshape(-1))\n",
        "    \n",
        "    for spec_idx, spec_type in enumerate(self.specialized_mapper):\n",
        "      # go through specialized\n",
        "      specialized_detector = self.specialized_detectors[spec_idx]\n",
        "      output = specialized_detector(x)\n",
        "      shallow_classifier_outputs.append(output.reshape(-1))\n",
        "\n",
        "    # convert to torch tensor\n",
        "    shallow_classifier_outputs = torch.vstack(shallow_classifier_outputs).T\n",
        "    outputs = self.linear_layer(shallow_classifier_outputs)\n",
        "\n",
        "    return outputs, shallow_classifier_outputs"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utqi7Y-23cRE"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def highlight_highest(series):\n",
        "  pal = []\n",
        "  # TODO: print the series labels for the 5 highest\n",
        "  max_values = sorted(series, reverse=True)[:5]\n",
        "\n",
        "  max_color = 'turquoise'\n",
        "  other_color = 'lightgrey'\n",
        "\n",
        "  for item in series:\n",
        "    if item in max_values:\n",
        "        pal.append(max_color)\n",
        "    else:\n",
        "        pal.append(other_color)\n",
        "        \n",
        "  return pal\n",
        "\n",
        "def plot_phoneme_probabilities(phoneme_tag, phonemes, probabilities):\n",
        "  fig = plt.figure(figsize=(35, 3))\n",
        " \n",
        "  # creating the bar plot\n",
        "  plt.bar(phonemes, probabilities, width = 0.4, color = highlight_highest(probabilities))\n",
        "  \n",
        "  plt.xlabel(\"Phonemes\")\n",
        "  plt.ylabel(\"Probabilities\")\n",
        "  plt.title(f\"Model Probabilities for frame (true label={phoneme_tag})\")\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "def plot_shallow_networks_outputs(phoneme_tag, shallow_networks, probabilities):\n",
        "  fig = plt.figure(figsize=(35, 3))\n",
        " \n",
        "  # creating the bar plot\n",
        "  plt.bar(shallow_networks, probabilities, width = 0.4, color = highlight_highest(probabilities))\n",
        "  \n",
        "  plt.xlabel(\"Shallow Networks\")\n",
        "  plt.ylabel(\"Probabilities\")\n",
        "  plt.title(f\"Shallow Networks Probabilities for frame (true label={phoneme_tag})\")\n",
        "  plt.show()\n",
        "\n",
        "def plot_shallow_networks_importance(target_phoneme_tag, weight_phoneme_tag,\n",
        "                                     shallow_networks, probabilities, \n",
        "                                     phoneme_neuron_weights):\n",
        "  fig = plt.figure(figsize=(35, 3))\n",
        "\n",
        "  importance = probabilities.cpu().detach().numpy() * phoneme_neuron_weights.cpu().detach().numpy()\n",
        "\n",
        "  # creating the bar plot\n",
        "  plt.bar(shallow_networks, importance, width = 0.4, color = highlight_highest(importance))\n",
        "  \n",
        "  plt.xlabel(\"Shallow Networks\")\n",
        "  plt.ylabel(f\"Probabilities * Weights ({weight_phoneme_tag})\")\n",
        "  plt.title(f\"Shallow Networks Importance for frame (true label={target_phoneme_tag}; weights phoneme={weight_phoneme_tag})\")\n",
        "  plt.show()"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNhuSUg0_5sH"
      },
      "source": [
        "class FramePhonemeClassifier():\n",
        "\n",
        "  def __init__(self, train_loader, dev_loader, phoneme_mapper, specialized_mapper):\n",
        "    \n",
        "    self.model = FramePhonemeClassifierModel(phoneme_mapper, specialized_mapper).to(DEVICE)\n",
        "    \n",
        "    self.train_loader = train_loader\n",
        "    self.dev_loader = dev_loader\n",
        "\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    self.train_loss_per_epoch = []\n",
        "    self.train_acc_per_epoch = []\n",
        "    self.dev_loss_per_epoch = []\n",
        "    self.dev_acc_per_epoch = []\n",
        "  \n",
        "  def save_model(self, epoch):\n",
        "    model_epoch_path = f\"{drivepath_final}/models/model_{MODEL_VERSION}_{epoch}\"\n",
        "    torch.save({\n",
        "        'model_state_dict': self.model.state_dict(),\n",
        "        'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "        'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "    }, model_epoch_path)\n",
        "    # print('saved model: {}'.format(model_epoch_path))\n",
        "\n",
        "  def train(self, epochs):\n",
        "    self.model.train()\n",
        "\n",
        "    # Run training and track with wandb\n",
        "    total_batches = len(self.train_loader) * epochs\n",
        "    example_ct = 0  # number of examples seen\n",
        "    batch_ct = 0\n",
        "\n",
        "    epoch = None\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        total_predictions = 0\n",
        "        correct_predictions = 0\n",
        "\n",
        "        true_labels = []\n",
        "        predictions = []\n",
        "        for _, (features, targets) in enumerate(self.train_loader):\n",
        "            batch_loss, outputs = self.train_batch(features, targets)\n",
        "            train_loss += batch_loss\n",
        "\n",
        "            example_ct += len(features)\n",
        "            batch_ct += 1\n",
        "\n",
        "            # check number of correct predictions\n",
        "            output_classes = torch.argmax(outputs.log_softmax(1), dim=1).detach().cpu()  # convert to class labels\n",
        "            total_predictions += len(output_classes)\n",
        "            correct_predictions += torch.sum(targets == output_classes)\n",
        "\n",
        "            true_labels += list(targets)\n",
        "            predictions += list(output_classes)\n",
        "\n",
        "        end_time = time.time()\n",
        "\n",
        "        train_loss /= example_ct\n",
        "        print(f\"training loss: {train_loss}; time: {end_time - start_time}s\")\n",
        "        \n",
        "        if (epoch + 1) % 10 == 0 or epoch == (epochs - 1):\n",
        "          report = classification_report(true_labels, predictions, output_dict=True)\n",
        "          df = pd.DataFrame(report).transpose()\n",
        "          df.to_csv(f\"{drivepath_final}/reports/reports_train_{MODEL_VERSION}_{epoch + 1}.csv\", index=False)\n",
        "          self.save_model(epoch)\n",
        "\n",
        "        train_acc = (correct_predictions/total_predictions) * 100.0\n",
        "        print(f\"training accuracy: {train_acc}%\")\n",
        "\n",
        "        self.train_loss_per_epoch.append(train_loss)\n",
        "        self.train_acc_per_epoch.append(train_acc)\n",
        "\n",
        "        # evaluate model with validation data\n",
        "        dev_loss, dev_acc = self.evaluate_model(epoch)\n",
        "        \n",
        "        self.dev_loss_per_epoch.append(dev_loss)\n",
        "        self.dev_acc_per_epoch.append(dev_acc)\n",
        "\n",
        "        # Step with the scheduler\n",
        "        self.scheduler.step(dev_loss)\n",
        "    \n",
        "    if epoch is not None:\n",
        "      # epoch completed, save model\n",
        "      self.save_model(epoch)\n",
        "\n",
        "  def train_batch(self, features, targets):\n",
        "    features, targets = features.to(DEVICE), targets.to(DEVICE)\n",
        "    targets = targets.reshape(-1, 1)\n",
        "\n",
        "    self.optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass ➡\n",
        "    outputs, shallow_classifier_outputs = self.model(features)\n",
        "    loss = self.criterion(outputs, targets.reshape(-1))  # compare with target outputs\n",
        "\n",
        "    # Backward pass ⬅\n",
        "    loss.backward()\n",
        "    \n",
        "    # Step with optimizer\n",
        "    self.optimizer.step()\n",
        "\n",
        "    return loss.item(), outputs\n",
        "\n",
        "  def evaluate_model(self, epoch):\n",
        "    with torch.no_grad():\n",
        "      self.model.eval()\n",
        "\n",
        "      running_loss = 0.0\n",
        "      total_predictions = 0.0\n",
        "      correct_predictions = 0.0\n",
        "\n",
        "      true_labels = []\n",
        "      predictions = []\n",
        "\n",
        "      example_ct = 0\n",
        "      start_time = time.time()\n",
        "      for batch_idx, (features, targets) in enumerate(self.dev_loader):\n",
        "        features = features.to(DEVICE)\n",
        "        targets = targets.to(DEVICE)\n",
        "        targets = targets.reshape(-1, 1)\n",
        "\n",
        "        example_ct += len(features)\n",
        "\n",
        "        outputs, shallow_classifier_outputs = self.model(features)\n",
        "        outputs = outputs.to(DEVICE)\n",
        "\n",
        "        # check number of correct predictions\n",
        "        output_classes = torch.argmax(outputs.log_softmax(1), dim=1)  # convert to class labels\n",
        "        total_predictions += len(output_classes)\n",
        "        correct_predictions += torch.sum(targets.reshape(-1) == output_classes)\n",
        "\n",
        "        loss = self.criterion(outputs, targets.reshape(-1)).detach()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        true_labels += list(targets.detach().cpu())\n",
        "        predictions += list(output_classes.detach().cpu())\n",
        "      \n",
        "      end_time = time.time()\n",
        "\n",
        "      running_loss /= example_ct\n",
        "      print(f\"testing loss: {running_loss}; time: {end_time - start_time}s\")\n",
        "      acc = (correct_predictions/total_predictions) * 100.0\n",
        "      print(f\"testing accuracy: {acc}%\")\n",
        "\n",
        "      if (epoch + 1) % 10 == 0:\n",
        "        report = classification_report(true_labels, predictions, output_dict=True)\n",
        "        df = pd.DataFrame(report).transpose()\n",
        "        df.to_csv(f\"{drivepath_final}/reports/reports_dev_{MODEL_VERSION}_{epoch + 1}.csv\", index=False)\n",
        "  \n",
        "      return running_loss, acc\n",
        "\n",
        "  def interpret_phoneme_frame(self, phoneme_tag, phoneme_label, features, targets):\n",
        "    self.model.eval()\n",
        "    features = features.to(DEVICE).unsqueeze(0)\n",
        "    targets = targets.to(DEVICE).unsqueeze(0).reshape(-1, 1)\n",
        "\n",
        "    outputs, shallow_classifier_outputs = self.model(features)\n",
        "    output_probabilities = self.softmax(outputs)[0]\n",
        "\n",
        "    output_class = torch.argmax(output_probabilities)  # convert to class label\n",
        "    predicted_phoneme_tag = PHONEME_MAPPER[output_class.item()]\n",
        "    print(f\"label assigned: {output_class}\")\n",
        "    print(f\"predicted_phoneme_tag: {predicted_phoneme_tag}\")\n",
        "\n",
        "    plot_phoneme_probabilities(phoneme_tag=phoneme_tag, \n",
        "                               phonemes=PHONEME_MAPPER.values(), \n",
        "                               probabilities=output_probabilities.tolist())\n",
        "    plot_shallow_networks_outputs(phoneme_tag=phoneme_tag, \n",
        "                                  shallow_networks=SHALLOW_NETWORKS, \n",
        "                                  probabilities=shallow_classifier_outputs[0].tolist())\n",
        "    \n",
        "    plot_shallow_networks_importance(target_phoneme_tag=phoneme_tag, \n",
        "                                      weight_phoneme_tag=phoneme_tag,\n",
        "                                      shallow_networks=SHALLOW_NETWORKS,\n",
        "                                      probabilities=shallow_classifier_outputs[0],\n",
        "                                      phoneme_neuron_weights=self.model.linear_layer.weight.data[phoneme_label, :])\n",
        "\n",
        "    if predicted_phoneme_tag == phoneme_tag:\n",
        "      print(f\"correctly classified as {phoneme_tag}\")\n",
        "    else:\n",
        "      print(f\"incorrectly classified as {phoneme_tag} (true={phoneme_tag})\")\n",
        "      plot_shallow_networks_importance(target_phoneme_tag=phoneme_tag, \n",
        "                                  weight_phoneme_tag=predicted_phoneme_tag,\n",
        "                                  shallow_networks=SHALLOW_NETWORKS,\n",
        "                                  probabilities=shallow_classifier_outputs[0],\n",
        "                                  phoneme_neuron_weights=self.model.linear_layer.weight.data[output_class, :])\n",
        "\n",
        "  def plot_graphs_for_each_phoneme(self, dev_data):\n",
        "    for phoneme_label, phoneme_tag in PHONEME_MAPPER.items():\n",
        "      print(f\"TESTING PHONEME '{phoneme_tag}' (label={phoneme_label})\")\n",
        "      phoneme_feature, phoneme_label = dev_data.get_phoneme_label_frames(phoneme_label=phoneme_label)\n",
        "      self.interpret_phoneme_frame(phoneme_tag, phoneme_index, phoneme_features[0], phoneme_labels[0])\n",
        "      print(\"\")\n"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmgukhuSqx7q"
      },
      "source": [
        "# Train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RgaXKNzySdO",
        "outputId": "fd7ea952-4ca5-41fc-c4e8-ed7b66e9c2bb"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/DL_Group_Project/Dataset/Preprocessed_Data"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1qwJK2jyGMl2dPnVFe6JNZvrrG45HoonZ/DL_Group_Project/Dataset/Preprocessed_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbfaEh8yYL1"
      },
      "source": [
        "from utilities import PHONEME_MAPPER\n",
        "from utilities import SPECIALIZED_TASKS"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7TH0JJh3QiH",
        "outputId": "40dd0f35-4c82-4ad8-806f-a85de98b1315"
      },
      "source": [
        "%cd /"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3TvLFZBygZ4",
        "outputId": "cc9b2b3b-d005-4fa1-e14f-8f349aee7f99"
      },
      "source": [
        "print(PHONEME_MAPPER)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'SIL', 1: 'AE', 2: 'AH', 3: 'AW', 4: 'AY', 5: 'B', 6: 'EH', 7: 'D', 8: 'DH', 9: 'EE', 10: 'FF', 11: 'G', 12: 'HH', 13: 'IH', 14: 'II', 15: 'J', 16: 'K', 17: 'LL', 18: 'MM', 19: 'NN', 20: 'OH', 21: 'OO', 22: 'OW', 23: 'OY', 24: 'P', 25: 'RR', 26: 'SH', 27: 'SS', 28: 'T', 29: 'TH', 30: 'UE', 31: 'UH', 32: 'VV', 33: 'WW', 34: 'YY', 35: 'ZZ', 36: 'CH', 37: 'ER', 38: 'NG'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYQLXKv3Bmwb",
        "outputId": "af163be7-d5af-4f16-fa8c-2dfb2a9bc4d0"
      },
      "source": [
        "print(SPECIALIZED_TASKS)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'1_vowel_vs_consonant': {0: ['EE', 'IH', 'EH', 'AE', 'UH', 'ER', 'AH', 'AW', 'OO', 'UE'], 1: ['FF', 'HH', 'MM', 'NN', 'NG', 'RR', 'SS', 'SH', 'VV', 'WW', 'YY', 'ZZ']}, '3_highvowel_vs_lowvowel': {0: ['EE', 'IH', 'UE', 'OO'], 1: ['AE', 'AH', 'AW']}, '4_voiced_vs_unvoiced_fricatives': {0: ['DH', 'VV', 'ZZ'], 1: ['FF', 'SS', 'SH', 'TH']}, '5_ss_vs_zz': {0: ['SS'], 1: ['ZZ']}, '6_b_vs_p': {0: ['B'], 1: ['P']}, '7_dh_vs_th': {0: ['DH'], 1: ['TH']}, '8_ww_vs_yy': {0: ['WW'], 1: ['YY']}, '9_ee_vs_aw': {0: ['EE'], 1: ['AW']}, '10_ah_vs_aw': {0: ['AH'], 1: ['AW']}, '11_mm_vs_nn': {0: ['MM'], 1: ['NN']}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCcL3aor6cjN"
      },
      "source": [
        "SHALLOW_NETWORKS = list(PHONEME_MAPPER.values())\n",
        "for task_name in SPECIALIZED_TASKS.keys():\n",
        "  task_id = task_name.split(\"_\")[0]\n",
        "  SHALLOW_NETWORKS.append(task_id)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ob-8tZjizxe3",
        "outputId": "a4e5ee3f-75a7-4ac4-fc54-30a9f89fddf1"
      },
      "source": [
        "train_data = PhonemesDataset(basepath=datapath, mode=\"train\")\n",
        "train_loader = make_dataloader(dataset=train_data, train=True, batch_size=BATCH_SIZE)\n",
        "print(f\"train_data.shape: {train_data.X.shape}\")\n",
        "\n",
        "dev_data = PhonemesDataset(basepath=datapath, mode=\"dev\")\n",
        "dev_loader = make_dataloader(dataset=dev_data, train=False, batch_size=BATCH_SIZE)\n",
        "print(f\"dev_data.shape: {dev_data.X.shape}\")"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_data.shape: (53755, 40)\n",
            "dev_data.shape: (11535, 40)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvRk8m8CLwGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1cfcde1-bdf8-4db0-9b3e-f52c11cd23dd"
      },
      "source": [
        "classifier = FramePhonemeClassifier(train_loader, dev_loader, PHONEME_MAPPER, SPECIALIZED_TASKS)\n",
        "#classifier.train(epochs=NUM_EPOCHS)\n",
        "classifier.train(epochs=20)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 0.024840148239084592; time: 33.167975425720215s\n",
            "training accuracy: 63.068016052246094%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  5%|▌         | 1/20 [00:36<11:37, 36.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.02633913896612962; time: 3.5117571353912354s\n",
            "testing accuracy: 62.14997863769531%\n",
            "training loss: 0.010170836112638481; time: 30.215386390686035s\n",
            "training accuracy: 71.15428161621094%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 10%|█         | 2/20 [01:10<10:43, 35.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.023556753676538093; time: 3.3624560832977295s\n",
            "testing accuracy: 67.87168884277344%\n",
            "training loss: 0.006116245970955836; time: 29.51873278617859s\n",
            "training accuracy: 74.7225112915039%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 15%|█▌        | 3/20 [01:43<09:53, 34.92s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.021964807341405723; time: 3.411412477493286s\n",
            "testing accuracy: 70.70654296875%\n",
            "training loss: 0.0042644158292659455; time: 29.57005214691162s\n",
            "training accuracy: 77.00759887695312%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 4/20 [02:15<09:08, 34.26s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.020879374193225424; time: 3.1439619064331055s\n",
            "testing accuracy: 71.94624328613281%\n",
            "training loss: 0.0032231396999924983; time: 27.50362277030945s\n",
            "training accuracy: 78.41365814208984%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 25%|██▌       | 5/20 [02:46<08:17, 33.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.019966310211007192; time: 3.142854690551758s\n",
            "testing accuracy: 73.18595123291016%\n",
            "training loss: 0.002563852425623962; time: 27.523662328720093s\n",
            "training accuracy: 79.21073913574219%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 30%|███       | 6/20 [03:17<07:33, 32.42s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.019208911265394726; time: 3.116781234741211s\n",
            "testing accuracy: 73.62808227539062%\n",
            "training loss: 0.0021146038939160523; time: 29.880637884140015s\n",
            "training accuracy: 79.75640869140625%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 35%|███▌      | 7/20 [03:50<07:04, 32.66s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01868487010670783; time: 3.301795244216919s\n",
            "testing accuracy: 74.07888793945312%\n",
            "training loss: 0.0017907824045373516; time: 30.382603406906128s\n",
            "training accuracy: 80.19963836669922%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 8/20 [04:24<06:35, 32.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01830553935560562; time: 3.314042329788208s\n",
            "testing accuracy: 74.70307159423828%\n",
            "training loss: 0.0015482206182849635; time: 30.392257690429688s\n",
            "training accuracy: 80.59818267822266%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 45%|████▌     | 9/20 [04:57<06:05, 33.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.017950395778577256; time: 3.3196873664855957s\n",
            "testing accuracy: 75.11053466796875%\n",
            "training loss: 0.0013609284701556216; time: 30.19190216064453s\n",
            "training accuracy: 80.99671936035156%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01753894193869005; time: 3.556731700897217s\n",
            "testing accuracy: 75.69137573242188%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 50%|█████     | 10/20 [05:33<05:37, 33.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "training loss: 0.0012104186589262191; time: 30.30970597267151s\n",
            "training accuracy: 81.39154052734375%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 55%|█████▌    | 11/20 [06:06<05:03, 33.75s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.017224585889193938; time: 3.3684308528900146s\n",
            "testing accuracy: 76.02947235107422%\n",
            "training loss: 0.001089854886234369; time: 29.5367169380188s\n",
            "training accuracy: 81.56473541259766%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 12/20 [06:39<04:28, 33.58s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.017015692317801014; time: 3.6499125957489014s\n",
            "testing accuracy: 76.31555938720703%\n",
            "training loss: 0.0009894460874134126; time: 28.455681800842285s\n",
            "training accuracy: 81.91299438476562%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 65%|██████▌   | 13/20 [07:11<03:50, 32.99s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01684947331255527; time: 3.124772310256958s\n",
            "testing accuracy: 76.47160339355469%\n",
            "training loss: 0.00090470999803108; time: 27.24881887435913s\n",
            "training accuracy: 82.1886215209961%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 70%|███████   | 14/20 [07:41<03:13, 32.20s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01665010206307691; time: 3.0912094116210938s\n",
            "testing accuracy: 76.61031341552734%\n",
            "training loss: 0.0008338018084432594; time: 27.11652398109436s\n",
            "training accuracy: 82.38788604736328%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 75%|███████▌  | 15/20 [08:12<02:38, 31.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.016490962688650048; time: 3.1140451431274414s\n",
            "testing accuracy: 76.87905883789062%\n",
            "training loss: 0.0007717599948680559; time: 28.995121240615845s\n",
            "training accuracy: 82.58529663085938%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 16/20 [08:44<02:07, 31.83s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.016322232863579575; time: 3.335376024246216s\n",
            "testing accuracy: 77.18247985839844%\n",
            "training loss: 0.0007182527498371414; time: 29.959548711776733s\n",
            "training accuracy: 82.73055267333984%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 85%|████████▌ | 17/20 [09:17<01:36, 32.27s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01608430620365242; time: 3.3225860595703125s\n",
            "testing accuracy: 77.36454010009766%\n",
            "training loss: 0.000670926258981291; time: 30.10239577293396s\n",
            "training accuracy: 82.95217895507812%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 90%|█████████ | 18/20 [09:51<01:05, 32.61s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.01618253534419949; time: 3.2953221797943115s\n",
            "testing accuracy: 77.32119750976562%\n",
            "training loss: 0.0006299860787213776; time: 29.65043306350708s\n",
            "training accuracy: 83.13282012939453%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 95%|█████████▌| 19/20 [10:24<00:32, 32.80s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "testing loss: 0.015883457515345128; time: 3.5680062770843506s\n",
            "testing accuracy: 77.55525970458984%\n",
            "training loss: 0.0005927454017511213; time: 29.863985061645508s\n",
            "training accuracy: 83.25387573242188%\n",
            "testing loss: 0.01580355052287619; time: 3.205950975418091s\n",
            "testing accuracy: 77.83267974853516%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [10:58<00:00, 32.94s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLC2extv0AE-"
      },
      "source": [
        "# test\n",
        "phoneme_index = 1\n",
        "phoneme_tag = PHONEME_MAPPER[phoneme_index]\n",
        "phoneme_features, phoneme_labels = dev_data.get_phoneme_label_frames(phoneme_label=phoneme_index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z__2guLawLaG"
      },
      "source": [
        "classifier.interpret_phoneme_frame(phoneme_tag, phoneme_index, phoneme_features[0], phoneme_labels[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhonkaUS1Okm"
      },
      "source": [
        "classifier.plot_graphs_for_each_phoneme(dev_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hImWrsSwD6xH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}