{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Frame_Phoneme_Classifier_Tester.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ0m9yaDqUnF"
      },
      "source": [
        "# Frame to Phoneme Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lS7elo3dEOZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f890b01-2b53-4bfc-de19-97586e9bedf1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQF8XwhESvy"
      },
      "source": [
        "drivepath = '/content/gdrive/MyDrive/DL_Group_Project/Dataset/Preprocessed_Data'\n",
        "word_path = '/content/gdrive/MyDrive/DL_Group_Project/Dataset/Preprocessed_Data/Word_Test'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNu7076tIgbg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc7c84b-8bea-445b-ca6a-df221b8206dc"
      },
      "source": [
        "!pip install tqdm"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0sSLZGvAcnu"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pandas as pd"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toPNjU3GMS7A"
      },
      "source": [
        "NUM_EPOCHS = 100\n",
        "BATCH_SIZE = 64\n",
        "HIDDEN_SIZE = 128\n",
        "MODEL_VERSION = 1\n",
        "LEARNING_RATE = 0.01\n",
        "LOGISTIC_THRESHOLD = 0.5\n",
        "OTHER_PHONEMES_PERCENT = 0.1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlpeV6MJHvzv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff13f21-beec-4476-fe4d-1a75125064fc"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 8 if cuda else 0\n",
        "DEVICE = \"cuda\" if cuda else \"cpu\"\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnYfqte6xK-6"
      },
      "source": [
        "class PhonemesDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, basepath, mode):\n",
        "      phoneme_features = np.zeros((1, 40))  # eliminate this row\n",
        "      phoneme_labels = np.zeros((1))  # eliminate this row\n",
        "\n",
        "      with os.scandir(basepath) as entries:\n",
        "        for entry in entries:\n",
        "          if entry.is_file():\n",
        "            if \"features\" in entry.name and mode in entry.name:\n",
        "              phoneme_tag = entry.name.split(\"_\")[0]\n",
        "\n",
        "              features_filepath = entry.path\n",
        "              other_phoneme_features = np.load(features_filepath, allow_pickle=True)\n",
        "              \n",
        "              # stack to phoneme features\n",
        "              phoneme_features = np.concatenate((phoneme_features, other_phoneme_features))\n",
        "              \n",
        "      self.X = phoneme_features[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        " \n",
        "    # get a row at an index\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.X[index]).float()\n",
        "        return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psP0nwMNE9yv"
      },
      "source": [
        "def make_dataloader(dataset, batch_size):\n",
        "  shuffle = False\n",
        "  drop_last = False\n",
        "    \n",
        "  loader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
        "                      drop_last=drop_last, shuffle=shuffle,\n",
        "                      pin_memory=True, num_workers=8)\n",
        "  \n",
        "  return loader"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--p_S9L8GWRd"
      },
      "source": [
        "class PhonemeShallowDetector(nn.Module):\n",
        "  \n",
        "  def __init__(self, hidden_size, activation):\n",
        "    super(PhonemeShallowDetector, self).__init__()\n",
        "    \n",
        "    self.linear_layer = nn.Linear(in_features=40, out_features=hidden_size)\n",
        "    self.bn_layer = nn.BatchNorm1d(num_features=hidden_size)\n",
        "    self.activation = activation\n",
        "    self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    seq_params = [\n",
        "      self.linear_layer,\n",
        "      self.bn_layer,\n",
        "      self.activation,\n",
        "      self.output_layer,\n",
        "      self.sigmoid\n",
        "    ]\n",
        "\n",
        "    self.network = nn.Sequential(*seq_params)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.network(x)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z65FZ5qdK5El"
      },
      "source": [
        "class FramePhonemeClassifierModel(nn.Module):\n",
        "  \n",
        "  def __init__(self, phoneme_mapper):\n",
        "    super(FramePhonemeClassifierModel, self).__init__()\n",
        "    \n",
        "    self.phoneme_mapper = phoneme_mapper\n",
        "\n",
        "    shallow_detectors = []\n",
        "    # generate the PhonemeShallowDetectors \n",
        "    for phoneme_index, phoneme_tag in phoneme_mapper.items():\n",
        "      shallow_detector = PhonemeShallowDetector(hidden_size=HIDDEN_SIZE, \n",
        "                                                activation=nn.LeakyReLU())\n",
        "      shallow_detectors.append(shallow_detector)\n",
        "    self.shallow_detectors = nn.ModuleList(shallow_detectors)\n",
        "\n",
        "    self.linear_layer = nn.Linear(in_features=len(phoneme_mapper), out_features=len(phoneme_mapper))\n",
        "\n",
        "    self.initialize_shallow_detectors()\n",
        "\n",
        "  def initialize_shallow_detectors(self):\n",
        "    # load weights from shallow detectors pre-trained models\n",
        "    for phoneme_index, phoneme_tag in self.phoneme_mapper.items():\n",
        "      phoneme_shallow_detector = self.shallow_detectors[phoneme_index]\n",
        "\n",
        "      phoneme_model_path = f\"{drivepath}/shallow_detectors/model_{phoneme_tag}_{MODEL_VERSION}_99\"\n",
        "      temp = torch.load(phoneme_model_path)\n",
        "      phoneme_shallow_detector.load_state_dict(temp['model_state_dict'])\n",
        "  \n",
        "  def forward(self, x):\n",
        "    \n",
        "    shallow_outputs = []\n",
        "    for phoneme_index, phoneme_tag in self.phoneme_mapper.items():\n",
        "      phoneme_shallow_detector = self.shallow_detectors[phoneme_index]\n",
        "\n",
        "      # run frame through shallow detector\n",
        "      output = phoneme_shallow_detector(x)\n",
        "      shallow_outputs.append(output.reshape(-1))\n",
        "\n",
        "    # convert to torch tensor\n",
        "    shallow_outputs = torch.vstack(shallow_outputs).T\n",
        "    outputs = self.linear_layer(shallow_outputs)\n",
        "\n",
        "    return outputs"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNhuSUg0_5sH"
      },
      "source": [
        "class FramePhonemeClassifier():\n",
        "\n",
        "  def __init__(self, phoneme_mapper):\n",
        "\n",
        "    word_data = PhonemesDataset(basepath=word_path, mode=\"word\")\n",
        "    self.word_loader = make_dataloader(dataset=word_data, batch_size=BATCH_SIZE)\n",
        "    print(f\"word_data.shape: {word_data.X.shape}\")\n",
        "\n",
        "    \n",
        "    self.model = FramePhonemeClassifierModel(phoneme_mapper).to(DEVICE)\n",
        "\n",
        "    self.criterion = nn.CrossEntropyLoss()\n",
        "    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
        "    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n",
        "\n",
        "  def load_model(self, epoch):\n",
        "\n",
        "    model_epoch_path = \"{}/final_classsifier/model_{}_{}\".format(drivepath,\n",
        "                                                                 MODEL_VERSION, \n",
        "                                                                 epoch)\n",
        "    best_model = torch.load(model_epoch_path)\n",
        "    self.model.load_state_dict(best_model['model_state_dict'], strict=False)\n",
        "    self.optimizer.load_state_dict(best_model['optimizer_state_dict'])\n",
        "    self.scheduler.load_state_dict(best_model['scheduler_state_dict'])\n",
        "\n",
        "  def test_model(self):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      self.model.eval()\n",
        "      total_predictions = 0.0\n",
        "      predictions = []\n",
        "\n",
        "      example_ct = 0\n",
        "      start_time = time.time()\n",
        "      for batch_idx, features in enumerate(self.word_loader):\n",
        "        features = features.to(DEVICE)\n",
        "        example_ct += len(features)\n",
        "\n",
        "        outputs = self.model(features)\n",
        "        outputs = outputs.to(DEVICE)\n",
        "\n",
        "        # check number of correct predictions\n",
        "        output_classes = torch.argmax(outputs.log_softmax(1), dim=1)  # convert to class labels\n",
        "        total_predictions += len(output_classes)\n",
        "        predictions += list(output_classes.detach().cpu())\n",
        "      \n",
        "      end_time = time.time()  \n",
        "      return predictions"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmgukhuSqx7q"
      },
      "source": [
        "# Test Word classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RgaXKNzySdO",
        "outputId": "74fa75e0-07c8-4768-b0f7-9bb0ee737932"
      },
      "source": [
        "%cd /content/gdrive/MyDrive/DL_Group_Project/Dataset/Preprocessed_Data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/1qwJK2jyGMl2dPnVFe6JNZvrrG45HoonZ/DL_Group_Project/Dataset/Preprocessed_Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjbfaEh8yYL1"
      },
      "source": [
        "from utilities import PHONEME_MAPPER"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7TH0JJh3QiH",
        "outputId": "dd20679a-78d8-4f76-e4ef-b4f9cc3b9fbc"
      },
      "source": [
        "%cd /"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3TvLFZBygZ4",
        "outputId": "438f0bc2-4b29-44a9-9721-0c61b7448e76"
      },
      "source": [
        "print(PHONEME_MAPPER)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'SIL', 1: 'AE', 2: 'AH', 3: 'AW', 4: 'AY', 5: 'B', 6: 'EH', 7: 'D', 8: 'DH', 9: 'EE', 10: 'FF', 11: 'G', 12: 'HH', 13: 'IH', 14: 'II', 15: 'J', 16: 'K', 17: 'LL', 18: 'MM', 19: 'NN', 20: 'OH', 21: 'OO', 22: 'OW', 23: 'OY', 24: 'P', 25: 'RR', 26: 'SH', 27: 'SS', 28: 'T', 29: 'TH', 30: 'UE', 31: 'UH', 32: 'VV', 33: 'WW', 34: 'YY', 35: 'ZZ'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvRk8m8CLwGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88bc2486-35b9-45a5-bcca-f36c23124244"
      },
      "source": [
        "classifier = FramePhonemeClassifier(PHONEME_MAPPER)\n",
        "classifier.load_model(99)\n",
        "predictions = classifier.test_model()\n",
        "print(predictions)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "word_data.shape: (1222, 40)\n",
            "[tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(22), tensor(22), tensor(0), tensor(22), tensor(22), tensor(3), tensor(0), tensor(0), tensor(5), tensor(0), tensor(23), tensor(23), tensor(23), tensor(7), tensor(23), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(1), tensor(15), tensor(0), tensor(28), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(27), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(20), tensor(2), tensor(22), tensor(22), tensor(0), tensor(0), tensor(3), tensor(21), tensor(0), tensor(30), tensor(25), tensor(25), tensor(17), tensor(23), tensor(23), tensor(23), tensor(13), tensor(13), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(17), tensor(15), tensor(13), tensor(0), tensor(13), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(27), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(21), tensor(0), tensor(0), tensor(2), tensor(3), tensor(3), tensor(3), tensor(3), tensor(0), tensor(30), tensor(30), tensor(25), tensor(23), tensor(25), tensor(23), tensor(23), tensor(13), tensor(23), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(17), tensor(13), tensor(13), tensor(13), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(11), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(22), tensor(0), tensor(3), tensor(3), tensor(3), tensor(0), tensor(0), tensor(25), tensor(25), tensor(23), tensor(17), tensor(23), tensor(13), tensor(13), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(15), tensor(13), tensor(13), tensor(13), tensor(0), tensor(13), tensor(13), tensor(15), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(27), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(21), tensor(20), tensor(20), tensor(22), tensor(0), tensor(3), tensor(3), tensor(30), tensor(30), tensor(25), tensor(25), tensor(23), tensor(23), tensor(23), tensor(23), tensor(13), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(0), tensor(13), tensor(0), tensor(13), tensor(13), tensor(13), tensor(16), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(11), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(27), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(22), tensor(3), tensor(0), tensor(0), tensor(3), tensor(30), tensor(0), tensor(25), tensor(25), tensor(23), tensor(23), tensor(23), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(1), tensor(0), tensor(13), tensor(13), tensor(0), tensor(0), tensor(0), tensor(13), tensor(13), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(21), tensor(0), tensor(0), tensor(2), tensor(0), tensor(0), tensor(0), tensor(30), tensor(30), tensor(30), tensor(25), tensor(25), tensor(23), tensor(17), tensor(13), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(0), tensor(0), tensor(13), tensor(13), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(21), tensor(21), tensor(0), tensor(2), tensor(2), tensor(3), tensor(3), tensor(0), tensor(0), tensor(30), tensor(25), tensor(17), tensor(23), tensor(23), tensor(13), tensor(13), tensor(15), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(0), tensor(13), tensor(13), tensor(28), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(0), tensor(21), tensor(0), tensor(2), tensor(0), tensor(33), tensor(18), tensor(30), tensor(23), tensor(23), tensor(23), tensor(17), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(15), tensor(15), tensor(13), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(2), tensor(0), tensor(22), tensor(22), tensor(21), tensor(33), tensor(33), tensor(30), tensor(25), tensor(23), tensor(23), tensor(23), tensor(13), tensor(23), tensor(13), tensor(13), tensor(13), tensor(13), tensor(13), tensor(7), tensor(13), tensor(13), tensor(13), tensor(25), tensor(0), tensor(17), tensor(13), tensor(16), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(11), tensor(11), tensor(0), tensor(0), tensor(34), tensor(11), tensor(0), tensor(0), tensor(0), tensor(0), tensor(11), tensor(0), tensor(19), tensor(0), tensor(0), tensor(0), tensor(0), tensor(19), tensor(19), tensor(0), tensor(0), tensor(0), tensor(0), tensor(11), tensor(19), tensor(0), tensor(35), tensor(19), tensor(0), tensor(19), tensor(0), tensor(0), tensor(19), tensor(0), tensor(0), tensor(0), tensor(11), tensor(0), tensor(19), tensor(0), tensor(0), tensor(0), tensor(0), tensor(34), tensor(11), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(34), tensor(0), tensor(7), tensor(7), tensor(0), tensor(0), tensor(34), tensor(34), tensor(0), tensor(34), tensor(5), tensor(5), tensor(0), tensor(33), tensor(0), tensor(34), tensor(27), tensor(0), tensor(0), tensor(8), tensor(0), tensor(0), tensor(0), tensor(34), tensor(34), tensor(34), tensor(0), tensor(0), tensor(34), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0), tensor(0)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rs2gBHHVk62",
        "outputId": "952ac933-8ced-4abb-a8a0-2e8294ce9554"
      },
      "source": [
        "print(predictions[0].item())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYDOci9XWiMQ",
        "outputId": "d6b8a5f5-0ee8-4f84-a919-a73faef5ecee"
      },
      "source": [
        "labels = list()\n",
        "for prediction in predictions:\n",
        "  labels.append(PHONEME_MAPPER[prediction.item()])\n",
        "print(labels)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OW', 'OW', 'SIL', 'OW', 'OW', 'AW', 'SIL', 'SIL', 'B', 'SIL', 'OY', 'OY', 'OY', 'D', 'OY', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'AE', 'J', 'SIL', 'T', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SS', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OH', 'AH', 'OW', 'OW', 'SIL', 'SIL', 'AW', 'OO', 'SIL', 'UE', 'RR', 'RR', 'LL', 'OY', 'OY', 'OY', 'IH', 'IH', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'LL', 'J', 'IH', 'SIL', 'IH', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SS', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OO', 'SIL', 'SIL', 'AH', 'AW', 'AW', 'AW', 'AW', 'SIL', 'UE', 'UE', 'RR', 'OY', 'RR', 'OY', 'OY', 'IH', 'OY', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'LL', 'IH', 'IH', 'IH', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'G', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'AH', 'SIL', 'OW', 'SIL', 'AW', 'AW', 'AW', 'SIL', 'SIL', 'RR', 'RR', 'OY', 'LL', 'OY', 'IH', 'IH', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'J', 'IH', 'IH', 'IH', 'SIL', 'IH', 'IH', 'J', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SS', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OO', 'OH', 'OH', 'OW', 'SIL', 'AW', 'AW', 'UE', 'UE', 'RR', 'RR', 'OY', 'OY', 'OY', 'OY', 'IH', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'SIL', 'IH', 'SIL', 'IH', 'IH', 'IH', 'K', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'G', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SS', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OW', 'AW', 'SIL', 'SIL', 'AW', 'UE', 'SIL', 'RR', 'RR', 'OY', 'OY', 'OY', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'AE', 'SIL', 'IH', 'IH', 'SIL', 'SIL', 'SIL', 'IH', 'IH', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OO', 'SIL', 'SIL', 'AH', 'SIL', 'SIL', 'SIL', 'UE', 'UE', 'UE', 'RR', 'RR', 'OY', 'LL', 'IH', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'SIL', 'SIL', 'IH', 'IH', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'OO', 'OO', 'SIL', 'AH', 'AH', 'AW', 'AW', 'SIL', 'SIL', 'UE', 'RR', 'LL', 'OY', 'OY', 'IH', 'IH', 'J', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'SIL', 'IH', 'IH', 'T', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'AH', 'SIL', 'SIL', 'OO', 'SIL', 'AH', 'SIL', 'WW', 'MM', 'UE', 'OY', 'OY', 'OY', 'LL', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'IH', 'J', 'J', 'IH', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'AH', 'SIL', 'OW', 'OW', 'OO', 'WW', 'WW', 'UE', 'RR', 'OY', 'OY', 'OY', 'IH', 'OY', 'IH', 'IH', 'IH', 'IH', 'IH', 'D', 'IH', 'IH', 'IH', 'RR', 'SIL', 'LL', 'IH', 'K', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'G', 'G', 'SIL', 'SIL', 'YY', 'G', 'SIL', 'SIL', 'SIL', 'SIL', 'G', 'SIL', 'NN', 'SIL', 'SIL', 'SIL', 'SIL', 'NN', 'NN', 'SIL', 'SIL', 'SIL', 'SIL', 'G', 'NN', 'SIL', 'ZZ', 'NN', 'SIL', 'NN', 'SIL', 'SIL', 'NN', 'SIL', 'SIL', 'SIL', 'G', 'SIL', 'NN', 'SIL', 'SIL', 'SIL', 'SIL', 'YY', 'G', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'YY', 'SIL', 'D', 'D', 'SIL', 'SIL', 'YY', 'YY', 'SIL', 'YY', 'B', 'B', 'SIL', 'WW', 'SIL', 'YY', 'SS', 'SIL', 'SIL', 'DH', 'SIL', 'SIL', 'SIL', 'YY', 'YY', 'YY', 'SIL', 'SIL', 'YY', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL', 'SIL']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFMIV01R7mmJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}