{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Specialized Task Shallow Detectors.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"pQ0m9yaDqUnF"},"source":["# Specialized Task Shallow Detectors\n","\n","*   Using latest email from Baker\n","\n"]},{"cell_type":"code","metadata":{"id":"lS7elo3dEOZK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619907486313,"user_tz":240,"elapsed":225,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"35622094-ac4d-49da-b208-05ee058f05ba"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":81,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJQF8XwhESvy","executionInfo":{"status":"ok","timestamp":1619907486486,"user_tz":240,"elapsed":218,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["drivepath = '/content/gdrive/MyDrive/Spring_2021/11785_Intro_to_Deep_Learning/DL_Group_Project'\n","datapath = '/content/gdrive/MyDrive/Spring_2021/11785_Intro_to_Deep_Learning/dl-group-project-code/preprocessed_data'\n","output_path = f'{drivepath}/experiments/specialized_detectors/'"],"execution_count":82,"outputs":[]},{"cell_type":"code","metadata":{"id":"tNu7076tIgbg","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619907489139,"user_tz":240,"elapsed":2698,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"561dbfb2-7179-4c32-bece-2677df753f78"},"source":["!pip install tqdm"],"execution_count":83,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a0sSLZGvAcnu","executionInfo":{"status":"ok","timestamp":1619907489139,"user_tz":240,"elapsed":2524,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","import os\n","from tqdm import tqdm\n","import time\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","import pandas as pd"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"toPNjU3GMS7A","executionInfo":{"status":"ok","timestamp":1619907489140,"user_tz":240,"elapsed":2380,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["NUM_EPOCHS = 30\n","BATCH_SIZE = 64\n","HIDDEN_SIZE = 128\n","MODEL_VERSION = 1\n","LEARNING_RATE = 0.01\n","LOGISTIC_THRESHOLD = 0.5"],"execution_count":85,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlpeV6MJHvzv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619907489141,"user_tz":240,"elapsed":2196,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"ff9761ac-ef91-4fa3-8cec-fe161c5ce261"},"source":["cuda = torch.cuda.is_available()\n","num_workers = 8 if cuda else 0\n","DEVICE = \"cuda\" if cuda else \"cpu\"\n","print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"],"execution_count":86,"outputs":[{"output_type":"stream","text":["Cuda = True with num_workers = 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jyjik86CAAE9","executionInfo":{"status":"ok","timestamp":1619907489141,"user_tz":240,"elapsed":2060,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["DEBUG = False"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"XnYfqte6xK-6","executionInfo":{"status":"ok","timestamp":1619907489142,"user_tz":240,"elapsed":1884,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["class SpecializedDataset(Dataset):\n","    \n","    def __init__(self, datapath, mode, task_name, phonemes_class_0, phonemes_class_1):\n","      \"\"\"\n","      phonemes_class_0: list of phoneme names for class 0\n","      phonemes_class_1: list of phoneme names for class 1\n","      \"\"\"\n","      complete_features = np.zeros((1, 40))  # eliminate this row\n","      complete_labels = np.zeros((1))  # eliminate this row\n","\n","      # go through all files in datapath, check phoneme if class=0 or class=1\n","      # assign that label and discard silence frames\n","      class_0_phonemes_found = []\n","      class_1_phonemes_found = []\n","      with os.scandir(datapath) as entries:\n","        for entry in entries:\n","          if entry.is_file():\n","            if \"features\" in entry.name and mode in entry.name:\n","              phoneme_tag = entry.name.split(\"_\")[0]\n","\n","              # find phoneme in class_0 or class_1 list and assign label\n","              phoneme_class = None\n","              if phoneme_tag in phonemes_class_0:\n","                phoneme_class = 0\n","                class_0_phonemes_found.append(phoneme_tag)\n","              if phoneme_tag in phonemes_class_1:\n","                phoneme_class = 1\n","                class_1_phonemes_found.append(phoneme_tag)\n","\n","              if phoneme_class is None:\n","                print(f\"phoneme '{phoneme_tag}' not found on class 0 nor class 1 lists; skip\") if DEBUG else None\n","                continue\n","\n","              print(f\"phoneme '{phoneme_tag}' is class: {phoneme_class}\") if DEBUG else None\n","\n","              features_filepath = entry.path\n","              labels_filepath = f\"{datapath}/{phoneme_tag}_{mode}_labels.npy\"\n","\n","              phoneme_features = np.load(features_filepath, allow_pickle=True)\n","              phoneme_labels = np.load(labels_filepath, allow_pickle=True)\n","              print(f\"{phoneme_tag} total features: {phoneme_features.shape}\") if DEBUG else None\n","              print(f\"{phoneme_tag} total labels: {phoneme_labels.shape}\") if DEBUG else None\n","\n","              # find frames where label != 0 (non-silence)\n","              non_zero_indexes = phoneme_labels.nonzero()\n","              phoneme_features = phoneme_features[non_zero_indexes]\n","              phoneme_labels = phoneme_labels[non_zero_indexes]\n","              print(f\"{phoneme_tag} no-silence features: {phoneme_features.shape}\") if DEBUG else None\n","              print(f\"{phoneme_tag} no-silence labels: {phoneme_labels.shape}\") if DEBUG else None\n","\n","              phoneme_labels[:] = phoneme_class  # label=class\n","\n","              # stack to phoneme features\n","              complete_features = np.concatenate((complete_features, phoneme_features))\n","              complete_labels = np.concatenate((complete_labels, phoneme_labels))\n","      \n","      self.X = complete_features[1:]\n","      self.Y = complete_labels[1:]\n","      print(f\"[task={task_name}] {self.X.shape} features\")\n","      print(f\"[task={task_name}] {self.Y.shape} labels\")\n","\n","      if sorted(class_0_phonemes_found) != sorted(phonemes_class_0):\n","        raise Exception(f\"class 0 phonemes found ({sorted(class_0_phonemes_found)}) != expected phonemes ({sorted(phonemes_class_0)})\")\n"," \n","      if sorted(class_1_phonemes_found) != sorted(phonemes_class_1):\n","        raise Exception(f\"class 1 phonemes found ({sorted(class_1_phonemes_found)}) != expected phonemes ({sorted(phonemes_class_1)})\")\n"," \n","\n","    def __len__(self):\n","        return len(self.X)\n"," \n","    # get a row at an index\n","    def __getitem__(self, index):\n","        x = torch.Tensor(self.X[index]).float()\n","        y = torch.as_tensor(self.Y[index]).float()\n","    \n","        return x,y"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"psP0nwMNE9yv","executionInfo":{"status":"ok","timestamp":1619907489362,"user_tz":240,"elapsed":1923,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["def make_dataloader(dataset, train, batch_size):\n","  if train:\n","    shuffle = True\n","    drop_last = True\n","  else:\n","    shuffle = False\n","    drop_last = False\n","    \n","  loader = DataLoader(dataset=dataset, batch_size=batch_size,\n","                      drop_last=drop_last, shuffle=shuffle,\n","                      pin_memory=True, num_workers=8)\n","  \n","  return loader"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"--p_S9L8GWRd","executionInfo":{"status":"ok","timestamp":1619907489363,"user_tz":240,"elapsed":1750,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["class SpecializedShallowDetector(nn.Module):\n","  \n","  def __init__(self, hidden_size, activation):\n","    super(SpecializedShallowDetector, self).__init__()\n","    \n","    self.linear_layer = nn.Linear(in_features=40, out_features=hidden_size)\n","    self.bn_layer = nn.BatchNorm1d(num_features=hidden_size)\n","    self.activation = activation\n","    self.output_layer = nn.Linear(in_features=hidden_size, out_features=1)\n","    self.sigmoid = nn.Sigmoid()\n","    seq_params = [\n","      self.linear_layer,\n","      self.bn_layer,\n","      self.activation,\n","      self.output_layer,\n","      self.sigmoid\n","    ]\n","\n","    self.network = nn.Sequential(*seq_params)\n","    \n","  def forward(self, x):\n","    return self.network(x)"],"execution_count":90,"outputs":[]},{"cell_type":"code","metadata":{"id":"KNhuSUg0_5sH","executionInfo":{"status":"ok","timestamp":1619907489452,"user_tz":240,"elapsed":1642,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["class SpecializedDetector():\n","\n","  def __init__(self, task_name, phonemes_class_0, phonemes_class_1):\n","    self.task_name = task_name\n","\n","    train_data = SpecializedDataset(datapath=datapath, mode=\"train\", \n","                                    task_name=task_name, \n","                                    phonemes_class_0=phonemes_class_0, \n","                                    phonemes_class_1=phonemes_class_1)\n","    self.train_loader = make_dataloader(dataset=train_data, train=True, batch_size=BATCH_SIZE)\n","\n","    dev_data = SpecializedDataset(datapath=datapath, mode=\"dev\", \n","                                  task_name=task_name, \n","                                  phonemes_class_0=phonemes_class_0, \n","                                  phonemes_class_1=phonemes_class_1)\n","    self.dev_loader = make_dataloader(dataset=dev_data, train=False, batch_size=BATCH_SIZE)\n","\n","    self.model = SpecializedShallowDetector(hidden_size=HIDDEN_SIZE, \n","                                            activation=nn.LeakyReLU()).to(DEVICE)\n","    self.criterion = nn.BCELoss()\n","    self.optimizer = torch.optim.SGD(self.model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n","    self.scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, 'min')\n","\n","    self.train_loss_per_epoch = []\n","    self.train_acc_per_epoch = []\n","    self.dev_loss_per_epoch = []\n","    self.dev_acc_per_epoch = []\n","  \n","  def save_model(self, epoch):\n","    model_epoch_path = \"{}/models/model_{}_{}_{}\".format(output_path, self.task_name, \n","                                                         MODEL_VERSION, epoch)\n","    torch.save({\n","        'model_state_dict': self.model.state_dict(),\n","        'optimizer_state_dict': self.optimizer.state_dict(),\n","        'scheduler_state_dict': self.scheduler.state_dict(),\n","    }, model_epoch_path)\n","    # print('saved model: {}'.format(model_epoch_path))\n","\n","  def train(self, epochs):\n","    # Run training and track with wandb\n","    total_batches = len(self.train_loader) * epochs\n","    example_ct = 0  # number of examples seen\n","    batch_ct = 0\n","\n","    for epoch in tqdm(range(epochs)):\n","        train_loss = 0.0\n","        start_time = time.time()\n","        total_predictions = 0\n","        correct_predictions = 0\n","\n","        true_labels = []\n","        predictions = []\n","        for _, (features, targets) in enumerate(self.train_loader):\n","            batch_loss, outputs = self.train_batch(features, targets)\n","            train_loss += batch_loss\n","\n","            example_ct += len(features)\n","            batch_ct += 1\n","\n","            targets = targets.reshape(-1, 1)\n","\n","            # check number of correct predictions\n","            output_classes = torch.where(outputs > LOGISTIC_THRESHOLD, 1, 0).detach().cpu() # convert to class labels\n","            total_predictions += len(output_classes)\n","            correct_predictions += torch.sum(targets == output_classes)\n","\n","            true_labels += list(targets)\n","            predictions += list(output_classes)\n","\n","        end_time = time.time()\n","\n","        train_loss /= example_ct\n","        print(f\"training loss: {train_loss}; time: {end_time - start_time}s\")\n","        \n","        if (epoch + 1) % 10 == 0 or epoch == (epochs - 1):\n","          report = classification_report(true_labels, predictions, output_dict=True)\n","          df = pd.DataFrame(report).transpose()\n","          df.to_csv(f\"{output_path}/reports/train_{self.task_name}_{MODEL_VERSION}_{epoch + 1}.csv\", index=False)\n","\n","        print(classification_report(true_labels, predictions))\n","        print(confusion_matrix(true_labels, predictions))\n","\n","        self.train_loss_per_epoch.append(train_loss)\n","        #self.train_acc_per_epoch.append(train_acc)\n","\n","        # evaluate model with validation data\n","        dev_loss = self.evaluate_model(epoch)\n","        \n","        self.dev_loss_per_epoch.append(dev_loss)\n","        #self.dev_acc_per_epoch.append(dev_acc)\n","\n","        # Step with the scheduler\n","        self.scheduler.step(dev_loss)\n","      \n","    # epoch completed, save model\n","    self.save_model(epoch)\n","\n","  def train_batch(self, features, targets):\n","    features, targets = features.to(DEVICE), targets.to(DEVICE)\n","    targets = targets.reshape(-1, 1)\n","\n","    self.optimizer.zero_grad()\n","\n","    # Forward pass ➡\n","    outputs = self.model(features)\n","    loss = self.criterion(outputs, targets)  # compare with target outputs\n","    # Backward pass ⬅\n","    loss.backward()\n","    # Step with optimizer\n","    self.optimizer.step()\n","\n","    return loss.item(), outputs\n","\n","  def evaluate_model(self, epoch):\n","\n","    with torch.no_grad():\n","      self.model.eval()\n","\n","      running_loss = 0.0\n","      total_predictions = 0.0\n","      correct_predictions = 0.0\n","\n","      true_labels = []\n","      predictions = []\n","\n","      example_ct = 0\n","      start_time = time.time()\n","      for batch_idx, (features, targets) in enumerate(self.dev_loader):\n","        features = features.to(DEVICE)\n","        targets = targets.to(DEVICE)\n","        targets = targets.reshape(-1, 1)\n","\n","        example_ct += len(features)\n","\n","        outputs = self.model(features)\n","        outputs = outputs.to(DEVICE)\n","\n","        # check number of correct predictions\n","        output_classes = torch.where(outputs > LOGISTIC_THRESHOLD, 1, 0)  # convert to class labels\n","        total_predictions += len(output_classes)\n","        correct_predictions += torch.sum(targets == output_classes)\n","\n","        loss = self.criterion(outputs, targets).detach()\n","        running_loss += loss.item()\n","\n","        true_labels += list(targets.detach().cpu())\n","        predictions += list(output_classes.detach().cpu())\n","      \n","      end_time = time.time()\n","\n","      running_loss /= example_ct\n","      print(f\"testing loss: {running_loss}; time: {end_time - start_time}s\")\n","\n","      if (epoch + 1) % 10 == 0:\n","        report = classification_report(true_labels, predictions, output_dict=True)\n","        df = pd.DataFrame(report).transpose()\n","        df.to_csv(f\"{output_path}/reports/reports_dev_{self.task_name}_{MODEL_VERSION}_{epoch + 1}.csv\", index=False)\n","  \n","      print(classification_report(true_labels, predictions))\n","      print(confusion_matrix(true_labels, predictions))\n","      return running_loss"],"execution_count":91,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmgukhuSqx7q"},"source":["## 2. Training shallow detectors (per phoneme + one for silence)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9RgaXKNzySdO","executionInfo":{"status":"ok","timestamp":1619907489452,"user_tz":240,"elapsed":1051,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"37b8dd36-57f1-4134-b896-4e1272d5f6c4"},"source":["%cd /content/gdrive/MyDrive/Spring_2021/11785_Intro_to_Deep_Learning/dl-group-project-code/utilities"],"execution_count":92,"outputs":[{"output_type":"stream","text":["/content/gdrive/MyDrive/Spring_2021/11785_Intro_to_Deep_Learning/dl-group-project-code/utilities\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tjbfaEh8yYL1","executionInfo":{"status":"ok","timestamp":1619907489453,"user_tz":240,"elapsed":762,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}}},"source":["from utilities import SPECIALIZED_TASKS"],"execution_count":93,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N7TH0JJh3QiH","executionInfo":{"status":"ok","timestamp":1619907489551,"user_tz":240,"elapsed":571,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"af421cd1-da57-42c9-dd87-5f8cde47ca2a"},"source":["%cd /"],"execution_count":94,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M3TvLFZBygZ4","executionInfo":{"status":"ok","timestamp":1619907489551,"user_tz":240,"elapsed":254,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"494b405c-508e-4cac-d9b7-530d972beeec"},"source":["print(SPECIALIZED_TASKS)"],"execution_count":95,"outputs":[{"output_type":"stream","text":["{'1_vowel_vs_consonant': {0: ['EE', 'IH', 'EH', 'AE', 'UH', 'ER', 'AH', 'AW', 'OO', 'UE'], 1: ['FF', 'HH', 'MM', 'NN', 'NG', 'RR', 'SS', 'SH', 'VV', 'WW', 'YY', 'ZZ']}, '3_highvowel_vs_lowvowel': {0: ['EE', 'IH', 'UE', 'OO'], 1: ['AE', 'AH', 'AW']}, '4_voiced_vs_unvoiced_fricatives': {0: ['DH', 'VV', 'ZZ'], 1: ['FF', 'SS', 'SH', 'TH']}, '5_ss_vs_zz': {0: ['SS'], 1: ['ZZ']}, '6_b_vs_p': {0: ['B'], 1: ['P']}, '7_dh_vs_th': {0: ['DH'], 1: ['TH']}, '8_ww_vs_yy': {0: ['WW'], 1: ['YY']}, '9_ee_vs_aw': {0: ['EE'], 1: ['AW']}, '10_ah_vs_aw': {0: ['AH'], 1: ['AW']}, '11_mm_vs_nn': {0: ['AH'], 1: ['AW']}}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mvRk8m8CLwGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619909930712,"user_tz":240,"elapsed":387422,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"989be797-d8f4-4d16-d778-a9d790d5eaa6"},"source":["not_trained = []\n","for task_name, classes_dict in SPECIALIZED_TASKS.items():\n","  try:\n","    detector = SpecializedDetector(task_name, classes_dict[0], classes_dict[1])\n","    detector.train(epochs=NUM_EPOCHS)\n","  except Exception as e:\n","    not_trained.append((task_name, str(e)))"],"execution_count":99,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["[task=1_vowel_vs_consonant] (12664, 40) features\n","[task=1_vowel_vs_consonant] (12664,) labels\n","[task=3_highvowel_vs_lowvowel] (4304, 40) features\n","[task=3_highvowel_vs_lowvowel] (4304,) labels\n","[task=3_highvowel_vs_lowvowel] (1065, 40) features\n","[task=3_highvowel_vs_lowvowel] (1065,) labels\n","training loss: 0.004561724262868068; time: 0.8154335021972656s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.95      0.91      2548\n","         1.0       0.91      0.81      0.86      1740\n","\n","    accuracy                           0.89      4288\n","   macro avg       0.90      0.88      0.88      4288\n","weighted avg       0.89      0.89      0.89      4288\n","\n","[[2410  138]\n"," [ 331 1409]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:44,  1.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003064388337549469; time: 0.550633430480957s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      1.00      0.94       616\n","         1.0       0.99      0.83      0.90       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.94      0.91      0.92      1065\n","weighted avg       0.93      0.92      0.92      1065\n","\n","[[613   3]\n"," [ 78 371]]\n","training loss: 0.002226301412438668; time: 0.7502002716064453s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.91      2543\n","         1.0       0.87      0.86      0.86      1745\n","\n","    accuracy                           0.89      4288\n","   macro avg       0.89      0.89      0.89      4288\n","weighted avg       0.89      0.89      0.89      4288\n","\n","[[2323  220]\n"," [ 248 1497]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:42,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003256545820986161; time: 0.5347650051116943s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.98      0.93       616\n","         1.0       0.96      0.84      0.90       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.93      0.91      0.92      1065\n","weighted avg       0.92      0.92      0.92      1065\n","\n","[[602  14]\n"," [ 70 379]]\n","training loss: 0.0010774259823860962; time: 0.7358226776123047s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94      2544\n","         1.0       0.92      0.89      0.90      1744\n","\n","    accuracy                           0.92      4288\n","   macro avg       0.92      0.92      0.92      4288\n","weighted avg       0.92      0.92      0.92      4288\n","\n","[[2401  143]\n"," [ 185 1559]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:40,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003913723189436214; time: 0.5429067611694336s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.99      0.93       616\n","         1.0       0.99      0.81      0.89       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.93      0.90      0.91      1065\n","weighted avg       0.93      0.92      0.92      1065\n","\n","[[612   4]\n"," [ 84 365]]\n","training loss: 0.0008205266064727929; time: 0.7491128444671631s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.93      2545\n","         1.0       0.91      0.89      0.90      1743\n","\n","    accuracy                           0.92      4288\n","   macro avg       0.92      0.92      0.92      4288\n","weighted avg       0.92      0.92      0.92      4288\n","\n","[[2393  152]\n"," [ 192 1551]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:06<00:39,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0026724121974947305; time: 0.6711645126342773s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.98      0.95       616\n","         1.0       0.97      0.87      0.92       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.94      0.93      0.93      1065\n","weighted avg       0.94      0.93      0.93      1065\n","\n","[[604  12]\n"," [ 58 391]]\n","training loss: 0.0005587098577907726; time: 0.752265453338623s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.95      0.94      2546\n","         1.0       0.92      0.90      0.91      1742\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.92      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2414  132]\n"," [ 171 1571]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:37,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0026485270632544593; time: 0.5352437496185303s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.94      0.94       616\n","         1.0       0.92      0.92      0.92       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.93      0.93      0.93      1065\n","weighted avg       0.93      0.93      0.93      1065\n","\n","[[582  34]\n"," [ 37 412]]\n","training loss: 0.00044564383387662917; time: 0.755396842956543s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.95      0.94      2546\n","         1.0       0.93      0.90      0.92      1742\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2430  116]\n"," [ 173 1569]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:08<00:35,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0026682692514338963; time: 0.5375864505767822s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.96      0.94       616\n","         1.0       0.94      0.90      0.92       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.93      0.93      0.93      1065\n","weighted avg       0.93      0.93      0.93      1065\n","\n","[[589  27]\n"," [ 44 405]]\n","training loss: 0.00040072363628539196; time: 0.770200252532959s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94      2543\n","         1.0       0.92      0.91      0.92      1745\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2410  133]\n"," [ 160 1585]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:10<00:34,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0025460618202675115; time: 0.5596230030059814s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.96      0.95       616\n","         1.0       0.94      0.91      0.92       449\n","\n","    accuracy                           0.94      1065\n","   macro avg       0.94      0.93      0.94      1065\n","weighted avg       0.94      0.94      0.94      1065\n","\n","[[592  24]\n"," [ 42 407]]\n","training loss: 0.00027912487288930024; time: 0.7596049308776855s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2546\n","         1.0       0.94      0.92      0.93      1742\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.94      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2448   98]\n"," [ 145 1597]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:11<00:32,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003142852374645466; time: 0.5354840755462646s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.86      0.91       616\n","         1.0       0.83      0.96      0.89       449\n","\n","    accuracy                           0.90      1065\n","   macro avg       0.90      0.91      0.90      1065\n","weighted avg       0.91      0.90      0.90      1065\n","\n","[[527  89]\n"," [ 18 431]]\n","training loss: 0.00029650389697174134; time: 0.7417690753936768s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94      2549\n","         1.0       0.93      0.91      0.92      1739\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2427  122]\n"," [ 164 1575]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:13<00:31,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004115601571303019; time: 0.5461649894714355s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      1.00      0.92       616\n","         1.0       1.00      0.78      0.87       449\n","\n","    accuracy                           0.91      1065\n","   macro avg       0.93      0.89      0.90      1065\n","weighted avg       0.92      0.91      0.90      1065\n","\n","[[616   0]\n"," [101 348]]\n","training loss: 0.0003224075810094155; time: 0.7621312141418457s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.95      0.94      2544\n","         1.0       0.92      0.89      0.90      1744\n","\n","    accuracy                           0.92      4288\n","   macro avg       0.92      0.92      0.92      4288\n","weighted avg       0.92      0.92      0.92      4288\n","\n","[[2406  138]\n"," [ 190 1554]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:14<00:30,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003152339779575106; time: 0.5394167900085449s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.99      0.94       616\n","         1.0       0.98      0.83      0.90       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.93      0.91      0.92      1065\n","weighted avg       0.93      0.92      0.92      1065\n","\n","[[609   7]\n"," [ 77 372]]\n","training loss: 0.00022912702279600088; time: 0.753434419631958s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2543\n","         1.0       0.94      0.91      0.92      1745\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.93      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2440  103]\n"," [ 164 1581]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:16<00:28,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003128178253280165; time: 0.5706162452697754s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.88      0.91       616\n","         1.0       0.85      0.94      0.89       449\n","\n","    accuracy                           0.91      1065\n","   macro avg       0.90      0.91      0.90      1065\n","weighted avg       0.91      0.91      0.91      1065\n","\n","[[540  76]\n"," [ 25 424]]\n","training loss: 0.00022434382768931675; time: 0.7546474933624268s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94      2547\n","         1.0       0.92      0.91      0.92      1741\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2416  131]\n"," [ 161 1580]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:17<00:27,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0027538061929000936; time: 0.5658001899719238s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.99      0.94       616\n","         1.0       0.98      0.85      0.91       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.94      0.92      0.93      1065\n","weighted avg       0.93      0.93      0.93      1065\n","\n","[[608   8]\n"," [ 67 382]]\n","training loss: 0.0001712797082512587; time: 0.7801218032836914s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2547\n","         1.0       0.94      0.91      0.93      1741\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.94      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2454   93]\n"," [ 152 1589]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:19<00:25,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004770916661885983; time: 0.5802633762359619s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.75      0.86       616\n","         1.0       0.74      0.99      0.85       449\n","\n","    accuracy                           0.85      1065\n","   macro avg       0.87      0.87      0.85      1065\n","weighted avg       0.89      0.85      0.85      1065\n","\n","[[463 153]\n"," [  4 445]]\n","training loss: 0.00017513055695659682; time: 0.9088039398193359s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94      2545\n","         1.0       0.92      0.91      0.92      1743\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2413  132]\n"," [ 150 1593]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:21<00:24,  1.56s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004706360694860488; time: 0.5661332607269287s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      1.00      0.92       616\n","         1.0       1.00      0.76      0.86       449\n","\n","    accuracy                           0.90      1065\n","   macro avg       0.93      0.88      0.89      1065\n","weighted avg       0.91      0.90      0.90      1065\n","\n","[[616   0]\n"," [108 341]]\n","training loss: 0.0001510329682389228; time: 0.776132345199585s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2545\n","         1.0       0.94      0.91      0.92      1743\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.93      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2440  105]\n"," [ 160 1583]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:22<00:23,  1.54s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00314267689423382; time: 0.5590043067932129s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.84      0.90       616\n","         1.0       0.82      0.96      0.89       449\n","\n","    accuracy                           0.89      1065\n","   macro avg       0.89      0.90      0.89      1065\n","weighted avg       0.91      0.89      0.90      1065\n","\n","[[520  96]\n"," [ 16 433]]\n","training loss: 0.00013039709198498861; time: 0.7703664302825928s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2545\n","         1.0       0.95      0.92      0.94      1743\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2457   88]\n"," [ 134 1609]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:24<00:21,  1.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002373944383831651; time: 0.5650856494903564s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.95       616\n","         1.0       0.95      0.91      0.93       449\n","\n","    accuracy                           0.94      1065\n","   macro avg       0.94      0.94      0.94      1065\n","weighted avg       0.94      0.94      0.94      1065\n","\n","[[595  21]\n"," [ 40 409]]\n","training loss: 0.00012221227980957182; time: 0.7602086067199707s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.96      2545\n","         1.0       0.95      0.93      0.94      1743\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.95      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2452   93]\n"," [ 124 1619]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:25<00:19,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003986743306784842; time: 0.5555346012115479s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      1.00      0.93       616\n","         1.0       0.99      0.80      0.89       449\n","\n","    accuracy                           0.91      1065\n","   macro avg       0.93      0.90      0.91      1065\n","weighted avg       0.92      0.91      0.91      1065\n","\n","[[614   2]\n"," [ 91 358]]\n","training loss: 0.00013699008262512362; time: 0.7718524932861328s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95      2545\n","         1.0       0.93      0.91      0.92      1743\n","\n","    accuracy                           0.93      4288\n","   macro avg       0.93      0.93      0.93      4288\n","weighted avg       0.93      0.93      0.93      4288\n","\n","[[2428  117]\n"," [ 165 1578]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:27<00:18,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0029944818222047017; time: 0.5474536418914795s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      1.00      0.93       616\n","         1.0       1.00      0.80      0.89       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.94      0.90      0.91      1065\n","weighted avg       0.93      0.92      0.91      1065\n","\n","[[615   1]\n"," [ 89 360]]\n","training loss: 0.00010063635492722965; time: 0.746649980545044s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2545\n","         1.0       0.95      0.93      0.94      1743\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.95      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2468   77]\n"," [ 129 1614]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:28<00:16,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002825288387111655; time: 0.5588052272796631s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.86      0.91       616\n","         1.0       0.83      0.96      0.89       449\n","\n","    accuracy                           0.90      1065\n","   macro avg       0.90      0.91      0.90      1065\n","weighted avg       0.91      0.90      0.90      1065\n","\n","[[530  86]\n"," [ 20 429]]\n","training loss: 0.00010730913004476521; time: 0.7500507831573486s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2545\n","         1.0       0.94      0.91      0.93      1743\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.94      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2450   95]\n"," [ 157 1586]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:30<00:15,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002538375233785367; time: 0.5484910011291504s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.99      0.95       616\n","         1.0       0.98      0.86      0.92       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.94      0.92      0.93      1065\n","weighted avg       0.94      0.93      0.93      1065\n","\n","[[610   6]\n"," [ 65 384]]\n","training loss: 0.00010978487099659203; time: 0.7430551052093506s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95      2544\n","         1.0       0.94      0.91      0.92      1744\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.94      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2437  107]\n"," [ 153 1591]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:31<00:13,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002505992853165792; time: 0.5505082607269287s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.99      0.94       616\n","         1.0       0.99      0.85      0.91       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.94      0.92      0.93      1065\n","weighted avg       0.94      0.93      0.93      1065\n","\n","[[611   5]\n"," [ 67 382]]\n","training loss: 9.569037662853146e-05; time: 0.7819747924804688s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.95      2544\n","         1.0       0.94      0.92      0.93      1744\n","\n","    accuracy                           0.94      4288\n","   macro avg       0.94      0.94      0.94      4288\n","weighted avg       0.94      0.94      0.94      4288\n","\n","[[2442  102]\n"," [ 140 1604]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:33<00:12,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0026461078247553864; time: 0.5581774711608887s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.89      0.92       616\n","         1.0       0.86      0.95      0.90       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.91      0.92      0.91      1065\n","weighted avg       0.92      0.92      0.92      1065\n","\n","[[548  68]\n"," [ 22 427]]\n","training loss: 8.087879382445563e-05; time: 0.8664736747741699s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.96      2546\n","         1.0       0.95      0.92      0.93      1742\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2467   79]\n"," [ 145 1597]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:34<00:10,  1.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0025890129552760596; time: 0.5573146343231201s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.99      0.94       616\n","         1.0       0.98      0.86      0.91       449\n","\n","    accuracy                           0.93      1065\n","   macro avg       0.94      0.92      0.93      1065\n","weighted avg       0.93      0.93      0.93      1065\n","\n","[[607   9]\n"," [ 65 384]]\n","training loss: 9.190029814632017e-05; time: 0.7828092575073242s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2546\n","         1.0       0.95      0.92      0.93      1742\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2460   86]\n"," [ 138 1604]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:36<00:09,  1.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002510253710785942; time: 0.5727076530456543s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.95       616\n","         1.0       0.95      0.91      0.93       449\n","\n","    accuracy                           0.94      1065\n","   macro avg       0.95      0.94      0.94      1065\n","weighted avg       0.94      0.94      0.94      1065\n","\n","[[596  20]\n"," [ 40 409]]\n","training loss: 8.595977221796317e-05; time: 0.7667016983032227s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.95      2548\n","         1.0       0.94      0.92      0.93      1740\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.94      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2450   98]\n"," [ 135 1605]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:37<00:07,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0022914570594477542; time: 0.5467076301574707s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.95       616\n","         1.0       0.96      0.91      0.93       449\n","\n","    accuracy                           0.95      1065\n","   macro avg       0.95      0.94      0.94      1065\n","weighted avg       0.95      0.95      0.95      1065\n","\n","[[600  16]\n"," [ 41 408]]\n","training loss: 7.561243117287602e-05; time: 0.7719919681549072s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.96      2547\n","         1.0       0.95      0.92      0.93      1741\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.94      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2464   83]\n"," [ 145 1596]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:39<00:06,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0025599037607510885; time: 0.561215877532959s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.91      0.93       616\n","         1.0       0.88      0.94      0.91       449\n","\n","    accuracy                           0.92      1065\n","   macro avg       0.92      0.93      0.92      1065\n","weighted avg       0.93      0.92      0.92      1065\n","\n","[[561  55]\n"," [ 26 423]]\n","training loss: 6.815237502491276e-05; time: 0.7707116603851318s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2543\n","         1.0       0.96      0.92      0.94      1745\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.95      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2469   74]\n"," [ 133 1612]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:40<00:04,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002313635932028014; time: 0.5500710010528564s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.98      0.95       616\n","         1.0       0.97      0.89      0.93       449\n","\n","    accuracy                           0.94      1065\n","   macro avg       0.95      0.94      0.94      1065\n","weighted avg       0.94      0.94      0.94      1065\n","\n","[[604  12]\n"," [ 49 400]]\n","training loss: 6.712989895969435e-05; time: 0.7691471576690674s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2548\n","         1.0       0.96      0.92      0.94      1740\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.95      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2479   69]\n"," [ 143 1597]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:42<00:03,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003299142093235898; time: 0.5711297988891602s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.83      0.90       616\n","         1.0       0.81      0.98      0.89       449\n","\n","    accuracy                           0.89      1065\n","   macro avg       0.90      0.90      0.89      1065\n","weighted avg       0.91      0.89      0.89      1065\n","\n","[[514 102]\n"," [ 11 438]]\n","training loss: 6.563850596779118e-05; time: 0.7628839015960693s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.96      2552\n","         1.0       0.95      0.91      0.93      1736\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.94      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2471   81]\n"," [ 149 1587]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:43<00:01,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0022405262704186597; time: 0.5881357192993164s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.95       616\n","         1.0       0.95      0.91      0.93       449\n","\n","    accuracy                           0.94      1065\n","   macro avg       0.94      0.94      0.94      1065\n","weighted avg       0.94      0.94      0.94      1065\n","\n","[[596  20]\n"," [ 41 408]]\n","training loss: 6.743580382664813e-05; time: 0.786733865737915s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96      2544\n","         1.0       0.95      0.92      0.93      1744\n","\n","    accuracy                           0.95      4288\n","   macro avg       0.95      0.94      0.95      4288\n","weighted avg       0.95      0.95      0.95      4288\n","\n","[[2456   88]\n"," [ 138 1606]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:45<00:00,  1.52s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00255941015803758; time: 0.5654411315917969s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.89      0.92       616\n","         1.0       0.86      0.95      0.90       449\n","\n","    accuracy                           0.91      1065\n","   macro avg       0.91      0.92      0.91      1065\n","weighted avg       0.92      0.91      0.91      1065\n","\n","[[547  69]\n"," [ 22 427]]\n","[task=4_voiced_vs_unvoiced_fricatives] (4633, 40) features\n","[task=4_voiced_vs_unvoiced_fricatives] (4633,) labels\n","[task=4_voiced_vs_unvoiced_fricatives] (1116, 40) features\n","[task=4_voiced_vs_unvoiced_fricatives] (1116,) labels\n","training loss: 0.004953575789436905; time: 0.7990396022796631s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.83      0.84      2047\n","         1.0       0.87      0.89      0.88      2561\n","\n","    accuracy                           0.86      4608\n","   macro avg       0.86      0.86      0.86      4608\n","weighted avg       0.86      0.86      0.86      4608\n","\n","[[1704  343]\n"," [ 284 2277]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:48,  1.66s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004363286145378612; time: 0.6920368671417236s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.92      0.86       463\n","         1.0       0.94      0.84      0.89       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.87      0.88      0.87      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[428  35]\n"," [104 549]]\n","training loss: 0.0030584699804118523; time: 0.8001470565795898s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.81      0.82      2045\n","         1.0       0.85      0.87      0.86      2563\n","\n","    accuracy                           0.84      4608\n","   macro avg       0.84      0.84      0.84      4608\n","weighted avg       0.84      0.84      0.84      4608\n","\n","[[1653  392]\n"," [ 327 2236]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:03<00:45,  1.63s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004577386870606399; time: 0.5572290420532227s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.82      0.85       463\n","         1.0       0.88      0.92      0.90       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.88      0.87      0.87      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[379  84]\n"," [ 53 600]]\n","training loss: 0.001252513046859315; time: 0.7794058322906494s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.87      0.88      2048\n","         1.0       0.90      0.91      0.90      2560\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1787  261]\n"," [ 230 2330]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:43,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0043603255476896054; time: 0.5605947971343994s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.81      0.86       463\n","         1.0       0.87      0.94      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.89      0.88      0.88      1116\n","weighted avg       0.89      0.89      0.89      1116\n","\n","[[375  88]\n"," [ 39 614]]\n","training loss: 0.0009313003360552506; time: 0.8176679611206055s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.87      0.88      2044\n","         1.0       0.90      0.91      0.91      2564\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1782  262]\n"," [ 227 2337]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:06<00:41,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0051840272495075794; time: 0.5834283828735352s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.98      0.82       463\n","         1.0       0.98      0.71      0.82       653\n","\n","    accuracy                           0.82      1116\n","   macro avg       0.84      0.85      0.82      1116\n","weighted avg       0.87      0.82      0.82      1116\n","\n","[[455   8]\n"," [189 464]]\n","training loss: 0.0008240113597518454; time: 0.7853572368621826s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.85      0.85      2046\n","         1.0       0.88      0.89      0.88      2562\n","\n","    accuracy                           0.87      4608\n","   macro avg       0.87      0.87      0.87      4608\n","weighted avg       0.87      0.87      0.87      4608\n","\n","[[1745  301]\n"," [ 291 2271]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:39,  1.57s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004620388367189942; time: 0.5554587841033936s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.73      0.83       463\n","         1.0       0.84      0.98      0.90       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.90      0.86      0.87      1116\n","weighted avg       0.89      0.88      0.87      1116\n","\n","[[340 123]\n"," [ 15 638]]\n","training loss: 0.0005805535663428061; time: 0.8133566379547119s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.88      0.89      2044\n","         1.0       0.90      0.92      0.91      2564\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1794  250]\n"," [ 215 2349]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:09<00:37,  1.57s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004715720979383342; time: 0.5630242824554443s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.97      0.83       463\n","         1.0       0.97      0.74      0.84       653\n","\n","    accuracy                           0.84      1116\n","   macro avg       0.85      0.86      0.84      1116\n","weighted avg       0.87      0.84      0.84      1116\n","\n","[[450  13]\n"," [170 483]]\n","training loss: 0.0005105830888847806; time: 0.7893753051757812s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.87      0.87      2048\n","         1.0       0.89      0.90      0.90      2560\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.88      0.88      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1773  275]\n"," [ 248 2312]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:10<00:35,  1.56s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004986268651795216; time: 0.5594372749328613s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.97      0.82       463\n","         1.0       0.97      0.72      0.83       653\n","\n","    accuracy                           0.83      1116\n","   macro avg       0.84      0.85      0.83      1116\n","weighted avg       0.86      0.83      0.83      1116\n","\n","[[449  14]\n"," [181 472]]\n","training loss: 0.00046118398636786477; time: 0.7921180725097656s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.87      0.87      2044\n","         1.0       0.90      0.89      0.89      2564\n","\n","    accuracy                           0.88      4608\n","   macro avg       0.88      0.88      0.88      4608\n","weighted avg       0.88      0.88      0.88      4608\n","\n","[[1781  263]\n"," [ 283 2281]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:12<00:34,  1.55s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00412455809346023; time: 0.5616955757141113s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.79      0.94      0.86       463\n","         1.0       0.95      0.82      0.88       653\n","\n","    accuracy                           0.87      1116\n","   macro avg       0.87      0.88      0.87      1116\n","weighted avg       0.88      0.87      0.87      1116\n","\n","[[435  28]\n"," [119 534]]\n","training loss: 0.00039727366881525536; time: 0.8949730396270752s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.87      0.88      2043\n","         1.0       0.90      0.91      0.90      2565\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1779  264]\n"," [ 238 2327]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:14<00:33,  1.58s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004034456553264758; time: 0.56569504737854s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.89      0.86       463\n","         1.0       0.92      0.87      0.89       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.87      0.88      0.87      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[414  49]\n"," [ 88 565]]\n","training loss: 0.00035587608969459933; time: 0.7929716110229492s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.87      0.88      2045\n","         1.0       0.90      0.91      0.90      2563\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1777  268]\n"," [ 236 2327]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:15<00:32,  1.60s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004593281108739128; time: 0.5748507976531982s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.98      0.84       463\n","         1.0       0.98      0.74      0.84       653\n","\n","    accuracy                           0.84      1116\n","   macro avg       0.86      0.86      0.84      1116\n","weighted avg       0.88      0.84      0.84      1116\n","\n","[[455   8]\n"," [171 482]]\n","training loss: 0.0003098446265512118; time: 0.8018045425415039s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.87      0.88      2043\n","         1.0       0.90      0.91      0.91      2565\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1784  259]\n"," [ 223 2342]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:17<00:30,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004282752726240398; time: 0.5776069164276123s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.77      0.85       463\n","         1.0       0.86      0.97      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.90      0.87      0.88      1116\n","weighted avg       0.90      0.89      0.89      1116\n","\n","[[356 107]\n"," [ 18 635]]\n","training loss: 0.000286102987081028; time: 0.8120968341827393s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.88      0.87      2040\n","         1.0       0.90      0.90      0.90      2568\n","\n","    accuracy                           0.89      4608\n","   macro avg       0.89      0.89      0.89      4608\n","weighted avg       0.89      0.89      0.89      4608\n","\n","[[1793  247]\n"," [ 267 2301]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:18<00:28,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004392178538906318; time: 0.579819917678833s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.74      0.83       463\n","         1.0       0.84      0.98      0.90       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.90      0.86      0.87      1116\n","weighted avg       0.89      0.88      0.87      1116\n","\n","[[341 122]\n"," [ 14 639]]\n","training loss: 0.000258641471587814; time: 0.8173954486846924s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.88      0.89      2046\n","         1.0       0.90      0.92      0.91      2562\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1791  255]\n"," [ 198 2364]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:20<00:27,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003929145801078034; time: 0.5927639007568359s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.89      0.86       463\n","         1.0       0.92      0.87      0.89       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.88      0.88      0.88      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[412  51]\n"," [ 83 570]]\n","training loss: 0.0002290419098922968; time: 0.8172810077667236s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89      2041\n","         1.0       0.91      0.91      0.91      2567\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1809  232]\n"," [ 225 2342]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:22<00:25,  1.58s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00452110599926723; time: 0.573512077331543s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.76      0.85       463\n","         1.0       0.85      0.97      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.90      0.87      0.88      1116\n","weighted avg       0.89      0.89      0.88      1116\n","\n","[[353 110]\n"," [ 18 635]]\n","training loss: 0.00021461648413807983; time: 0.8083853721618652s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89      2044\n","         1.0       0.91      0.92      0.92      2564\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.90      0.90      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1818  226]\n"," [ 206 2358]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:23<00:23,  1.58s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003956621365895408; time: 0.5757195949554443s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.89      0.87       463\n","         1.0       0.92      0.88      0.90       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.88      0.89      0.88      1116\n","weighted avg       0.89      0.89      0.89      1116\n","\n","[[414  49]\n"," [ 77 576]]\n","training loss: 0.00019294881227930696; time: 0.8097236156463623s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.90      2047\n","         1.0       0.91      0.92      0.92      2561\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1817  230]\n"," [ 193 2368]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:25<00:22,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004012900962090407; time: 0.5993149280548096s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.85      0.86       463\n","         1.0       0.89      0.91      0.90       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.88      0.88      0.88      1116\n","weighted avg       0.89      0.89      0.89      1116\n","\n","[[392  71]\n"," [ 57 596]]\n","training loss: 0.00018751434182894287; time: 0.8185784816741943s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.88      0.89      2043\n","         1.0       0.91      0.91      0.91      2565\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1802  241]\n"," [ 227 2338]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:26<00:20,  1.60s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0042559720916293; time: 0.6049962043762207s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.77      0.85       463\n","         1.0       0.86      0.98      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.91      0.87      0.88      1116\n","weighted avg       0.90      0.89      0.89      1116\n","\n","[[356 107]\n"," [ 16 637]]\n","training loss: 0.00017675704329582161; time: 0.932323694229126s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89      2045\n","         1.0       0.91      0.92      0.91      2563\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1817  228]\n"," [ 210 2353]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:28<00:19,  1.62s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004296577131662745; time: 0.5742461681365967s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.76      0.84       463\n","         1.0       0.85      0.98      0.91       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.90      0.87      0.88      1116\n","weighted avg       0.89      0.88      0.88      1116\n","\n","[[350 113]\n"," [ 16 637]]\n","training loss: 0.0001631911567613831; time: 0.785003662109375s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.88      0.89      2048\n","         1.0       0.91      0.92      0.92      2560\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1806  242]\n"," [ 197 2363]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:30<00:17,  1.60s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004364458256564687; time: 0.5694522857666016s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.97      0.83       463\n","         1.0       0.97      0.74      0.84       653\n","\n","    accuracy                           0.84      1116\n","   macro avg       0.85      0.86      0.84      1116\n","weighted avg       0.87      0.84      0.84      1116\n","\n","[[449  14]\n"," [167 486]]\n","training loss: 0.00016140048424454612; time: 0.8123137950897217s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.88      0.88      2047\n","         1.0       0.90      0.91      0.91      2561\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1793  254]\n"," [ 220 2341]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:31<00:16,  1.63s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004146450142439548; time: 0.5993010997772217s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.76      0.85       463\n","         1.0       0.85      0.97      0.91       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.90      0.87      0.88      1116\n","weighted avg       0.89      0.88      0.88      1116\n","\n","[[352 111]\n"," [ 18 635]]\n","training loss: 0.00014494518717386262; time: 0.8238506317138672s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.90      2044\n","         1.0       0.92      0.93      0.92      2564\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1824  220]\n"," [ 192 2372]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:33<00:14,  1.61s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004041687435200138; time: 0.5674400329589844s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.94      0.86       463\n","         1.0       0.95      0.83      0.89       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.87      0.89      0.87      1116\n","weighted avg       0.89      0.88      0.88      1116\n","\n","[[436  27]\n"," [112 541]]\n","training loss: 0.0001493456379970244; time: 0.8156704902648926s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.90      0.89      2041\n","         1.0       0.92      0.90      0.91      2567\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1827  214]\n"," [ 244 2323]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:34<00:12,  1.61s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00405157691428578; time: 0.601701021194458s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.89      0.85       463\n","         1.0       0.92      0.85      0.88       653\n","\n","    accuracy                           0.87      1116\n","   macro avg       0.86      0.87      0.86      1116\n","weighted avg       0.87      0.87      0.87      1116\n","\n","[[414  49]\n"," [101 552]]\n","training loss: 0.00013551339329949215; time: 0.8071773052215576s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89      2043\n","         1.0       0.91      0.92      0.92      2565\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1824  219]\n"," [ 211 2354]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:36<00:11,  1.61s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004396515020493111; time: 0.6006827354431152s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.95      0.83       463\n","         1.0       0.96      0.76      0.85       653\n","\n","    accuracy                           0.84      1116\n","   macro avg       0.85      0.86      0.84      1116\n","weighted avg       0.87      0.84      0.84      1116\n","\n","[[440  23]\n"," [154 499]]\n","training loss: 0.00012966382598312553; time: 0.7939791679382324s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89      2044\n","         1.0       0.91      0.91      0.91      2564\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1817  227]\n"," [ 218 2346]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:38<00:09,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003908673548356606; time: 0.5787525177001953s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.87      0.86       463\n","         1.0       0.91      0.89      0.90       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.88      0.88      0.88      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[404  59]\n"," [ 72 581]]\n","training loss: 0.00011877283415136238; time: 0.7990596294403076s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.89      0.90      2042\n","         1.0       0.91      0.93      0.92      2566\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1817  225]\n"," [ 185 2381]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:39<00:08,  1.62s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0040328151823478785; time: 0.7070553302764893s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.84      0.87       463\n","         1.0       0.89      0.93      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.90      0.89      0.89      1116\n","weighted avg       0.89      0.89      0.89      1116\n","\n","[[388  75]\n"," [ 43 610]]\n","training loss: 0.00012086175013240028; time: 0.8220574855804443s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89      2046\n","         1.0       0.91      0.91      0.91      2562\n","\n","    accuracy                           0.90      4608\n","   macro avg       0.90      0.90      0.90      4608\n","weighted avg       0.90      0.90      0.90      4608\n","\n","[[1811  235]\n"," [ 229 2333]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:41<00:06,  1.61s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003975899639709663; time: 0.5777184963226318s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.87      0.86       463\n","         1.0       0.90      0.89      0.90       653\n","\n","    accuracy                           0.88      1116\n","   macro avg       0.88      0.88      0.88      1116\n","weighted avg       0.88      0.88      0.88      1116\n","\n","[[401  62]\n"," [ 72 581]]\n","training loss: 0.00011233846384384229; time: 0.8019871711730957s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.90      2049\n","         1.0       0.91      0.92      0.92      2559\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1826  223]\n"," [ 197 2362]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:42<00:04,  1.60s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004060454119170438; time: 0.5943450927734375s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.92      0.85       463\n","         1.0       0.94      0.83      0.88       653\n","\n","    accuracy                           0.87      1116\n","   macro avg       0.87      0.88      0.87      1116\n","weighted avg       0.88      0.87      0.87      1116\n","\n","[[427  36]\n"," [110 543]]\n","training loss: 0.00010739397117821869; time: 0.8086023330688477s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.88      0.89      2043\n","         1.0       0.91      0.93      0.92      2565\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.90      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1806  237]\n"," [ 192 2373]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:44<00:03,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003956891312581023; time: 0.5764124393463135s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.86      0.87       463\n","         1.0       0.90      0.92      0.91       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.89      0.89      0.89      1116\n","weighted avg       0.89      0.89      0.89      1116\n","\n","[[396  67]\n"," [ 53 600]]\n","training loss: 0.00010124423213961438; time: 0.8126494884490967s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.90      0.90      2046\n","         1.0       0.92      0.93      0.92      2562\n","\n","    accuracy                           0.92      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.92      0.92      0.92      4608\n","\n","[[1842  204]\n"," [ 187 2375]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:46<00:01,  1.59s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004043610883362618; time: 0.5989668369293213s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.83      0.86       463\n","         1.0       0.88      0.93      0.90       653\n","\n","    accuracy                           0.89      1116\n","   macro avg       0.89      0.88      0.88      1116\n","weighted avg       0.89      0.89      0.88      1116\n","\n","[[383  80]\n"," [ 48 605]]\n","training loss: 0.00010071437255074097; time: 0.803624153137207s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.90      0.90      2044\n","         1.0       0.92      0.92      0.92      2564\n","\n","    accuracy                           0.91      4608\n","   macro avg       0.91      0.91      0.91      4608\n","weighted avg       0.91      0.91      0.91      4608\n","\n","[[1832  212]\n"," [ 204 2360]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:47<00:00,  1.59s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004000259563326836; time: 0.5894951820373535s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.91      0.86       463\n","         1.0       0.93      0.85      0.89       653\n","\n","    accuracy                           0.87      1116\n","   macro avg       0.87      0.88      0.87      1116\n","weighted avg       0.88      0.87      0.88      1116\n","\n","[[421  42]\n"," [ 98 555]]\n","[task=5_ss_vs_zz] (1426, 40) features\n","[task=5_ss_vs_zz] (1426,) labels\n","[task=5_ss_vs_zz] (321, 40) features\n","[task=5_ss_vs_zz] (321,) labels\n","training loss: 0.007413104779764332; time: 0.6275174617767334s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.83      0.80       740\n","         1.0       0.80      0.74      0.77       668\n","\n","    accuracy                           0.79      1408\n","   macro avg       0.79      0.79      0.79      1408\n","weighted avg       0.79      0.79      0.79      1408\n","\n","[[615 125]\n"," [174 494]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:36,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01247061501225207; time: 0.5529253482818604s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.69      0.99      0.81       158\n","         1.0       0.99      0.56      0.71       163\n","\n","    accuracy                           0.77       321\n","   macro avg       0.84      0.78      0.76       321\n","weighted avg       0.84      0.77      0.76       321\n","\n","[[157   1]\n"," [ 72  91]]\n","training loss: 0.002870924209921875; time: 0.6320712566375732s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.88      0.88       743\n","         1.0       0.87      0.85      0.86       665\n","\n","    accuracy                           0.87      1408\n","   macro avg       0.87      0.87      0.87      1408\n","weighted avg       0.87      0.87      0.87      1408\n","\n","[[655  88]\n"," [ 97 568]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:35,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.03907988405557251; time: 0.545020341873169s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.59      1.00      0.75       158\n","         1.0       1.00      0.34      0.50       163\n","\n","    accuracy                           0.66       321\n","   macro avg       0.80      0.67      0.62       321\n","weighted avg       0.80      0.66      0.62       321\n","\n","[[158   0]\n"," [108  55]]\n","training loss: 0.0017235544192689385; time: 0.625377893447876s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.88      0.87       744\n","         1.0       0.86      0.84      0.85       664\n","\n","    accuracy                           0.86      1408\n","   macro avg       0.86      0.86      0.86      1408\n","weighted avg       0.86      0.86      0.86      1408\n","\n","[[656  88]\n"," [108 556]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:03<00:33,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005767360608154368; time: 0.5391886234283447s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.89      0.92       158\n","         1.0       0.90      0.97      0.93       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.93      0.93      0.93       321\n","weighted avg       0.93      0.93      0.93       321\n","\n","[[140  18]\n"," [  5 158]]\n","training loss: 0.0007674632718342102; time: 0.6452436447143555s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.92       740\n","         1.0       0.91      0.92      0.91       668\n","\n","    accuracy                           0.92      1408\n","   macro avg       0.92      0.92      0.92      1408\n","weighted avg       0.92      0.92      0.92      1408\n","\n","[[679  61]\n"," [ 55 613]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:32,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.023129047563363366; time: 0.565593957901001s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      1.00      0.82       158\n","         1.0       1.00      0.58      0.73       163\n","\n","    accuracy                           0.79       321\n","   macro avg       0.85      0.79      0.78       321\n","weighted avg       0.85      0.79      0.78       321\n","\n","[[158   0]\n"," [ 69  94]]\n","training loss: 0.0007283683591098948; time: 0.6227331161499023s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.92      0.90       744\n","         1.0       0.91      0.86      0.88       664\n","\n","    accuracy                           0.89      1408\n","   macro avg       0.89      0.89      0.89      1408\n","weighted avg       0.89      0.89      0.89      1408\n","\n","[[684  60]\n"," [ 91 573]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:06<00:31,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004720052373464977; time: 0.5661365985870361s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.86      0.92       158\n","         1.0       0.88      0.99      0.93       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.94      0.93      0.93       321\n","weighted avg       0.94      0.93      0.93       321\n","\n","[[136  22]\n"," [  1 162]]\n","training loss: 0.0006723753679332069; time: 0.638439416885376s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.87      0.88       740\n","         1.0       0.86      0.89      0.87       668\n","\n","    accuracy                           0.88      1408\n","   macro avg       0.88      0.88      0.88      1408\n","weighted avg       0.88      0.88      0.88      1408\n","\n","[[642  98]\n"," [ 74 594]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:07<00:30,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0068651775704737395; time: 0.5485439300537109s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.97      0.88       158\n","         1.0       0.96      0.78      0.86       163\n","\n","    accuracy                           0.87       321\n","   macro avg       0.89      0.87      0.87       321\n","weighted avg       0.89      0.87      0.87       321\n","\n","[[153   5]\n"," [ 36 127]]\n","training loss: 0.0004445952370871681; time: 0.6163241863250732s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.91       742\n","         1.0       0.90      0.89      0.90       666\n","\n","    accuracy                           0.90      1408\n","   macro avg       0.90      0.90      0.90      1408\n","weighted avg       0.90      0.90      0.90      1408\n","\n","[[677  65]\n"," [ 72 594]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:08<00:28,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007547125591667271; time: 0.5479288101196289s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.91      0.93       158\n","         1.0       0.91      0.96      0.93       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.93      0.93      0.93       321\n","weighted avg       0.93      0.93      0.93       321\n","\n","[[143  15]\n"," [  7 156]]\n","training loss: 0.00044160172348545694; time: 0.6213035583496094s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.91      0.91       746\n","         1.0       0.90      0.90      0.90       662\n","\n","    accuracy                           0.91      1408\n","   macro avg       0.91      0.91      0.91      1408\n","weighted avg       0.91      0.91      0.91      1408\n","\n","[[681  65]\n"," [ 65 597]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:10<00:27,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011040171126710291; time: 0.5444691181182861s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      1.00      0.87       158\n","         1.0       1.00      0.71      0.83       163\n","\n","    accuracy                           0.85       321\n","   macro avg       0.89      0.86      0.85       321\n","weighted avg       0.89      0.85      0.85       321\n","\n","[[158   0]\n"," [ 47 116]]\n","training loss: 0.0003476669997767066; time: 0.6291830539703369s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.91       741\n","         1.0       0.90      0.91      0.90       667\n","\n","    accuracy                           0.91      1408\n","   macro avg       0.91      0.91      0.91      1408\n","weighted avg       0.91      0.91      0.91      1408\n","\n","[[674  67]\n"," [ 62 605]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:11<00:26,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.02027905601253762; time: 0.5369739532470703s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      1.00      0.83       158\n","         1.0       1.00      0.60      0.75       163\n","\n","    accuracy                           0.80       321\n","   macro avg       0.85      0.80      0.79       321\n","weighted avg       0.86      0.80      0.79       321\n","\n","[[158   0]\n"," [ 65  98]]\n","training loss: 0.00025261020848781545; time: 0.6250708103179932s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.93       740\n","         1.0       0.92      0.92      0.92       668\n","\n","    accuracy                           0.92      1408\n","   macro avg       0.92      0.92      0.92      1408\n","weighted avg       0.92      0.92      0.92      1408\n","\n","[[688  52]\n"," [ 56 612]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:12<00:25,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.017006668442065286; time: 0.5398738384246826s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      1.00      0.86       158\n","         1.0       1.00      0.67      0.81       163\n","\n","    accuracy                           0.83       321\n","   macro avg       0.87      0.84      0.83       321\n","weighted avg       0.88      0.83      0.83       321\n","\n","[[158   0]\n"," [ 53 110]]\n","training loss: 0.0002592919742657749; time: 0.6185939311981201s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.92       740\n","         1.0       0.92      0.91      0.91       668\n","\n","    accuracy                           0.92      1408\n","   macro avg       0.92      0.92      0.92      1408\n","weighted avg       0.92      0.92      0.92      1408\n","\n","[[685  55]\n"," [ 60 608]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:13<00:23,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007043642650512149; time: 0.5506792068481445s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.93       158\n","         1.0       0.93      0.93      0.93       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.93      0.93      0.93       321\n","weighted avg       0.93      0.93      0.93       321\n","\n","[[147  11]\n"," [ 12 151]]\n","training loss: 0.0001932509233787035; time: 0.6170237064361572s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.93      0.93       742\n","         1.0       0.92      0.92      0.92       666\n","\n","    accuracy                           0.93      1408\n","   macro avg       0.93      0.93      0.93      1408\n","weighted avg       0.93      0.93      0.93      1408\n","\n","[[689  53]\n"," [ 51 615]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:15<00:22,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01034909152538977; time: 0.5386168956756592s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.99      0.89       158\n","         1.0       0.99      0.76      0.86       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.87       321\n","weighted avg       0.90      0.88      0.87       321\n","\n","[[157   1]\n"," [ 39 124]]\n","training loss: 0.0001934204916909363; time: 0.6212866306304932s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.94      0.93       740\n","         1.0       0.93      0.91      0.92       668\n","\n","    accuracy                           0.92      1408\n","   macro avg       0.92      0.92      0.92      1408\n","weighted avg       0.92      0.92      0.92      1408\n","\n","[[695  45]\n"," [ 63 605]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:16<00:21,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0067586851338174115; time: 0.5640099048614502s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.97      0.91       158\n","         1.0       0.97      0.84      0.90       163\n","\n","    accuracy                           0.91       321\n","   macro avg       0.91      0.91      0.91       321\n","weighted avg       0.91      0.91      0.91       321\n","\n","[[154   4]\n"," [ 26 137]]\n","training loss: 0.00016767039476264897; time: 0.6362860202789307s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.93       743\n","         1.0       0.93      0.92      0.93       665\n","\n","    accuracy                           0.93      1408\n","   macro avg       0.93      0.93      0.93      1408\n","weighted avg       0.93      0.93      0.93      1408\n","\n","[[697  46]\n"," [ 53 612]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:17<00:20,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009859740826942468; time: 0.5589845180511475s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.91      0.94       158\n","         1.0       0.91      0.98      0.94       163\n","\n","    accuracy                           0.94       321\n","   macro avg       0.94      0.94      0.94       321\n","weighted avg       0.94      0.94      0.94       321\n","\n","[[143  15]\n"," [  4 159]]\n","training loss: 0.00013735260652152426; time: 0.6259067058563232s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.94      0.95       746\n","         1.0       0.93      0.95      0.94       662\n","\n","    accuracy                           0.94      1408\n","   macro avg       0.94      0.94      0.94      1408\n","weighted avg       0.94      0.94      0.94      1408\n","\n","[[702  44]\n"," [ 35 627]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:18<00:18,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006974488299490878; time: 0.5622215270996094s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.97      0.93       158\n","         1.0       0.97      0.88      0.92       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.93      0.93      0.93       321\n","weighted avg       0.93      0.93      0.93       321\n","\n","[[154   4]\n"," [ 20 143]]\n","training loss: 0.00018386163025173698; time: 0.6483831405639648s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.91       742\n","         1.0       0.90      0.91      0.91       666\n","\n","    accuracy                           0.91      1408\n","   macro avg       0.91      0.91      0.91      1408\n","weighted avg       0.91      0.91      0.91      1408\n","\n","[[676  66]\n"," [ 61 605]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:20<00:17,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.013256544195045935; time: 0.5438854694366455s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.98      0.92       158\n","         1.0       0.98      0.85      0.91       163\n","\n","    accuracy                           0.92       321\n","   macro avg       0.92      0.92      0.92       321\n","weighted avg       0.92      0.92      0.92       321\n","\n","[[155   3]\n"," [ 24 139]]\n","training loss: 0.0001228775954830216; time: 0.6446995735168457s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.95       743\n","         1.0       0.95      0.94      0.95       665\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[710  33]\n"," [ 39 626]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:21<00:16,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008985247068408865; time: 0.5413675308227539s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.99      0.90       158\n","         1.0       0.99      0.81      0.89       163\n","\n","    accuracy                           0.90       321\n","   macro avg       0.91      0.90      0.90       321\n","weighted avg       0.91      0.90      0.90       321\n","\n","[[156   2]\n"," [ 31 132]]\n","training loss: 0.00010733023983181802; time: 0.6389997005462646s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.96       742\n","         1.0       0.96      0.94      0.95       666\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[715  27]\n"," [ 38 628]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:22<00:15,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011412210774106028; time: 0.5487759113311768s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.99      0.90       158\n","         1.0       0.98      0.79      0.88       163\n","\n","    accuracy                           0.89       321\n","   macro avg       0.90      0.89      0.89       321\n","weighted avg       0.90      0.89      0.89       321\n","\n","[[156   2]\n"," [ 34 129]]\n","training loss: 0.00010100511904208783; time: 0.6191344261169434s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       742\n","         1.0       0.95      0.95      0.95       666\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[708  34]\n"," [ 36 630]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:23<00:13,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01217584436138471; time: 0.5543720722198486s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.99      0.89       158\n","         1.0       0.99      0.77      0.87       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.88       321\n","weighted avg       0.90      0.88      0.88       321\n","\n","[[157   1]\n"," [ 37 126]]\n","training loss: 9.534534910926595e-05; time: 0.6173875331878662s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       741\n","         1.0       0.94      0.95      0.94       667\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[702  39]\n"," [ 36 631]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:25<00:12,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.012500919894869454; time: 0.5473771095275879s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.99      0.88       158\n","         1.0       0.99      0.75      0.86       163\n","\n","    accuracy                           0.87       321\n","   macro avg       0.89      0.87      0.87       321\n","weighted avg       0.90      0.87      0.87       321\n","\n","[[157   1]\n"," [ 40 123]]\n","training loss: 8.84009722229174e-05; time: 0.6416025161743164s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       746\n","         1.0       0.95      0.94      0.94       662\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[711  35]\n"," [ 38 624]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:26<00:11,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01223154439129562; time: 0.547461986541748s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.99      0.89       158\n","         1.0       0.99      0.76      0.86       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.87       321\n","weighted avg       0.90      0.88      0.87       321\n","\n","[[157   1]\n"," [ 39 124]]\n","training loss: 8.351918697657356e-05; time: 0.6512932777404785s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       743\n","         1.0       0.95      0.94      0.94       665\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[708  35]\n"," [ 39 626]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:27<00:10,  1.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011463777936786134; time: 0.5496854782104492s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.99      0.90       158\n","         1.0       0.98      0.80      0.88       163\n","\n","    accuracy                           0.89       321\n","   macro avg       0.91      0.89      0.89       321\n","weighted avg       0.91      0.89      0.89       321\n","\n","[[156   2]\n"," [ 33 130]]\n","training loss: 7.88141357189729e-05; time: 0.6163449287414551s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.95       742\n","         1.0       0.95      0.95      0.95       666\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[709  33]\n"," [ 35 631]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:28<00:08,  1.26s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01192186905123363; time: 0.5672848224639893s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.99      0.89       158\n","         1.0       0.98      0.78      0.87       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.88       321\n","weighted avg       0.90      0.88      0.88       321\n","\n","[[156   2]\n"," [ 36 127]]\n","training loss: 7.602103615874623e-05; time: 0.7614600658416748s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95       744\n","         1.0       0.95      0.93      0.94       664\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[714  30]\n"," [ 44 620]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:30<00:07,  1.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.013435138250205004; time: 0.5438802242279053s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.79      1.00      0.88       158\n","         1.0       1.00      0.74      0.85       163\n","\n","    accuracy                           0.87       321\n","   macro avg       0.89      0.87      0.86       321\n","weighted avg       0.89      0.87      0.86       321\n","\n","[[158   0]\n"," [ 43 120]]\n","training loss: 7.119710197333585e-05; time: 0.6554982662200928s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.95      0.95       742\n","         1.0       0.95      0.95      0.95       666\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[706  36]\n"," [ 33 633]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:31<00:06,  1.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01296885420693044; time: 0.5672140121459961s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.99      0.89       158\n","         1.0       0.98      0.77      0.87       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.88       321\n","weighted avg       0.90      0.88      0.88       321\n","\n","[[156   2]\n"," [ 37 126]]\n","training loss: 6.738856701030546e-05; time: 0.6427903175354004s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.96       742\n","         1.0       0.96      0.94      0.95       666\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[716  26]\n"," [ 39 627]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:32<00:05,  1.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009595962896989513; time: 0.5584509372711182s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.98      0.93       158\n","         1.0       0.98      0.88      0.93       163\n","\n","    accuracy                           0.93       321\n","   macro avg       0.94      0.93      0.93       321\n","weighted avg       0.94      0.93      0.93       321\n","\n","[[155   3]\n"," [ 19 144]]\n","training loss: 6.853892414607985e-05; time: 0.6383330821990967s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.94      0.95       745\n","         1.0       0.94      0.95      0.95       663\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[704  41]\n"," [ 32 631]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:34<00:03,  1.28s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.012773851298283194; time: 0.5679419040679932s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.99      0.89       158\n","         1.0       0.98      0.77      0.87       163\n","\n","    accuracy                           0.88       321\n","   macro avg       0.90      0.88      0.88       321\n","weighted avg       0.90      0.88      0.88       321\n","\n","[[156   2]\n"," [ 37 126]]\n","training loss: 6.115791034830323e-05; time: 0.6527543067932129s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.97      0.95       743\n","         1.0       0.97      0.93      0.95       665\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[721  22]\n"," [ 46 619]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:35<00:02,  1.28s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.012024599559767596; time: 0.5603621006011963s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.99      0.90       158\n","         1.0       0.98      0.79      0.88       163\n","\n","    accuracy                           0.89       321\n","   macro avg       0.90      0.89      0.89       321\n","weighted avg       0.90      0.89      0.89       321\n","\n","[[156   2]\n"," [ 34 129]]\n","training loss: 5.9760763196035236e-05; time: 0.6535789966583252s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.96       740\n","         1.0       0.95      0.95      0.95       668\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[710  30]\n"," [ 34 634]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:36<00:01,  1.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011294574282390306; time: 0.5775887966156006s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.99      0.90       158\n","         1.0       0.98      0.80      0.89       163\n","\n","    accuracy                           0.89       321\n","   macro avg       0.91      0.90      0.89       321\n","weighted avg       0.91      0.89      0.89       321\n","\n","[[156   2]\n"," [ 32 131]]\n","training loss: 5.797871342634387e-05; time: 0.653480052947998s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.95      0.96       741\n","         1.0       0.95      0.96      0.95       667\n","\n","    accuracy                           0.95      1408\n","   macro avg       0.95      0.95      0.95      1408\n","weighted avg       0.95      0.95      0.95      1408\n","\n","[[705  36]\n"," [ 30 637]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:38<00:00,  1.27s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011673065534911795; time: 0.5725085735321045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.99      0.90       158\n","         1.0       0.98      0.80      0.88       163\n","\n","    accuracy                           0.89       321\n","   macro avg       0.91      0.89      0.89       321\n","weighted avg       0.91      0.89      0.89       321\n","\n","[[156   2]\n"," [ 33 130]]\n","[task=6_b_vs_p] (610, 40) features\n","[task=6_b_vs_p] (610,) labels\n","[task=6_b_vs_p] (169, 40) features\n","[task=6_b_vs_p] (169,) labels\n","training loss: 0.009323434283336004; time: 0.6248962879180908s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.93      0.80       352\n","         1.0       0.78      0.37      0.50       224\n","\n","    accuracy                           0.72       576\n","   macro avg       0.74      0.65      0.65       576\n","weighted avg       0.73      0.72      0.68       576\n","\n","[[329  23]\n"," [141  83]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:35,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011338624728501901; time: 0.5501019954681396s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.94      0.78        96\n","         1.0       0.83      0.40      0.54        73\n","\n","    accuracy                           0.70       169\n","   macro avg       0.75      0.67      0.66       169\n","weighted avg       0.74      0.70      0.68       169\n","\n","[[90  6]\n"," [44 29]]\n","training loss: 0.0045255141901887124; time: 0.5994076728820801s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.76      0.80      0.78       350\n","         1.0       0.66      0.62      0.64       226\n","\n","    accuracy                           0.73       576\n","   macro avg       0.71      0.71      0.71       576\n","weighted avg       0.72      0.73      0.73       576\n","\n","[[279  71]\n"," [ 86 140]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:33,  1.20s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007875864146023813; time: 0.5488214492797852s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.96      0.84        96\n","         1.0       0.91      0.56      0.69        73\n","\n","    accuracy                           0.79       169\n","   macro avg       0.83      0.76      0.77       169\n","weighted avg       0.82      0.79      0.78       169\n","\n","[[92  4]\n"," [32 41]]\n","training loss: 0.0043236651733793595; time: 0.6021325588226318s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.76      0.73       354\n","         1.0       0.56      0.49      0.52       222\n","\n","    accuracy                           0.65       576\n","   macro avg       0.63      0.62      0.63       576\n","weighted avg       0.65      0.65      0.65       576\n","\n","[[268  86]\n"," [113 109]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:03<00:32,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009040763921286228; time: 0.572760820388794s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.94      0.82        96\n","         1.0       0.87      0.55      0.67        73\n","\n","    accuracy                           0.77       169\n","   macro avg       0.80      0.74      0.75       169\n","weighted avg       0.79      0.77      0.76       169\n","\n","[[90  6]\n"," [33 40]]\n","training loss: 0.002002019254076812; time: 0.6062302589416504s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.82      0.79       352\n","         1.0       0.67      0.58      0.62       224\n","\n","    accuracy                           0.73       576\n","   macro avg       0.71      0.70      0.70       576\n","weighted avg       0.72      0.73      0.72       576\n","\n","[[289  63]\n"," [ 95 129]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:04<00:31,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008890219870403674; time: 0.5699863433837891s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.58      0.74        96\n","         1.0       0.65      1.00      0.78        73\n","\n","    accuracy                           0.76       169\n","   macro avg       0.82      0.79      0.76       169\n","weighted avg       0.85      0.76      0.76       169\n","\n","[[56 40]\n"," [ 0 73]]\n","training loss: 0.0013916763477027417; time: 0.5929546356201172s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.88      0.84       355\n","         1.0       0.77      0.65      0.71       221\n","\n","    accuracy                           0.79       576\n","   macro avg       0.79      0.77      0.77       576\n","weighted avg       0.79      0.79      0.79       576\n","\n","[[313  42]\n"," [ 77 144]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:06<00:30,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009862694955436437; time: 0.5687403678894043s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.35      0.52        96\n","         1.0       0.54      1.00      0.70        73\n","\n","    accuracy                           0.63       169\n","   macro avg       0.77      0.68      0.61       169\n","weighted avg       0.80      0.63      0.60       169\n","\n","[[34 62]\n"," [ 0 73]]\n","training loss: 0.0011215051032464813; time: 0.6204569339752197s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.84      0.83       350\n","         1.0       0.74      0.72      0.73       226\n","\n","    accuracy                           0.79       576\n","   macro avg       0.78      0.78      0.78       576\n","weighted avg       0.79      0.79      0.79       576\n","\n","[[294  56]\n"," [ 63 163]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:07<00:29,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009040318385383786; time: 0.557788610458374s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.48      0.65        96\n","         1.0       0.59      1.00      0.74        73\n","\n","    accuracy                           0.70       169\n","   macro avg       0.80      0.74      0.70       169\n","weighted avg       0.82      0.70      0.69       169\n","\n","[[46 50]\n"," [ 0 73]]\n","training loss: 0.0008522168260126833; time: 0.618598222732544s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.84      0.85       354\n","         1.0       0.76      0.79      0.77       222\n","\n","    accuracy                           0.82       576\n","   macro avg       0.81      0.82      0.81       576\n","weighted avg       0.82      0.82      0.82       576\n","\n","[[298  56]\n"," [ 47 175]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:08<00:27,  1.21s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006630635296804665; time: 0.5377476215362549s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.76      0.85        96\n","         1.0       0.76      0.97      0.85        73\n","\n","    accuracy                           0.85       169\n","   macro avg       0.86      0.87      0.85       169\n","weighted avg       0.88      0.85      0.85       169\n","\n","[[73 23]\n"," [ 2 71]]\n","training loss: 0.0011527491733431816; time: 0.6161210536956787s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.77      0.78       350\n","         1.0       0.65      0.67      0.66       226\n","\n","    accuracy                           0.73       576\n","   macro avg       0.72      0.72      0.72       576\n","weighted avg       0.73      0.73      0.73       576\n","\n","[[270  80]\n"," [ 75 151]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:09<00:26,  1.22s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.02816927415930484; time: 0.5695719718933105s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.58      1.00      0.74        96\n","         1.0       1.00      0.05      0.10        73\n","\n","    accuracy                           0.59       169\n","   macro avg       0.79      0.53      0.42       169\n","weighted avg       0.76      0.59      0.46       169\n","\n","[[96  0]\n"," [69  4]]\n","training loss: 0.001143853329581979; time: 0.6136538982391357s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.72      0.82      0.77       349\n","         1.0       0.66      0.52      0.58       227\n","\n","    accuracy                           0.70       576\n","   macro avg       0.69      0.67      0.68       576\n","weighted avg       0.70      0.70      0.70       576\n","\n","[[287  62]\n"," [109 118]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:10<00:25,  1.22s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009964249719529462; time: 0.5728116035461426s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.38      0.55        96\n","         1.0       0.55      1.00      0.71        73\n","\n","    accuracy                           0.64       169\n","   macro avg       0.77      0.69      0.63       169\n","weighted avg       0.81      0.64      0.62       169\n","\n","[[36 60]\n"," [ 0 73]]\n","training loss: 0.0008506566855228609; time: 0.5994775295257568s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.73      0.76       354\n","         1.0       0.61      0.68      0.64       222\n","\n","    accuracy                           0.71       576\n","   macro avg       0.70      0.70      0.70       576\n","weighted avg       0.72      0.71      0.71       576\n","\n","[[258  96]\n"," [ 71 151]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:12<00:24,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00965128794929685; time: 0.5686602592468262s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.33      0.50        96\n","         1.0       0.53      1.00      0.70        73\n","\n","    accuracy                           0.62       169\n","   macro avg       0.77      0.67      0.60       169\n","weighted avg       0.80      0.62      0.58       169\n","\n","[[32 64]\n"," [ 0 73]]\n","training loss: 0.0007367219512510781; time: 0.6027998924255371s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.80      0.77      0.79       354\n","         1.0       0.66      0.69      0.67       222\n","\n","    accuracy                           0.74       576\n","   macro avg       0.73      0.73      0.73       576\n","weighted avg       0.74      0.74      0.74       576\n","\n","[[274  80]\n"," [ 69 153]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:13<00:23,  1.22s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00918169980923805; time: 0.5550992488861084s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      1.00      0.82        96\n","         1.0       1.00      0.44      0.61        73\n","\n","    accuracy                           0.76       169\n","   macro avg       0.85      0.72      0.72       169\n","weighted avg       0.83      0.76      0.73       169\n","\n","[[96  0]\n"," [41 32]]\n","training loss: 0.0006269114523160237; time: 0.6351583003997803s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.82      0.80       347\n","         1.0       0.71      0.64      0.67       229\n","\n","    accuracy                           0.75       576\n","   macro avg       0.74      0.73      0.74       576\n","weighted avg       0.75      0.75      0.75       576\n","\n","[[286  61]\n"," [ 82 147]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:14<00:22,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.013209095720708722; time: 0.5778169631958008s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.65      1.00      0.79        96\n","         1.0       1.00      0.30      0.46        73\n","\n","    accuracy                           0.70       169\n","   macro avg       0.83      0.65      0.63       169\n","weighted avg       0.80      0.70      0.65       169\n","\n","[[96  0]\n"," [51 22]]\n","training loss: 0.000595731390082938; time: 0.6135349273681641s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.87      0.82       350\n","         1.0       0.75      0.62      0.68       226\n","\n","    accuracy                           0.77       576\n","   macro avg       0.76      0.74      0.75       576\n","weighted avg       0.77      0.77      0.76       576\n","\n","[[304  46]\n"," [ 87 139]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:15<00:21,  1.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.010465583681354862; time: 0.5868830680847168s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.68      1.00      0.81        96\n","         1.0       1.00      0.37      0.54        73\n","\n","    accuracy                           0.73       169\n","   macro avg       0.84      0.68      0.67       169\n","weighted avg       0.82      0.73      0.69       169\n","\n","[[96  0]\n"," [46 27]]\n","training loss: 0.00045265523081142753; time: 0.622699499130249s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.89      0.86       349\n","         1.0       0.81      0.74      0.77       227\n","\n","    accuracy                           0.83       576\n","   macro avg       0.83      0.81      0.82       576\n","weighted avg       0.83      0.83      0.83       576\n","\n","[[310  39]\n"," [ 59 168]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:17<00:19,  1.24s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007309728120205671; time: 0.5668606758117676s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.65      0.78        96\n","         1.0       0.68      1.00      0.81        73\n","\n","    accuracy                           0.80       169\n","   macro avg       0.84      0.82      0.80       169\n","weighted avg       0.86      0.80      0.80       169\n","\n","[[62 34]\n"," [ 0 73]]\n","training loss: 0.00035790925914490666; time: 0.6071395874023438s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.87      0.87       351\n","         1.0       0.80      0.79      0.79       225\n","\n","    accuracy                           0.84       576\n","   macro avg       0.83      0.83      0.83       576\n","weighted avg       0.84      0.84      0.84       576\n","\n","[[307  44]\n"," [ 48 177]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:18<00:18,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006603825991675699; time: 0.5723836421966553s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.90      0.85        96\n","         1.0       0.84      0.73      0.78        73\n","\n","    accuracy                           0.82       169\n","   macro avg       0.83      0.81      0.82       169\n","weighted avg       0.82      0.82      0.82       169\n","\n","[[86 10]\n"," [20 53]]\n","training loss: 0.00031426744276864664; time: 0.6192882061004639s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.89      0.88       349\n","         1.0       0.83      0.79      0.81       227\n","\n","    accuracy                           0.85       576\n","   macro avg       0.85      0.84      0.85       576\n","weighted avg       0.85      0.85      0.85       576\n","\n","[[312  37]\n"," [ 47 180]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:19<00:17,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006129377868753919; time: 0.5754315853118896s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.77      0.85        96\n","         1.0       0.76      0.95      0.84        73\n","\n","    accuracy                           0.85       169\n","   macro avg       0.85      0.86      0.85       169\n","weighted avg       0.87      0.85      0.85       169\n","\n","[[74 22]\n"," [ 4 69]]\n","training loss: 0.00036983074942981104; time: 0.6076445579528809s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.85      0.85       351\n","         1.0       0.77      0.77      0.77       225\n","\n","    accuracy                           0.82       576\n","   macro avg       0.81      0.81      0.81       576\n","weighted avg       0.82      0.82      0.82       576\n","\n","[[298  53]\n"," [ 51 174]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:20<00:15,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00633172100112283; time: 0.5618884563446045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.92      0.86        96\n","         1.0       0.87      0.73      0.79        73\n","\n","    accuracy                           0.83       169\n","   macro avg       0.84      0.82      0.83       169\n","weighted avg       0.84      0.83      0.83       169\n","\n","[[88  8]\n"," [20 53]]\n","training loss: 0.00029774180923899013; time: 0.6244604587554932s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.89      0.86       347\n","         1.0       0.82      0.74      0.78       229\n","\n","    accuracy                           0.83       576\n","   macro avg       0.83      0.82      0.82       576\n","weighted avg       0.83      0.83      0.83       576\n","\n","[[309  38]\n"," [ 59 170]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:22<00:14,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008649050263610817; time: 0.559208869934082s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.49      0.66        96\n","         1.0       0.60      1.00      0.75        73\n","\n","    accuracy                           0.71       169\n","   macro avg       0.80      0.74      0.70       169\n","weighted avg       0.83      0.71      0.70       169\n","\n","[[47 49]\n"," [ 0 73]]\n","training loss: 0.0002757856208417151; time: 0.6315038204193115s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.87      0.86       349\n","         1.0       0.79      0.76      0.78       227\n","\n","    accuracy                           0.83       576\n","   macro avg       0.82      0.82      0.82       576\n","weighted avg       0.83      0.83      0.83       576\n","\n","[[304  45]\n"," [ 54 173]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:23<00:13,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006402320939408251; time: 0.558009147644043s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.88      0.86        96\n","         1.0       0.83      0.78      0.80        73\n","\n","    accuracy                           0.83       169\n","   macro avg       0.83      0.83      0.83       169\n","weighted avg       0.83      0.83      0.83       169\n","\n","[[84 12]\n"," [16 57]]\n","training loss: 0.00022619597924252352; time: 0.6271412372589111s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       346\n","         1.0       0.83      0.84      0.84       230\n","\n","    accuracy                           0.87       576\n","   macro avg       0.86      0.86      0.86       576\n","weighted avg       0.87      0.87      0.87       576\n","\n","[[307  39]\n"," [ 37 193]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:24<00:12,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006306170006475505; time: 0.5448098182678223s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.88      0.84        96\n","         1.0       0.82      0.74      0.78        73\n","\n","    accuracy                           0.82       169\n","   macro avg       0.82      0.81      0.81       169\n","weighted avg       0.82      0.82      0.82       169\n","\n","[[84 12]\n"," [19 54]]\n","training loss: 0.00024139981534548852; time: 0.6151823997497559s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.86      0.87       349\n","         1.0       0.79      0.82      0.81       227\n","\n","    accuracy                           0.85       576\n","   macro avg       0.84      0.84      0.84       576\n","weighted avg       0.85      0.85      0.85       576\n","\n","[[301  48]\n"," [ 41 186]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:25<00:11,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008732612977719165; time: 0.5622014999389648s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.97      0.82        96\n","         1.0       0.92      0.47      0.62        73\n","\n","    accuracy                           0.75       169\n","   macro avg       0.81      0.72      0.72       169\n","weighted avg       0.80      0.75      0.73       169\n","\n","[[93  3]\n"," [39 34]]\n","training loss: 0.00031434082322650484; time: 0.6210205554962158s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.87      0.85       355\n","         1.0       0.77      0.70      0.73       221\n","\n","    accuracy                           0.81       576\n","   macro avg       0.80      0.79      0.79       576\n","weighted avg       0.80      0.81      0.80       576\n","\n","[[309  46]\n"," [ 66 155]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:26<00:09,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01231016392803051; time: 0.5590870380401611s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.39      0.56        96\n","         1.0       0.55      1.00      0.71        73\n","\n","    accuracy                           0.65       169\n","   macro avg       0.78      0.69      0.63       169\n","weighted avg       0.81      0.65      0.62       169\n","\n","[[37 59]\n"," [ 0 73]]\n","training loss: 0.00027997771520977437; time: 0.6284170150756836s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.84      0.84       351\n","         1.0       0.75      0.76      0.75       225\n","\n","    accuracy                           0.81       576\n","   macro avg       0.80      0.80      0.80       576\n","weighted avg       0.81      0.81      0.81       576\n","\n","[[294  57]\n"," [ 54 171]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:28<00:08,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.009588665290344396; time: 0.5668458938598633s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.70      0.99      0.82        96\n","         1.0       0.97      0.44      0.60        73\n","\n","    accuracy                           0.75       169\n","   macro avg       0.83      0.71      0.71       169\n","weighted avg       0.82      0.75      0.73       169\n","\n","[[95  1]\n"," [41 32]]\n","training loss: 0.00022765307437145599; time: 0.6211235523223877s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.87      0.86       351\n","         1.0       0.79      0.75      0.77       225\n","\n","    accuracy                           0.82       576\n","   macro avg       0.82      0.81      0.81       576\n","weighted avg       0.82      0.82      0.82       576\n","\n","[[307  44]\n"," [ 57 168]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:29<00:07,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0066965712598089635; time: 0.5657768249511719s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.75      0.84        96\n","         1.0       0.74      0.95      0.83        73\n","\n","    accuracy                           0.83       169\n","   macro avg       0.84      0.85      0.83       169\n","weighted avg       0.86      0.83      0.83       169\n","\n","[[72 24]\n"," [ 4 69]]\n","training loss: 0.00021727009158995417; time: 0.6046757698059082s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.88      0.87       353\n","         1.0       0.81      0.76      0.78       223\n","\n","    accuracy                           0.84       576\n","   macro avg       0.83      0.82      0.83       576\n","weighted avg       0.84      0.84      0.84       576\n","\n","[[312  41]\n"," [ 53 170]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:30<00:06,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008078780929012411; time: 0.5803141593933105s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.98      0.82        96\n","         1.0       0.94      0.47      0.62        73\n","\n","    accuracy                           0.76       169\n","   macro avg       0.83      0.72      0.72       169\n","weighted avg       0.81      0.76      0.74       169\n","\n","[[94  2]\n"," [39 34]]\n","training loss: 0.00016767122090244904; time: 0.6102068424224854s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       351\n","         1.0       0.83      0.83      0.83       225\n","\n","    accuracy                           0.86       576\n","   macro avg       0.86      0.86      0.86       576\n","weighted avg       0.86      0.86      0.86       576\n","\n","[[312  39]\n"," [ 39 186]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:31<00:04,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00622913453000537; time: 0.5905075073242188s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.81      0.86        96\n","         1.0       0.79      0.90      0.84        73\n","\n","    accuracy                           0.85       169\n","   macro avg       0.85      0.86      0.85       169\n","weighted avg       0.86      0.85      0.85       169\n","\n","[[78 18]\n"," [ 7 66]]\n","training loss: 0.00015367524518244307; time: 0.6168661117553711s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.92      0.89       356\n","         1.0       0.86      0.78      0.82       220\n","\n","    accuracy                           0.87       576\n","   macro avg       0.86      0.85      0.86       576\n","weighted avg       0.87      0.87      0.86       576\n","\n","[[328  28]\n"," [ 49 171]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:33<00:03,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00906628670071709; time: 0.5574121475219727s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.49      0.66        96\n","         1.0       0.60      1.00      0.75        73\n","\n","    accuracy                           0.71       169\n","   macro avg       0.80      0.74      0.70       169\n","weighted avg       0.83      0.71      0.70       169\n","\n","[[47 49]\n"," [ 0 73]]\n","training loss: 0.0001750193833787408; time: 0.6254527568817139s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.87      0.87       349\n","         1.0       0.80      0.80      0.80       227\n","\n","    accuracy                           0.84       576\n","   macro avg       0.83      0.83      0.83       576\n","weighted avg       0.84      0.84      0.84       576\n","\n","[[303  46]\n"," [ 45 182]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:34<00:02,  1.23s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007569614070407032; time: 0.5699267387390137s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.96      0.83        96\n","         1.0       0.91      0.55      0.68        73\n","\n","    accuracy                           0.78       169\n","   macro avg       0.82      0.75      0.76       169\n","weighted avg       0.81      0.78      0.77       169\n","\n","[[92  4]\n"," [33 40]]\n","training loss: 0.0001337593822772133; time: 0.6546812057495117s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.93      0.90       355\n","         1.0       0.87      0.80      0.83       221\n","\n","    accuracy                           0.88       576\n","   macro avg       0.88      0.86      0.87       576\n","weighted avg       0.88      0.88      0.88       576\n","\n","[[329  26]\n"," [ 45 176]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:35<00:01,  1.25s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0063107787857394244; time: 0.5866622924804688s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.75      0.84        96\n","         1.0       0.74      0.95      0.83        73\n","\n","    accuracy                           0.83       169\n","   macro avg       0.84      0.85      0.83       169\n","weighted avg       0.86      0.83      0.83       169\n","\n","[[72 24]\n"," [ 4 69]]\n","training loss: 0.0001337268501865091; time: 0.6140060424804688s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.90      0.90       348\n","         1.0       0.85      0.84      0.84       228\n","\n","    accuracy                           0.88       576\n","   macro avg       0.87      0.87      0.87       576\n","weighted avg       0.87      0.88      0.87       576\n","\n","[[313  35]\n"," [ 37 191]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:36<00:00,  1.23s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006446624031433692; time: 0.58693528175354s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.91      0.86        96\n","         1.0       0.85      0.73      0.79        73\n","\n","    accuracy                           0.83       169\n","   macro avg       0.83      0.82      0.82       169\n","weighted avg       0.83      0.83      0.83       169\n","\n","[[87  9]\n"," [20 53]]\n","[task=7_dh_vs_th] (1170, 40) features\n","[task=7_dh_vs_th] (1170,) labels\n","[task=7_dh_vs_th] (310, 40) features\n","[task=7_dh_vs_th] (310,) labels\n","training loss: 0.006767626722446746; time: 0.6471455097198486s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.79      0.82       628\n","         1.0       0.77      0.84      0.80       524\n","\n","    accuracy                           0.81      1152\n","   macro avg       0.81      0.82      0.81      1152\n","weighted avg       0.82      0.81      0.81      1152\n","\n","[[499 129]\n"," [ 85 439]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:36,  1.27s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005504267831002513; time: 0.5728428363800049s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.91      0.82       138\n","         1.0       0.92      0.76      0.83       172\n","\n","    accuracy                           0.83       310\n","   macro avg       0.83      0.83      0.83       310\n","weighted avg       0.84      0.83      0.83       310\n","\n","[[126  12]\n"," [ 42 130]]\n","training loss: 0.0027270933884816864; time: 0.6702463626861572s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.86      0.87       637\n","         1.0       0.83      0.84      0.84       515\n","\n","    accuracy                           0.85      1152\n","   macro avg       0.85      0.85      0.85      1152\n","weighted avg       0.85      0.85      0.85      1152\n","\n","[[549  88]\n"," [ 81 434]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:36,  1.29s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011891202235053624; time: 0.5806746482849121s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.66      0.99      0.79       138\n","         1.0       0.99      0.59      0.74       172\n","\n","    accuracy                           0.77       310\n","   macro avg       0.83      0.79      0.77       310\n","weighted avg       0.84      0.77      0.77       310\n","\n","[[137   1]\n"," [ 70 102]]\n","training loss: 0.0015585900379206847; time: 0.673459529876709s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       630\n","         1.0       0.87      0.86      0.86       522\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[560  70]\n"," [ 71 451]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:03<00:35,  1.30s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005760802761200935; time: 0.5926053524017334s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.97      0.82       138\n","         1.0       0.97      0.67      0.79       172\n","\n","    accuracy                           0.81       310\n","   macro avg       0.84      0.82      0.81       310\n","weighted avg       0.85      0.81      0.80       310\n","\n","[[134   4]\n"," [ 56 116]]\n","training loss: 0.0011007027318959849; time: 0.6623961925506592s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.88      0.89       633\n","         1.0       0.86      0.87      0.86       519\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[559  74]\n"," [ 68 451]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:34,  1.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004747704740974211; time: 0.5979166030883789s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.69      0.80       138\n","         1.0       0.80      0.98      0.88       172\n","\n","    accuracy                           0.85       310\n","   macro avg       0.88      0.83      0.84       310\n","weighted avg       0.87      0.85      0.84       310\n","\n","[[ 95  43]\n"," [  4 168]]\n","training loss: 0.0008254075164182319; time: 0.6774296760559082s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.88      0.88       630\n","         1.0       0.85      0.87      0.86       522\n","\n","    accuracy                           0.87      1152\n","   macro avg       0.87      0.87      0.87      1152\n","weighted avg       0.87      0.87      0.87      1152\n","\n","[[553  77]\n"," [ 69 453]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:06<00:32,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004861106290932625; time: 0.582888126373291s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.67      0.79       138\n","         1.0       0.79      0.98      0.87       172\n","\n","    accuracy                           0.84       310\n","   macro avg       0.87      0.83      0.83       310\n","weighted avg       0.86      0.84      0.84       310\n","\n","[[ 93  45]\n"," [  4 168]]\n","training loss: 0.000695953850582656; time: 0.6610450744628906s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.90      0.89       631\n","         1.0       0.88      0.85      0.86       521\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[568  63]\n"," [ 77 444]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:07<00:31,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004796510141703391; time: 0.6088745594024658s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.70      0.81       138\n","         1.0       0.80      0.98      0.88       172\n","\n","    accuracy                           0.85       310\n","   macro avg       0.88      0.84      0.84       310\n","weighted avg       0.87      0.85      0.85       310\n","\n","[[ 96  42]\n"," [  4 168]]\n","training loss: 0.0006047467117212595; time: 0.6588740348815918s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.87      0.88       634\n","         1.0       0.85      0.86      0.85       518\n","\n","    accuracy                           0.87      1152\n","   macro avg       0.86      0.86      0.86      1152\n","weighted avg       0.87      0.87      0.87      1152\n","\n","[[554  80]\n"," [ 75 443]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:09<00:30,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004388227193586288; time: 0.5885379314422607s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.75      0.84       138\n","         1.0       0.83      0.97      0.89       172\n","\n","    accuracy                           0.87       310\n","   macro avg       0.89      0.86      0.87       310\n","weighted avg       0.88      0.87      0.87       310\n","\n","[[104  34]\n"," [  6 166]]\n","training loss: 0.0005065352597739547; time: 0.6837160587310791s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       630\n","         1.0       0.87      0.87      0.87       522\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[560  70]\n"," [ 66 456]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:10<00:29,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004477994672713741; time: 0.5852599143981934s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.80      0.85       138\n","         1.0       0.85      0.92      0.89       172\n","\n","    accuracy                           0.87       310\n","   macro avg       0.88      0.86      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[111  27]\n"," [ 13 159]]\n","training loss: 0.00043940735710669816; time: 0.6539046764373779s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89       629\n","         1.0       0.87      0.88      0.87       523\n","\n","    accuracy                           0.89      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.89      0.89      0.89      1152\n","\n","[[561  68]\n"," [ 64 459]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:11<00:27,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005393162321659826; time: 0.588001012802124s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.96      0.83       138\n","         1.0       0.96      0.71      0.82       172\n","\n","    accuracy                           0.82       310\n","   macro avg       0.84      0.84      0.82       310\n","weighted avg       0.86      0.82      0.82       310\n","\n","[[133   5]\n"," [ 50 122]]\n","training loss: 0.00043760857855280243; time: 0.6487076282501221s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.87      0.88       634\n","         1.0       0.85      0.86      0.85       518\n","\n","    accuracy                           0.86      1152\n","   macro avg       0.86      0.86      0.86      1152\n","weighted avg       0.86      0.86      0.86      1152\n","\n","[[553  81]\n"," [ 75 443]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:13<00:26,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004892612236642068; time: 0.5740265846252441s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.67      0.79       138\n","         1.0       0.79      0.98      0.87       172\n","\n","    accuracy                           0.84       310\n","   macro avg       0.87      0.82      0.83       310\n","weighted avg       0.86      0.84      0.83       310\n","\n","[[ 92  46]\n"," [  4 168]]\n","training loss: 0.0003702131563308414; time: 0.6500916481018066s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.88      0.89       629\n","         1.0       0.86      0.88      0.87       523\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[554  75]\n"," [ 63 460]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:14<00:24,  1.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00582974219033795; time: 0.5750868320465088s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.69      0.98      0.81       138\n","         1.0       0.97      0.65      0.78       172\n","\n","    accuracy                           0.80       310\n","   macro avg       0.83      0.81      0.80       310\n","weighted avg       0.85      0.80      0.79       310\n","\n","[[135   3]\n"," [ 60 112]]\n","training loss: 0.0003316664757827918; time: 0.6589994430541992s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.89      0.89       636\n","         1.0       0.86      0.86      0.86       516\n","\n","    accuracy                           0.87      1152\n","   macro avg       0.87      0.87      0.87      1152\n","weighted avg       0.87      0.87      0.87      1152\n","\n","[[564  72]\n"," [ 74 442]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:15<00:23,  1.31s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006661352443118249; time: 0.5779609680175781s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.68      0.98      0.80       138\n","         1.0       0.97      0.63      0.77       172\n","\n","    accuracy                           0.79       310\n","   macro avg       0.83      0.81      0.79       310\n","weighted avg       0.84      0.79      0.78       310\n","\n","[[135   3]\n"," [ 63 109]]\n","training loss: 0.000284687508470737; time: 0.6588683128356934s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.91       634\n","         1.0       0.89      0.87      0.88       518\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.89      0.89      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[579  55]\n"," [ 65 453]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:17<00:22,  1.32s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004465258049388085; time: 0.6084671020507812s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.82      0.84       138\n","         1.0       0.86      0.90      0.88       172\n","\n","    accuracy                           0.86       310\n","   macro avg       0.87      0.86      0.86       310\n","weighted avg       0.86      0.86      0.86       310\n","\n","[[113  25]\n"," [ 17 155]]\n","training loss: 0.00028686414820156876; time: 0.6832602024078369s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89       634\n","         1.0       0.86      0.87      0.87       518\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[562  72]\n"," [ 65 453]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:18<00:21,  1.33s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006058236187504184; time: 0.6035900115966797s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.98      0.82       138\n","         1.0       0.97      0.68      0.80       172\n","\n","    accuracy                           0.81       310\n","   macro avg       0.84      0.83      0.81       310\n","weighted avg       0.86      0.81      0.81       310\n","\n","[[135   3]\n"," [ 55 117]]\n","training loss: 0.0002595535833043633; time: 0.674750566482544s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.89      0.90       628\n","         1.0       0.87      0.89      0.88       524\n","\n","    accuracy                           0.89      1152\n","   macro avg       0.89      0.89      0.89      1152\n","weighted avg       0.89      0.89      0.89      1152\n","\n","[[556  72]\n"," [ 58 466]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:19<00:20,  1.34s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007536136959829638; time: 0.6302585601806641s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.69      0.98      0.81       138\n","         1.0       0.97      0.64      0.77       172\n","\n","    accuracy                           0.79       310\n","   macro avg       0.83      0.81      0.79       310\n","weighted avg       0.85      0.79      0.79       310\n","\n","[[135   3]\n"," [ 62 110]]\n","training loss: 0.0002843463524994958; time: 0.7238137722015381s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.90      0.88       631\n","         1.0       0.87      0.83      0.85       521\n","\n","    accuracy                           0.87      1152\n","   macro avg       0.87      0.86      0.87      1152\n","weighted avg       0.87      0.87      0.87      1152\n","\n","[[568  63]\n"," [ 90 431]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:21<00:19,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005014284099301984; time: 0.6230330467224121s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.65      0.78       138\n","         1.0       0.78      0.98      0.87       172\n","\n","    accuracy                           0.84       310\n","   macro avg       0.87      0.82      0.82       310\n","weighted avg       0.86      0.84      0.83       310\n","\n","[[ 90  48]\n"," [  3 169]]\n","training loss: 0.0002646631335997893; time: 0.6628837585449219s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.86      0.87       629\n","         1.0       0.83      0.86      0.85       523\n","\n","    accuracy                           0.86      1152\n","   macro avg       0.86      0.86      0.86      1152\n","weighted avg       0.86      0.86      0.86      1152\n","\n","[[538  91]\n"," [ 71 452]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:22<00:17,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0065471076436581154; time: 0.6117851734161377s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.60      0.75       138\n","         1.0       0.76      0.99      0.86       172\n","\n","    accuracy                           0.82       310\n","   macro avg       0.87      0.80      0.80       310\n","weighted avg       0.86      0.82      0.81       310\n","\n","[[ 83  55]\n"," [  1 171]]\n","training loss: 0.00023733636574175808; time: 0.6960325241088867s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.88      0.88       630\n","         1.0       0.85      0.85      0.85       522\n","\n","    accuracy                           0.87      1152\n","   macro avg       0.87      0.87      0.87      1152\n","weighted avg       0.87      0.87      0.87      1152\n","\n","[[553  77]\n"," [ 77 445]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:23<00:16,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00479210413271381; time: 0.5912446975708008s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.93      0.83       138\n","         1.0       0.94      0.76      0.84       172\n","\n","    accuracy                           0.84       310\n","   macro avg       0.84      0.85      0.84       310\n","weighted avg       0.85      0.84      0.84       310\n","\n","[[129   9]\n"," [ 42 130]]\n","training loss: 0.00018599169936074674; time: 0.687314510345459s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.91       633\n","         1.0       0.89      0.88      0.89       519\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[578  55]\n"," [ 63 456]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:25<00:14,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004457172366880601; time: 0.6066591739654541s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.83      0.84       138\n","         1.0       0.87      0.88      0.88       172\n","\n","    accuracy                           0.86       310\n","   macro avg       0.86      0.86      0.86       310\n","weighted avg       0.86      0.86      0.86       310\n","\n","[[115  23]\n"," [ 20 152]]\n","training loss: 0.00017644962257084746; time: 0.6869451999664307s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.93      0.92       634\n","         1.0       0.91      0.87      0.89       518\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.90      0.90      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[590  44]\n"," [ 65 453]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:26<00:13,  1.37s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004477798794546435; time: 0.5945296287536621s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.84      0.84       138\n","         1.0       0.87      0.87      0.87       172\n","\n","    accuracy                           0.85       310\n","   macro avg       0.85      0.85      0.85       310\n","weighted avg       0.85      0.85      0.85       310\n","\n","[[116  22]\n"," [ 23 149]]\n","training loss: 0.0001668270681023834; time: 0.6620609760284424s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.89      0.91       631\n","         1.0       0.87      0.91      0.89       521\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[560  71]\n"," [ 46 475]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:28<00:12,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00527391827875568; time: 0.5992956161499023s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.73      0.96      0.83       138\n","         1.0       0.96      0.71      0.82       172\n","\n","    accuracy                           0.82       310\n","   macro avg       0.84      0.84      0.82       310\n","weighted avg       0.86      0.82      0.82       310\n","\n","[[133   5]\n"," [ 50 122]]\n","training loss: 0.0001587501157903009; time: 0.6668350696563721s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.93      0.91       632\n","         1.0       0.91      0.88      0.89       520\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[585  47]\n"," [ 65 455]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:29<00:10,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004617724303276308; time: 0.6060223579406738s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.88      0.82       138\n","         1.0       0.89      0.78      0.84       172\n","\n","    accuracy                           0.83       310\n","   macro avg       0.83      0.83      0.83       310\n","weighted avg       0.84      0.83      0.83       310\n","\n","[[122  16]\n"," [ 37 135]]\n","training loss: 0.0001475577774696088; time: 0.6622002124786377s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.93      0.91       632\n","         1.0       0.91      0.88      0.89       520\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[585  47]\n"," [ 64 456]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:30<00:09,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004412723789291997; time: 0.6184237003326416s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.83      0.84       138\n","         1.0       0.86      0.89      0.88       172\n","\n","    accuracy                           0.86       310\n","   macro avg       0.86      0.86      0.86       310\n","weighted avg       0.86      0.86      0.86       310\n","\n","[[114  24]\n"," [ 19 153]]\n","training loss: 0.00014178742249323814; time: 0.6760454177856445s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.92      0.92       633\n","         1.0       0.90      0.90      0.90       519\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.91      0.91      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[584  49]\n"," [ 54 465]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:32<00:08,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004402880466753437; time: 0.6125078201293945s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.83      0.85       138\n","         1.0       0.87      0.90      0.88       172\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.86      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[114  24]\n"," [ 17 155]]\n","training loss: 0.00013624900745020974; time: 0.6925792694091797s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.92      0.92       632\n","         1.0       0.90      0.90      0.90       520\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.91      0.91      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[580  52]\n"," [ 51 469]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:33<00:06,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004463492766503365; time: 0.6073911190032959s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.84      0.83       138\n","         1.0       0.87      0.86      0.87       172\n","\n","    accuracy                           0.85       310\n","   macro avg       0.85      0.85      0.85       310\n","weighted avg       0.85      0.85      0.85       310\n","\n","[[116  22]\n"," [ 24 148]]\n","training loss: 0.00012867190550742115; time: 0.6936256885528564s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.92      0.92       632\n","         1.0       0.90      0.89      0.90       520\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.91      0.91      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[582  50]\n"," [ 57 463]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:34<00:05,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004513274013034759; time: 0.6028006076812744s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.79      0.86      0.82       138\n","         1.0       0.88      0.81      0.85       172\n","\n","    accuracy                           0.84       310\n","   macro avg       0.83      0.84      0.83       310\n","weighted avg       0.84      0.84      0.84       310\n","\n","[[119  19]\n"," [ 32 140]]\n","training loss: 0.00012399908969631043; time: 0.6654434204101562s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.92      0.92       635\n","         1.0       0.90      0.89      0.89       517\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.90      0.91      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[586  49]\n"," [ 59 458]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:36<00:04,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004613483817346635; time: 0.6199781894683838s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.88      0.82       138\n","         1.0       0.89      0.78      0.84       172\n","\n","    accuracy                           0.83       310\n","   macro avg       0.83      0.83      0.83       310\n","weighted avg       0.84      0.83      0.83       310\n","\n","[[122  16]\n"," [ 37 135]]\n","training loss: 0.00011915073818748905; time: 0.6874651908874512s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.92       631\n","         1.0       0.90      0.90      0.90       521\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.91      0.91      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[577  54]\n"," [ 53 468]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:37<00:02,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004559144281571911; time: 0.6062171459197998s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.86      0.82       138\n","         1.0       0.88      0.80      0.84       172\n","\n","    accuracy                           0.83       310\n","   macro avg       0.83      0.83      0.83       310\n","weighted avg       0.83      0.83      0.83       310\n","\n","[[119  19]\n"," [ 35 137]]\n","training loss: 0.0001147061727327291; time: 0.676445722579956s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.92      0.91       634\n","         1.0       0.90      0.89      0.89       518\n","\n","    accuracy                           0.91      1152\n","   macro avg       0.91      0.90      0.90      1152\n","weighted avg       0.91      0.91      0.91      1152\n","\n","[[584  50]\n"," [ 59 459]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:38<00:01,  1.36s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004719886231806971; time: 0.6292736530303955s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.74      0.91      0.82       138\n","         1.0       0.91      0.75      0.82       172\n","\n","    accuracy                           0.82       310\n","   macro avg       0.83      0.83      0.82       310\n","weighted avg       0.84      0.82      0.82       310\n","\n","[[125  13]\n"," [ 43 129]]\n","training loss: 0.00010938578526730891; time: 0.6996502876281738s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.94      0.91       632\n","         1.0       0.92      0.86      0.89       520\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[591  41]\n"," [ 72 448]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:40<00:00,  1.34s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004612363874912262; time: 0.6162998676300049s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.88      0.82       138\n","         1.0       0.89      0.78      0.84       172\n","\n","    accuracy                           0.83       310\n","   macro avg       0.83      0.83      0.83       310\n","weighted avg       0.84      0.83      0.83       310\n","\n","[[122  16]\n"," [ 37 135]]\n","[task=8_ww_vs_yy] (1105, 40) features\n","[task=8_ww_vs_yy] (1105,) labels\n","[task=8_ww_vs_yy] (310, 40) features\n","[task=8_ww_vs_yy] (310,) labels\n","training loss: 0.006876996197902104; time: 0.6775798797607422s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.76      0.85      0.80       518\n","         1.0       0.85      0.76      0.80       570\n","\n","    accuracy                           0.80      1088\n","   macro avg       0.80      0.80      0.80      1088\n","weighted avg       0.81      0.80      0.80      1088\n","\n","[[439  79]\n"," [137 433]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:39,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005385925068009285; time: 0.6253993511199951s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.91      0.85       155\n","         1.0       0.90      0.78      0.83       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.85      0.85      0.84       310\n","weighted avg       0.85      0.85      0.84       310\n","\n","[[141  14]\n"," [ 34 121]]\n","training loss: 0.0018875974346883595; time: 0.6786773204803467s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.90       519\n","         1.0       0.90      0.91      0.91       569\n","\n","    accuracy                           0.90      1088\n","   macro avg       0.90      0.90      0.90      1088\n","weighted avg       0.90      0.90      0.90      1088\n","\n","[[462  57]\n"," [ 50 519]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:37,  1.35s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.015960275689740816; time: 0.6142439842224121s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.67      0.96      0.79       155\n","         1.0       0.93      0.52      0.67       155\n","\n","    accuracy                           0.74       310\n","   macro avg       0.80      0.74      0.73       310\n","weighted avg       0.80      0.74      0.73       310\n","\n","[[149   6]\n"," [ 74  81]]\n","training loss: 0.002650100208234553; time: 0.8119239807128906s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.84      0.83       517\n","         1.0       0.85      0.85      0.85       571\n","\n","    accuracy                           0.84      1088\n","   macro avg       0.84      0.84      0.84      1088\n","weighted avg       0.84      0.84      0.84      1088\n","\n","[[432  85]\n"," [ 87 484]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:37,  1.39s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0071395374353854886; time: 0.5986721515655518s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.57      0.73       155\n","         1.0       0.70      1.00      0.82       155\n","\n","    accuracy                           0.79       310\n","   macro avg       0.85      0.79      0.78       310\n","weighted avg       0.85      0.79      0.78       310\n","\n","[[ 89  66]\n"," [  0 155]]\n","training loss: 0.0008932030109195586; time: 0.7737133502960205s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.88      0.89       514\n","         1.0       0.90      0.91      0.90       574\n","\n","    accuracy                           0.90      1088\n","   macro avg       0.90      0.90      0.90      1088\n","weighted avg       0.90      0.90      0.90      1088\n","\n","[[453  61]\n"," [ 51 523]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:36,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005173266174331788; time: 0.6513760089874268s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.87      0.86       155\n","         1.0       0.87      0.84      0.85       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[135  20]\n"," [ 25 130]]\n","training loss: 0.0007603993694133618; time: 0.7005178928375244s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       519\n","         1.0       0.90      0.90      0.90       569\n","\n","    accuracy                           0.90      1088\n","   macro avg       0.90      0.90      0.90      1088\n","weighted avg       0.90      0.90      0.90      1088\n","\n","[[463  56]\n"," [ 57 512]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:35,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008513980671282737; time: 0.6523170471191406s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.71      0.96      0.81       155\n","         1.0       0.94      0.60      0.73       155\n","\n","    accuracy                           0.78       310\n","   macro avg       0.82      0.78      0.77       310\n","weighted avg       0.82      0.78      0.77       310\n","\n","[[149   6]\n"," [ 62  93]]\n","training loss: 0.0006200369817259558; time: 0.7020573616027832s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.88      0.87       521\n","         1.0       0.88      0.88      0.88       567\n","\n","    accuracy                           0.88      1088\n","   macro avg       0.88      0.88      0.88      1088\n","weighted avg       0.88      0.88      0.88      1088\n","\n","[[456  65]\n"," [ 69 498]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:08<00:33,  1.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0050477592695143915; time: 0.6247611045837402s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.91      0.86       155\n","         1.0       0.90      0.80      0.85       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[141  14]\n"," [ 31 124]]\n","training loss: 0.0004363979502510624; time: 0.7012732028961182s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.89      0.90       515\n","         1.0       0.90      0.92      0.91       573\n","\n","    accuracy                           0.91      1088\n","   macro avg       0.91      0.91      0.91      1088\n","weighted avg       0.91      0.91      0.91      1088\n","\n","[[459  56]\n"," [ 43 530]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:09<00:32,  1.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005375908243079339; time: 0.6184570789337158s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.79      0.92      0.85       155\n","         1.0       0.91      0.76      0.83       155\n","\n","    accuracy                           0.84       310\n","   macro avg       0.85      0.84      0.84       310\n","weighted avg       0.85      0.84      0.84       310\n","\n","[[143  12]\n"," [ 37 118]]\n","training loss: 0.0003561839257599786; time: 0.7466578483581543s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.92      0.92       516\n","         1.0       0.93      0.92      0.92       572\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[475  41]\n"," [ 45 527]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:11<00:31,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0057555204437625025; time: 0.6304976940155029s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.74      0.83       155\n","         1.0       0.79      0.97      0.87       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.87      0.85      0.85       310\n","weighted avg       0.87      0.85      0.85       310\n","\n","[[114  41]\n"," [  5 150]]\n","training loss: 0.0004180978612329056; time: 0.7255105972290039s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.87      0.88       516\n","         1.0       0.89      0.91      0.90       572\n","\n","    accuracy                           0.89      1088\n","   macro avg       0.89      0.89      0.89      1088\n","weighted avg       0.89      0.89      0.89      1088\n","\n","[[449  67]\n"," [ 54 518]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:12<00:29,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006107890101209763; time: 0.6459646224975586s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.65      0.78       155\n","         1.0       0.74      0.99      0.85       155\n","\n","    accuracy                           0.82       310\n","   macro avg       0.86      0.82      0.81       310\n","weighted avg       0.86      0.82      0.81       310\n","\n","[[101  54]\n"," [  2 153]]\n","training loss: 0.00030756530981949145; time: 0.7324349880218506s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.91      0.91       516\n","         1.0       0.92      0.92      0.92       572\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[471  45]\n"," [ 47 525]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:14<00:28,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005634984109670885; time: 0.6333940029144287s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.72      0.83       155\n","         1.0       0.78      0.97      0.87       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.87      0.85      0.85       310\n","weighted avg       0.87      0.85      0.85       310\n","\n","[[112  43]\n"," [  4 151]]\n","training loss: 0.00035656614161848544; time: 0.70924973487854s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.87      0.89       517\n","         1.0       0.89      0.91      0.90       571\n","\n","    accuracy                           0.89      1088\n","   macro avg       0.89      0.89      0.89      1088\n","weighted avg       0.89      0.89      0.89      1088\n","\n","[[452  65]\n"," [ 52 519]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:15<00:27,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.010892915929998121; time: 0.6652224063873291s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.68      0.96      0.79       155\n","         1.0       0.93      0.54      0.69       155\n","\n","    accuracy                           0.75       310\n","   macro avg       0.81      0.75      0.74       310\n","weighted avg       0.81      0.75      0.74       310\n","\n","[[149   6]\n"," [ 71  84]]\n","training loss: 0.0003634617189128025; time: 0.7321841716766357s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.86      0.87       517\n","         1.0       0.88      0.89      0.89       571\n","\n","    accuracy                           0.88      1088\n","   macro avg       0.88      0.88      0.88      1088\n","weighted avg       0.88      0.88      0.88      1088\n","\n","[[446  71]\n"," [ 61 510]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:17<00:25,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0053247688758757804; time: 0.6135785579681396s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      0.93      0.85       155\n","         1.0       0.91      0.74      0.82       155\n","\n","    accuracy                           0.84       310\n","   macro avg       0.85      0.84      0.83       310\n","weighted avg       0.85      0.84      0.83       310\n","\n","[[144  11]\n"," [ 40 115]]\n","training loss: 0.0002287476791313331; time: 0.6871325969696045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.92      0.90       519\n","         1.0       0.92      0.90      0.91       569\n","\n","    accuracy                           0.91      1088\n","   macro avg       0.91      0.91      0.91      1088\n","weighted avg       0.91      0.91      0.91      1088\n","\n","[[475  44]\n"," [ 56 513]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:18<00:24,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005143858011691801; time: 0.6212189197540283s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.88      0.86       155\n","         1.0       0.88      0.83      0.85       155\n","\n","    accuracy                           0.86       310\n","   macro avg       0.86      0.86      0.86       310\n","weighted avg       0.86      0.86      0.86       310\n","\n","[[137  18]\n"," [ 26 129]]\n","training loss: 0.00021280145772513659; time: 0.6871581077575684s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.90      0.91       517\n","         1.0       0.91      0.93      0.92       571\n","\n","    accuracy                           0.91      1088\n","   macro avg       0.91      0.91      0.91      1088\n","weighted avg       0.91      0.91      0.91      1088\n","\n","[[466  51]\n"," [ 42 529]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:19<00:22,  1.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005137852459184585; time: 0.6274209022521973s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.85      0.87       155\n","         1.0       0.85      0.90      0.87       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.87      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[131  24]\n"," [ 16 139]]\n","training loss: 0.00019479646603120309; time: 0.6908810138702393s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.90      0.90       516\n","         1.0       0.91      0.92      0.91       572\n","\n","    accuracy                           0.91      1088\n","   macro avg       0.91      0.91      0.91      1088\n","weighted avg       0.91      0.91      0.91      1088\n","\n","[[462  54]\n"," [ 46 526]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:21<00:21,  1.40s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0055134425961202195; time: 0.6242156028747559s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.71      0.81       155\n","         1.0       0.77      0.97      0.86       155\n","\n","    accuracy                           0.84       310\n","   macro avg       0.86      0.84      0.84       310\n","weighted avg       0.86      0.84      0.84       310\n","\n","[[110  45]\n"," [  5 150]]\n","training loss: 0.00017993055713732783; time: 0.714768648147583s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.92      0.91       515\n","         1.0       0.93      0.91      0.92       573\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[474  41]\n"," [ 49 524]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:22<00:19,  1.41s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006010243705203457; time: 0.6490535736083984s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.70      0.81       155\n","         1.0       0.76      0.97      0.85       155\n","\n","    accuracy                           0.83       310\n","   macro avg       0.86      0.83      0.83       310\n","weighted avg       0.86      0.83      0.83       310\n","\n","[[108  47]\n"," [  5 150]]\n","training loss: 0.00020721051431096653; time: 0.7074885368347168s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.87      0.89       519\n","         1.0       0.89      0.93      0.91       569\n","\n","    accuracy                           0.90      1088\n","   macro avg       0.90      0.90      0.90      1088\n","weighted avg       0.90      0.90      0.90      1088\n","\n","[[454  65]\n"," [ 42 527]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:24<00:18,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005216740696660934; time: 0.6707322597503662s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.79      0.93      0.85       155\n","         1.0       0.91      0.75      0.83       155\n","\n","    accuracy                           0.84       310\n","   macro avg       0.85      0.84      0.84       310\n","weighted avg       0.85      0.84      0.84       310\n","\n","[[144  11]\n"," [ 38 117]]\n","training loss: 0.0001556304704970102; time: 0.7187507152557373s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.94      0.92       516\n","         1.0       0.95      0.90      0.92       572\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[487  29]\n"," [ 56 516]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:25<00:17,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004957893058176964; time: 0.6262180805206299s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.79      0.86       155\n","         1.0       0.82      0.94      0.88       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.88      0.87      0.87       310\n","weighted avg       0.88      0.87      0.87       310\n","\n","[[123  32]\n"," [  9 146]]\n","training loss: 0.0001411257385948079; time: 0.710618257522583s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.91      0.92       516\n","         1.0       0.92      0.94      0.93       572\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.92      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[468  48]\n"," [ 33 539]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:26<00:15,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004885841040841995; time: 0.6424548625946045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.87      0.85       155\n","         1.0       0.86      0.83      0.84       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.85      0.85      0.85       310\n","weighted avg       0.85      0.85      0.85       310\n","\n","[[135  20]\n"," [ 27 128]]\n","training loss: 0.00013058278401491835; time: 0.73811936378479s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.94      0.93       517\n","         1.0       0.94      0.92      0.93       571\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[484  33]\n"," [ 43 528]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:28<00:14,  1.45s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004899665761378504; time: 0.6594905853271484s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.87      0.85       155\n","         1.0       0.87      0.83      0.85       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.85      0.85      0.85       310\n","weighted avg       0.85      0.85      0.85       310\n","\n","[[135  20]\n"," [ 26 129]]\n","training loss: 0.00012565108507882062; time: 0.7253813743591309s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.94      0.92       518\n","         1.0       0.94      0.91      0.93       570\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[487  31]\n"," [ 50 520]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:29<00:13,  1.45s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004943932304459234; time: 0.6509599685668945s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.83      0.86       155\n","         1.0       0.84      0.90      0.87       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.87      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[129  26]\n"," [ 15 140]]\n","training loss: 0.00012392150910501494; time: 0.7235140800476074s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.89      0.91       516\n","         1.0       0.90      0.95      0.93       572\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[458  58]\n"," [ 28 544]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:31<00:11,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005113287270069123; time: 0.6356549263000488s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.81      0.92      0.86       155\n","         1.0       0.91      0.79      0.84       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[143  12]\n"," [ 33 122]]\n","training loss: 0.00011391259576229716; time: 0.7140693664550781s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.92       521\n","         1.0       0.94      0.92      0.93       567\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[485  36]\n"," [ 45 522]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:32<00:10,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005000359348712429; time: 0.6474790573120117s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.82      0.86       155\n","         1.0       0.84      0.92      0.87       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.87      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[127  28]\n"," [ 13 142]]\n","training loss: 0.00010729424698807884; time: 0.7264142036437988s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.94      0.92       517\n","         1.0       0.95      0.91      0.93       571\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[487  30]\n"," [ 49 522]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:34<00:08,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.00514040877742152; time: 0.6479756832122803s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.77      0.85       155\n","         1.0       0.81      0.95      0.88       155\n","\n","    accuracy                           0.86       310\n","   macro avg       0.88      0.86      0.86       310\n","weighted avg       0.88      0.86      0.86       310\n","\n","[[120  35]\n"," [  7 148]]\n","training loss: 0.00010444921852253816; time: 0.7034955024719238s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.91      0.93       520\n","         1.0       0.92      0.96      0.94       568\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.94      0.93      0.93      1088\n","weighted avg       0.94      0.93      0.93      1088\n","\n","[[473  47]\n"," [ 24 544]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:35<00:07,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004991975282469104; time: 0.6507947444915771s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.92      0.86       155\n","         1.0       0.90      0.79      0.85       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[142  13]\n"," [ 32 123]]\n","training loss: 9.872980586493312e-05; time: 0.7145414352416992s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.92       514\n","         1.0       0.93      0.93      0.93       574\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[472  42]\n"," [ 38 536]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:37<00:05,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005038304386600371; time: 0.6358644962310791s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.82      0.86       155\n","         1.0       0.84      0.92      0.87       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.87      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[127  28]\n"," [ 13 142]]\n","training loss: 9.316008249886155e-05; time: 0.7288877964019775s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.92       518\n","         1.0       0.93      0.93      0.93       570\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[481  37]\n"," [ 42 528]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:38<00:04,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005017618354289762; time: 0.6527187824249268s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.90      0.86       155\n","         1.0       0.89      0.82      0.85       155\n","\n","    accuracy                           0.86       310\n","   macro avg       0.86      0.86      0.86       310\n","weighted avg       0.86      0.86      0.86       310\n","\n","[[139  16]\n"," [ 28 127]]\n","training loss: 9.107416003605962e-05; time: 0.7196085453033447s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.93       518\n","         1.0       0.93      0.93      0.93       570\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[481  37]\n"," [ 41 529]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:39<00:02,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004995011033550385; time: 0.642798662185669s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.83      0.85       155\n","         1.0       0.84      0.88      0.86       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[129  26]\n"," [ 19 136]]\n","training loss: 8.62533405600739e-05; time: 0.7179782390594482s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.93      0.93       520\n","         1.0       0.94      0.93      0.93       568\n","\n","    accuracy                           0.93      1088\n","   macro avg       0.93      0.93      0.93      1088\n","weighted avg       0.93      0.93      0.93      1088\n","\n","[[484  36]\n"," [ 39 529]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:41<00:01,  1.43s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004991329966052886; time: 0.6370081901550293s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.84      0.85       155\n","         1.0       0.84      0.87      0.86       155\n","\n","    accuracy                           0.85       310\n","   macro avg       0.86      0.85      0.85       310\n","weighted avg       0.86      0.85      0.85       310\n","\n","[[130  25]\n"," [ 20 135]]\n","training loss: 8.458433234516312e-05; time: 0.7179150581359863s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.93      0.92       520\n","         1.0       0.94      0.92      0.93       568\n","\n","    accuracy                           0.92      1088\n","   macro avg       0.92      0.92      0.92      1088\n","weighted avg       0.92      0.92      0.92      1088\n","\n","[[485  35]\n"," [ 47 521]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:42<00:00,  1.43s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005076205393960399; time: 0.664247989654541s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.82      0.86       155\n","         1.0       0.84      0.92      0.88       155\n","\n","    accuracy                           0.87       310\n","   macro avg       0.87      0.87      0.87       310\n","weighted avg       0.87      0.87      0.87       310\n","\n","[[127  28]\n"," [ 12 143]]\n","[task=9_ee_vs_aw] (1434, 40) features\n","[task=9_ee_vs_aw] (1434,) labels\n","[task=9_ee_vs_aw] (388, 40) features\n","[task=9_ee_vs_aw] (388,) labels\n","training loss: 0.00467150537720458; time: 0.7380387783050537s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.99      0.92       813\n","         1.0       0.99      0.78      0.87       595\n","\n","    accuracy                           0.90      1408\n","   macro avg       0.92      0.89      0.90      1408\n","weighted avg       0.91      0.90      0.90      1408\n","\n","[[808   5]\n"," [131 464]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:42,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003050505212440933; time: 0.6728644371032715s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.94      0.95       226\n","         1.0       0.92      0.95      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.94      0.95      0.94       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[213  13]\n"," [  8 154]]\n","training loss: 0.0007072626718912612; time: 0.7346646785736084s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.97      0.97       807\n","         1.0       0.96      0.95      0.96       601\n","\n","    accuracy                           0.96      1408\n","   macro avg       0.96      0.96      0.96      1408\n","weighted avg       0.96      0.96      0.96      1408\n","\n","[[784  23]\n"," [ 28 573]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:41,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0022839103998213085; time: 0.657731294631958s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.93      0.94       226\n","         1.0       0.91      0.94      0.92       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.93      0.94      0.93       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[210  16]\n"," [  9 153]]\n","training loss: 0.0004911999613713389; time: 0.7380056381225586s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.98      0.97       812\n","         1.0       0.97      0.95      0.96       596\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.97      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[795  17]\n"," [ 27 569]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:39,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008566089132296633; time: 0.6658480167388916s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.78      0.87       226\n","         1.0       0.76      0.99      0.86       162\n","\n","    accuracy                           0.87       388\n","   macro avg       0.88      0.89      0.87       388\n","weighted avg       0.90      0.87      0.87       388\n","\n","[[176  50]\n"," [  1 161]]\n","training loss: 0.0005003269930470692; time: 0.7536489963531494s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.96      0.96       811\n","         1.0       0.95      0.96      0.95       597\n","\n","    accuracy                           0.96      1408\n","   macro avg       0.96      0.96      0.96      1408\n","weighted avg       0.96      0.96      0.96      1408\n","\n","[[778  33]\n"," [ 25 572]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:38,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0036376174371305506; time: 0.6674847602844238s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.86      0.92       226\n","         1.0       0.83      0.98      0.90       162\n","\n","    accuracy                           0.91       388\n","   macro avg       0.91      0.92      0.91       388\n","weighted avg       0.92      0.91      0.91       388\n","\n","[[194  32]\n"," [  3 159]]\n","training loss: 0.0002743959497655107; time: 0.7722086906433105s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.97      0.97       808\n","         1.0       0.96      0.97      0.96       600\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.97      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[781  27]\n"," [ 20 580]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:37,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004106188889055215; time: 0.7098135948181152s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.83      0.90       226\n","         1.0       0.81      0.98      0.89       162\n","\n","    accuracy                           0.89       388\n","   macro avg       0.90      0.91      0.89       388\n","weighted avg       0.91      0.89      0.90       388\n","\n","[[188  38]\n"," [  3 159]]\n","training loss: 0.0003135630214466911; time: 0.7351517677307129s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.97      0.96       813\n","         1.0       0.96      0.94      0.95       595\n","\n","    accuracy                           0.96      1408\n","   macro avg       0.96      0.96      0.96      1408\n","weighted avg       0.96      0.96      0.96      1408\n","\n","[[790  23]\n"," [ 35 560]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:09<00:36,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.008775709701591585; time: 0.6874966621398926s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.76      0.86       226\n","         1.0       0.75      1.00      0.85       162\n","\n","    accuracy                           0.86       388\n","   macro avg       0.87      0.88      0.86       388\n","weighted avg       0.89      0.86      0.86       388\n","\n","[[171  55]\n"," [  0 162]]\n","training loss: 0.00021828592859976623; time: 0.7458422183990479s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.97      0.97       814\n","         1.0       0.95      0.96      0.96       594\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.96      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[787  27]\n"," [ 21 573]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:10<00:34,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0020510039397889806; time: 0.6448962688446045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.97      0.96       226\n","         1.0       0.96      0.94      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.96      0.96       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[220   6]\n"," [ 10 152]]\n","training loss: 0.00012005132901487576; time: 0.7332439422607422s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       808\n","         1.0       0.98      0.97      0.97       600\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[797  11]\n"," [ 19 581]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:11<00:32,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0022901522005264905; time: 0.6583170890808105s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.94      0.95       226\n","         1.0       0.92      0.94      0.93       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.94      0.94      0.94       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[212  14]\n"," [ 10 152]]\n","training loss: 9.533973780256046e-05; time: 0.7319324016571045s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.98      0.98       807\n","         1.0       0.97      0.97      0.97       601\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[792  15]\n"," [ 18 583]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:13<00:31,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003247812205503128; time: 0.631650447845459s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.89      0.93       226\n","         1.0       0.86      0.97      0.91       162\n","\n","    accuracy                           0.92       388\n","   macro avg       0.92      0.93      0.92       388\n","weighted avg       0.93      0.92      0.92       388\n","\n","[[201  25]\n"," [  5 157]]\n","training loss: 0.0002022629296830432; time: 0.7241418361663818s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.97      0.96       811\n","         1.0       0.96      0.94      0.95       597\n","\n","    accuracy                           0.96      1408\n","   macro avg       0.96      0.95      0.95      1408\n","weighted avg       0.96      0.96      0.96      1408\n","\n","[[785  26]\n"," [ 37 560]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:14<00:29,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0019544052324958682; time: 0.6623170375823975s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.98      0.96       226\n","         1.0       0.97      0.92      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.95      0.95       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[222   4]\n"," [ 13 149]]\n","training loss: 0.00013689380062143665; time: 0.720672607421875s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.96      0.96       811\n","         1.0       0.95      0.96      0.95       597\n","\n","    accuracy                           0.96      1408\n","   macro avg       0.96      0.96      0.96      1408\n","weighted avg       0.96      0.96      0.96      1408\n","\n","[[778  33]\n"," [ 26 571]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:16<00:28,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002533294356514498; time: 0.6725819110870361s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.93      0.94       226\n","         1.0       0.90      0.94      0.92       162\n","\n","    accuracy                           0.93       388\n","   macro avg       0.93      0.93      0.93       388\n","weighted avg       0.93      0.93      0.93       388\n","\n","[[210  16]\n"," [ 10 152]]\n","training loss: 7.573115065249361e-05; time: 0.7287611961364746s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       813\n","         1.0       0.98      0.97      0.97       595\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[802  11]\n"," [ 19 576]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:17<00:26,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0028840693376343887; time: 0.6536533832550049s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.90      0.93       226\n","         1.0       0.88      0.95      0.91       162\n","\n","    accuracy                           0.92       388\n","   macro avg       0.92      0.93      0.92       388\n","weighted avg       0.93      0.92      0.92       388\n","\n","[[204  22]\n"," [  8 154]]\n","training loss: 5.990021610331324e-05; time: 0.7417359352111816s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       812\n","         1.0       0.98      0.97      0.98       596\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[800  12]\n"," [ 17 579]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:19<00:25,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0020941463635139857; time: 0.6574018001556396s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.96      0.96       226\n","         1.0       0.94      0.94      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.95      0.95      0.95       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[217   9]\n"," [ 10 152]]\n","training loss: 5.167941339828025e-05; time: 0.745621919631958s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       811\n","         1.0       0.99      0.97      0.98       597\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[803   8]\n"," [ 17 580]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:20<00:23,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003116095784245078; time: 0.662229061126709s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.89      0.93       226\n","         1.0       0.86      0.97      0.91       162\n","\n","    accuracy                           0.92       388\n","   macro avg       0.92      0.93      0.92       388\n","weighted avg       0.93      0.92      0.92       388\n","\n","[[201  25]\n"," [  5 157]]\n","training loss: 8.667077362946601e-05; time: 0.7270305156707764s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.98      0.98       811\n","         1.0       0.97      0.97      0.97       597\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.97      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[791  20]\n"," [ 20 577]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:22<00:22,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002232855848353548; time: 0.6480538845062256s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.94      0.95       226\n","         1.0       0.92      0.94      0.93       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.94      0.94      0.94       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[213  13]\n"," [ 10 152]]\n","training loss: 6.413249758969124e-05; time: 0.732464075088501s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.98      0.98       810\n","         1.0       0.97      0.97      0.97       598\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.97      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[791  19]\n"," [ 20 578]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:23<00:20,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0020338825151785134; time: 0.6427373886108398s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.98      0.96       226\n","         1.0       0.97      0.91      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.96      0.95      0.95       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[222   4]\n"," [ 14 148]]\n","training loss: 5.7716992782381546e-05; time: 0.753265380859375s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.98      0.98       815\n","         1.0       0.97      0.96      0.97       593\n","\n","    accuracy                           0.97      1408\n","   macro avg       0.97      0.97      0.97      1408\n","weighted avg       0.97      0.97      0.97      1408\n","\n","[[800  15]\n"," [ 21 572]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:25<00:19,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003444918798589983; time: 0.648338794708252s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.87      0.92       226\n","         1.0       0.84      0.98      0.91       162\n","\n","    accuracy                           0.91       388\n","   macro avg       0.91      0.92      0.91       388\n","weighted avg       0.92      0.91      0.92       388\n","\n","[[196  30]\n"," [  3 159]]\n","training loss: 4.3655702837794604e-05; time: 0.7251720428466797s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       808\n","         1.0       0.98      0.97      0.98       600\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[798  10]\n"," [ 18 582]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:26<00:17,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002090342035613109; time: 0.6671791076660156s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.96      0.96       226\n","         1.0       0.94      0.94      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.95      0.95      0.95       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[217   9]\n"," [ 10 152]]\n","training loss: 4.367235471198166e-05; time: 0.744680643081665s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.98      0.98       811\n","         1.0       0.98      0.97      0.97       597\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[797  14]\n"," [ 16 581]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:28<00:16,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0021860535381381043; time: 0.6483376026153564s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.94      0.95       226\n","         1.0       0.92      0.94      0.93       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.94      0.94      0.94       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[213  13]\n"," [ 10 152]]\n","training loss: 4.794864185400498e-05; time: 0.7183041572570801s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.98      0.98       812\n","         1.0       0.97      0.97      0.97       596\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[797  15]\n"," [ 18 578]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:29<00:14,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0021731184085005337; time: 0.6614015102386475s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.95      0.95       226\n","         1.0       0.93      0.94      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.94      0.94      0.94       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[215  11]\n"," [ 10 152]]\n","training loss: 3.6246810622212935e-05; time: 0.733729362487793s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       807\n","         1.0       0.98      0.97      0.98       601\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[797  10]\n"," [ 18 583]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:31<00:13,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0020176533311989505; time: 0.6531853675842285s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.98      0.96       226\n","         1.0       0.97      0.92      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.95      0.95       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[222   4]\n"," [ 13 149]]\n","training loss: 3.431764605559971e-05; time: 0.7513930797576904s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.98       814\n","         1.0       0.98      0.97      0.98       594\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[803  11]\n"," [ 17 577]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:32<00:11,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0019662501962529016; time: 0.6987597942352295s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.98      0.97       226\n","         1.0       0.97      0.94      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.96      0.96       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[221   5]\n"," [ 10 152]]\n","training loss: 2.7903799390813276e-05; time: 0.739001989364624s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.99       810\n","         1.0       0.99      0.97      0.98       598\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[805   5]\n"," [ 18 580]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:34<00:10,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0022676321821882553; time: 0.6548218727111816s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.93      0.94       226\n","         1.0       0.91      0.94      0.92       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.93      0.94      0.93       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[210  16]\n"," [  9 153]]\n","training loss: 2.59836639143583e-05; time: 0.757225513458252s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.99      0.99       811\n","         1.0       0.98      0.98      0.98       597\n","\n","    accuracy                           0.99      1408\n","   macro avg       0.99      0.99      0.99      1408\n","weighted avg       0.99      0.99      0.99      1408\n","\n","[[801  10]\n"," [ 10 587]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:35<00:08,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.001962029336730844; time: 0.6754186153411865s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.98      0.97       226\n","         1.0       0.97      0.94      0.96       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.97      0.96      0.96       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[222   4]\n"," [ 10 152]]\n","training loss: 2.5939711433073338e-05; time: 0.7214512825012207s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.99       812\n","         1.0       0.98      0.98      0.98       596\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[803   9]\n"," [ 14 582]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:37<00:07,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002001476637327794; time: 0.6495628356933594s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.97      0.96       226\n","         1.0       0.96      0.94      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.95      0.95       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[219   7]\n"," [ 10 152]]\n","training loss: 2.357865846883774e-05; time: 0.7315921783447266s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.99       811\n","         1.0       0.99      0.98      0.98       597\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[803   8]\n"," [ 14 583]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:38<00:05,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0020850771922886987; time: 0.6604034900665283s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.96      0.96       226\n","         1.0       0.94      0.94      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.95      0.95      0.95       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[217   9]\n"," [ 10 152]]\n","training loss: 2.3661201247696133e-05; time: 0.7521686553955078s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.99       811\n","         1.0       0.98      0.98      0.98       597\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[802   9]\n"," [ 13 584]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:40<00:04,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002242184608944298; time: 0.6732370853424072s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.93      0.94       226\n","         1.0       0.91      0.94      0.92       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.93      0.94      0.93       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[211  15]\n"," [ 10 152]]\n","training loss: 2.2833874523216352e-05; time: 0.7461233139038086s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.99      0.99       812\n","         1.0       0.98      0.98      0.98       596\n","\n","    accuracy                           0.98      1408\n","   macro avg       0.98      0.98      0.98      1408\n","weighted avg       0.98      0.98      0.98      1408\n","\n","[[802  10]\n"," [ 14 582]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:41<00:02,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002214212369020145; time: 0.6671037673950195s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.95      0.95       226\n","         1.0       0.93      0.94      0.93       162\n","\n","    accuracy                           0.94       388\n","   macro avg       0.94      0.94      0.94       388\n","weighted avg       0.94      0.94      0.94       388\n","\n","[[214  12]\n"," [ 10 152]]\n","training loss: 2.067556552191887e-05; time: 0.7300817966461182s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.99      0.99       809\n","         1.0       0.98      0.98      0.98       599\n","\n","    accuracy                           0.99      1408\n","   macro avg       0.99      0.99      0.99      1408\n","weighted avg       0.99      0.99      0.99      1408\n","\n","[[800   9]\n"," [ 11 588]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:43<00:01,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.001986187210632968; time: 0.6711750030517578s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.98      0.97       226\n","         1.0       0.97      0.94      0.95       162\n","\n","    accuracy                           0.96       388\n","   macro avg       0.96      0.96      0.96       388\n","weighted avg       0.96      0.96      0.96       388\n","\n","[[221   5]\n"," [ 10 152]]\n","training loss: 2.0490299214019835e-05; time: 0.7478890419006348s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.99      0.99       809\n","         1.0       0.98      0.98      0.98       599\n","\n","    accuracy                           0.99      1408\n","   macro avg       0.99      0.99      0.99      1408\n","weighted avg       0.99      0.99      0.99      1408\n","\n","[[800   9]\n"," [ 11 588]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0021328414339072924; time: 0.6828145980834961s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.96      0.96       226\n","         1.0       0.94      0.94      0.94       162\n","\n","    accuracy                           0.95       388\n","   macro avg       0.95      0.95      0.95       388\n","weighted avg       0.95      0.95      0.95       388\n","\n","[[216  10]\n"," [ 10 152]]\n","[task=10_ah_vs_aw] (1201, 40) features\n","[task=10_ah_vs_aw] (1201,) labels\n","[task=10_ah_vs_aw] (305, 40) features\n","[task=10_ah_vs_aw] (305,) labels\n","training loss: 0.007754202854509155; time: 0.7133502960205078s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.82      0.76      0.79       573\n","         1.0       0.78      0.83      0.80       579\n","\n","    accuracy                           0.80      1152\n","   macro avg       0.80      0.80      0.80      1152\n","weighted avg       0.80      0.80      0.80      1152\n","\n","[[436 137]\n"," [ 98 481]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:41,  1.42s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005594379589205883; time: 0.6540980339050293s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.71      0.81       143\n","         1.0       0.79      0.96      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.84       305\n","weighted avg       0.86      0.84      0.84       305\n","\n","[[101  42]\n"," [  6 156]]\n","training loss: 0.002521995118715697; time: 0.7452459335327148s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       572\n","         1.0       0.89      0.89      0.89       580\n","\n","    accuracy                           0.89      1152\n","   macro avg       0.89      0.89      0.89      1152\n","weighted avg       0.89      0.89      0.89      1152\n","\n","[[511  61]\n"," [ 65 515]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:40,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.012252647733529572; time: 0.6470654010772705s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.52      0.69       143\n","         1.0       0.70      1.00      0.83       162\n","\n","    accuracy                           0.78       305\n","   macro avg       0.85      0.76      0.76       305\n","weighted avg       0.84      0.78      0.76       305\n","\n","[[ 75  68]\n"," [  0 162]]\n","training loss: 0.0037297195263413917; time: 0.7071278095245361s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      0.78      0.76       569\n","         1.0       0.78      0.75      0.76       583\n","\n","    accuracy                           0.76      1152\n","   macro avg       0.76      0.76      0.76      1152\n","weighted avg       0.76      0.76      0.76      1152\n","\n","[[444 125]\n"," [148 435]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:38,  1.44s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.011132419695619677; time: 0.6745991706848145s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.24      0.38       143\n","         1.0       0.60      1.00      0.75       162\n","\n","    accuracy                           0.64       305\n","   macro avg       0.80      0.62      0.57       305\n","weighted avg       0.79      0.64      0.58       305\n","\n","[[ 34 109]\n"," [  0 162]]\n","training loss: 0.001228352266480215; time: 0.8870177268981934s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.82      0.87       567\n","         1.0       0.84      0.93      0.88       585\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[464 103]\n"," [ 39 546]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:38,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006758985753919257; time: 0.6545543670654297s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.75      1.00      0.86       143\n","         1.0       1.00      0.71      0.83       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.88      0.85      0.84       305\n","weighted avg       0.88      0.85      0.84       305\n","\n","[[143   0]\n"," [ 47 115]]\n","training loss: 0.0014776109562565883; time: 0.7243108749389648s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.87      0.86       572\n","         1.0       0.87      0.84      0.85       580\n","\n","    accuracy                           0.85      1152\n","   macro avg       0.85      0.85      0.85      1152\n","weighted avg       0.85      0.85      0.85      1152\n","\n","[[496  76]\n"," [ 92 488]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:36,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0041525226636011095; time: 0.6480402946472168s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       143\n","         1.0       0.90      0.90      0.90       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.89      0.89      0.89       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[127  16]\n"," [ 16 146]]\n","training loss: 0.0008513290538556046; time: 0.7528879642486572s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.87      0.88       572\n","         1.0       0.87      0.90      0.89       580\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[495  77]\n"," [ 57 523]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:08<00:35,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004909581385675024; time: 0.6480977535247803s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.99      0.87       143\n","         1.0       0.98      0.75      0.85       162\n","\n","    accuracy                           0.86       305\n","   macro avg       0.88      0.87      0.86       305\n","weighted avg       0.89      0.86      0.86       305\n","\n","[[141   2]\n"," [ 41 121]]\n","training loss: 0.000395620119802299; time: 0.7148466110229492s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94       570\n","         1.0       0.94      0.93      0.94       582\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[538  32]\n"," [ 39 543]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:10<00:33,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003901127664769282; time: 0.6640264987945557s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.86      0.89       143\n","         1.0       0.88      0.93      0.91       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.90      0.90      0.90       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[123  20]\n"," [ 11 151]]\n","training loss: 0.00030584313531613187; time: 0.720454216003418s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.94      0.94       564\n","         1.0       0.94      0.94      0.94       588\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[528  36]\n"," [ 36 552]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:11<00:32,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004436726501730622; time: 0.6811161041259766s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.75      0.84       143\n","         1.0       0.81      0.96      0.88       162\n","\n","    accuracy                           0.86       305\n","   macro avg       0.88      0.86      0.86       305\n","weighted avg       0.88      0.86      0.86       305\n","\n","[[107  36]\n"," [  6 156]]\n","training loss: 0.00023896811187934178; time: 0.7312569618225098s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.94      0.95       562\n","         1.0       0.95      0.95      0.95       590\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[531  31]\n"," [ 29 561]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:13<00:30,  1.46s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004834475050695607; time: 0.6508245468139648s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.71      0.81       143\n","         1.0       0.79      0.96      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.84       305\n","weighted avg       0.86      0.84      0.84       305\n","\n","[[101  42]\n"," [  6 156]]\n","training loss: 0.0003018020872130162; time: 0.7359423637390137s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.93       563\n","         1.0       0.93      0.93      0.93       589\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[519  44]\n"," [ 39 550]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:14<00:29,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004276893153542378; time: 0.6712846755981445s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.83      0.99      0.90       143\n","         1.0       0.99      0.83      0.90       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.91      0.91      0.90       305\n","weighted avg       0.91      0.90      0.90       305\n","\n","[[141   2]\n"," [ 28 134]]\n","training loss: 0.00026203236234553085; time: 0.7517869472503662s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.93       574\n","         1.0       0.94      0.93      0.93       578\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[537  37]\n"," [ 42 536]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:16<00:28,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004514366803599186; time: 0.6653971672058105s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.71      0.81       143\n","         1.0       0.79      0.96      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.84       305\n","weighted avg       0.86      0.84      0.84       305\n","\n","[[101  42]\n"," [  6 156]]\n","training loss: 0.00017530126313903128; time: 0.7403576374053955s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95       571\n","         1.0       0.95      0.94      0.95       581\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[543  28]\n"," [ 34 547]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:17<00:26,  1.47s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003408052735641354; time: 0.6552190780639648s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.88      0.90       143\n","         1.0       0.90      0.93      0.92       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.91      0.91      0.91       305\n","weighted avg       0.91      0.91      0.91       305\n","\n","[[126  17]\n"," [ 11 151]]\n","training loss: 0.00021155254863616492; time: 0.7582077980041504s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.93      0.93       570\n","         1.0       0.93      0.93      0.93       582\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[532  38]\n"," [ 40 542]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:19<00:25,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005065641393426989; time: 0.671623706817627s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.70      0.80       143\n","         1.0       0.78      0.96      0.86       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.86      0.83      0.83       305\n","weighted avg       0.86      0.84      0.84       305\n","\n","[[100  43]\n"," [  6 156]]\n","training loss: 0.0001640505146323925; time: 0.7422089576721191s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94       570\n","         1.0       0.95      0.94      0.94       582\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[540  30]\n"," [ 34 548]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:20<00:23,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0043891292370733664; time: 0.6681864261627197s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.78      0.86       143\n","         1.0       0.83      0.97      0.89       162\n","\n","    accuracy                           0.88       305\n","   macro avg       0.89      0.87      0.88       305\n","weighted avg       0.89      0.88      0.88       305\n","\n","[[111  32]\n"," [  5 157]]\n","training loss: 0.00015299906221183913; time: 0.7443695068359375s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.93       575\n","         1.0       0.94      0.93      0.93       577\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[538  37]\n"," [ 41 536]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:22<00:22,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005633419568909974; time: 0.6686360836029053s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.65      0.77       143\n","         1.0       0.76      0.98      0.85       162\n","\n","    accuracy                           0.82       305\n","   macro avg       0.86      0.81      0.81       305\n","weighted avg       0.85      0.82      0.82       305\n","\n","[[ 93  50]\n"," [  4 158]]\n","training loss: 0.00015788719813119515; time: 0.733555793762207s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94       568\n","         1.0       0.94      0.93      0.94       584\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[533  35]\n"," [ 38 546]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:23<00:20,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004282722805367141; time: 0.6647157669067383s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.73      0.82       143\n","         1.0       0.80      0.96      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.87      0.85      0.85       305\n","weighted avg       0.87      0.85      0.85       305\n","\n","[[104  39]\n"," [  6 156]]\n","training loss: 0.00011899549281224608; time: 0.7502050399780273s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95       574\n","         1.0       0.95      0.94      0.95       578\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[548  26]\n"," [ 34 544]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:25<00:19,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005928861404784391; time: 0.6965744495391846s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.66      0.79       143\n","         1.0       0.77      0.99      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.88      0.83      0.83       305\n","weighted avg       0.87      0.84      0.83       305\n","\n","[[ 94  49]\n"," [  1 161]]\n","training loss: 0.00015736278362089284; time: 0.7520129680633545s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.93       570\n","         1.0       0.92      0.94      0.93       582\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[524  46]\n"," [ 37 545]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:26<00:17,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005038560731489151; time: 0.6589245796203613s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.77      0.95      0.85       143\n","         1.0       0.95      0.75      0.84       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.86      0.85      0.85       305\n","weighted avg       0.86      0.85      0.85       305\n","\n","[[136   7]\n"," [ 40 122]]\n","training loss: 0.00012867705170092395; time: 0.7560443878173828s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.95      0.93       571\n","         1.0       0.95      0.91      0.93       581\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[544  27]\n"," [ 53 528]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:28<00:16,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004130720615875526; time: 0.6702156066894531s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.73      0.82       143\n","         1.0       0.80      0.96      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.87      0.85      0.85       305\n","weighted avg       0.87      0.85      0.85       305\n","\n","[[104  39]\n"," [  6 156]]\n","training loss: 9.45008996899964e-05; time: 0.7397282123565674s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       566\n","         1.0       0.95      0.95      0.95       586\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[535  31]\n"," [ 31 555]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:29<00:14,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003752257833715345; time: 0.6572291851043701s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.78      0.85       143\n","         1.0       0.83      0.96      0.89       162\n","\n","    accuracy                           0.88       305\n","   macro avg       0.89      0.87      0.87       305\n","weighted avg       0.89      0.88      0.87       305\n","\n","[[111  32]\n"," [  6 156]]\n","training loss: 9.515202264227564e-05; time: 0.7457647323608398s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94       575\n","         1.0       0.95      0.94      0.94       577\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[544  31]\n"," [ 34 543]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:31<00:13,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003503119676816659; time: 0.6795778274536133s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.86      0.98      0.92       143\n","         1.0       0.98      0.86      0.92       162\n","\n","    accuracy                           0.92       305\n","   macro avg       0.92      0.92      0.92       305\n","weighted avg       0.93      0.92      0.92       305\n","\n","[[140   3]\n"," [ 22 140]]\n","training loss: 0.0001222824391490319; time: 0.7587995529174805s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.93       574\n","         1.0       0.92      0.93      0.93       578\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[530  44]\n"," [ 39 539]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:32<00:11,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0033512724471873923; time: 0.6703994274139404s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.83      0.88       143\n","         1.0       0.86      0.96      0.91       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.91      0.89      0.90       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[118  25]\n"," [  6 156]]\n","training loss: 7.787415170637162e-05; time: 0.7425639629364014s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95       567\n","         1.0       0.96      0.94      0.95       585\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[545  22]\n"," [ 33 552]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:34<00:10,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0037489697092869243; time: 0.6934285163879395s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.78      0.85       143\n","         1.0       0.83      0.96      0.89       162\n","\n","    accuracy                           0.87       305\n","   macro avg       0.88      0.87      0.87       305\n","weighted avg       0.88      0.87      0.87       305\n","\n","[[111  32]\n"," [  7 155]]\n","training loss: 8.549389086611982e-05; time: 0.751166820526123s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94       566\n","         1.0       0.94      0.94      0.94       586\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[530  36]\n"," [ 37 549]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:35<00:08,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0033868467710057243; time: 0.6784193515777588s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.98      0.92       143\n","         1.0       0.98      0.88      0.93       162\n","\n","    accuracy                           0.92       305\n","   macro avg       0.93      0.93      0.92       305\n","weighted avg       0.93      0.92      0.92       305\n","\n","[[140   3]\n"," [ 20 142]]\n","training loss: 7.344986907102995e-05; time: 0.7762124538421631s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94       560\n","         1.0       0.95      0.94      0.95       592\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[531  29]\n"," [ 34 558]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:37<00:07,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003474439338582461; time: 0.6864500045776367s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.79      0.86       143\n","         1.0       0.84      0.96      0.90       162\n","\n","    accuracy                           0.88       305\n","   macro avg       0.89      0.88      0.88       305\n","weighted avg       0.89      0.88      0.88       305\n","\n","[[113  30]\n"," [  6 156]]\n","training loss: 7.296471685394007e-05; time: 0.7662687301635742s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       567\n","         1.0       0.95      0.95      0.95       585\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[539  28]\n"," [ 29 556]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:38<00:06,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0036445198489017173; time: 0.667844295501709s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.78      0.86       143\n","         1.0       0.83      0.96      0.89       162\n","\n","    accuracy                           0.88       305\n","   macro avg       0.89      0.87      0.88       305\n","weighted avg       0.89      0.88      0.88       305\n","\n","[[112  31]\n"," [  6 156]]\n","training loss: 7.648970282621253e-05; time: 0.7539942264556885s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.94      0.94       573\n","         1.0       0.94      0.94      0.94       579\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[541  32]\n"," [ 34 545]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:40<00:04,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006450935590584747; time: 0.6885485649108887s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.78      1.00      0.88       143\n","         1.0       1.00      0.75      0.86       162\n","\n","    accuracy                           0.87       305\n","   macro avg       0.89      0.88      0.87       305\n","weighted avg       0.90      0.87      0.87       305\n","\n","[[143   0]\n"," [ 40 122]]\n","training loss: 9.991765592343336e-05; time: 0.7387027740478516s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.93       569\n","         1.0       0.94      0.92      0.93       583\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[532  37]\n"," [ 48 535]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:41<00:03,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005279986010711701; time: 0.6902918815612793s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.98      0.66      0.79       143\n","         1.0       0.77      0.99      0.86       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.83       305\n","weighted avg       0.87      0.84      0.83       305\n","\n","[[ 95  48]\n"," [  2 160]]\n","training loss: 6.738204176277207e-05; time: 0.7415444850921631s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.94      0.94       565\n","         1.0       0.94      0.95      0.95       587\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[529  36]\n"," [ 28 559]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:43<00:01,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003682877489777862; time: 0.6818883419036865s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.99      0.91       143\n","         1.0       0.99      0.83      0.90       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.91      0.91      0.90       305\n","weighted avg       0.92      0.90      0.90       305\n","\n","[[141   2]\n"," [ 27 135]]\n","training loss: 6.390203639899416e-05; time: 0.7314167022705078s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.95      0.94       571\n","         1.0       0.95      0.93      0.94       581\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[545  26]\n"," [ 42 539]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:44<00:00,  1.49s/it]\n","\n","  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003323353753715265; time: 0.6594605445861816s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.81      0.88       143\n","         1.0       0.85      0.96      0.90       162\n","\n","    accuracy                           0.89       305\n","   macro avg       0.90      0.89      0.89       305\n","weighted avg       0.90      0.89      0.89       305\n","\n","[[116  27]\n"," [  6 156]]\n","[task=11_mm_vs_nn] (1201, 40) features\n","[task=11_mm_vs_nn] (1201,) labels\n","[task=11_mm_vs_nn] (305, 40) features\n","[task=11_mm_vs_nn] (305,) labels\n","training loss: 0.00735497301340931; time: 0.7447822093963623s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.76      0.81       559\n","         1.0       0.80      0.89      0.84       593\n","\n","    accuracy                           0.83      1152\n","   macro avg       0.83      0.83      0.83      1152\n","weighted avg       0.83      0.83      0.83      1152\n","\n","[[426 133]\n"," [ 66 527]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  3%|▎         | 1/30 [00:01<00:43,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.01099823119698978; time: 0.6877670288085938s\n","              precision    recall  f1-score   support\n","\n","         0.0       1.00      0.25      0.40       143\n","         1.0       0.60      1.00      0.75       162\n","\n","    accuracy                           0.65       305\n","   macro avg       0.80      0.63      0.58       305\n","weighted avg       0.79      0.65      0.59       305\n","\n","[[ 36 107]\n"," [  0 162]]\n","training loss: 0.0023043024282540297; time: 0.7342147827148438s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.88      0.86      0.87       559\n","         1.0       0.87      0.89      0.88       593\n","\n","    accuracy                           0.88      1152\n","   macro avg       0.88      0.88      0.88      1152\n","weighted avg       0.88      0.88      0.88      1152\n","\n","[[483  76]\n"," [ 65 528]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","  7%|▋         | 2/30 [00:02<00:41,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005704946522829962; time: 0.6855924129486084s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.66      0.78       143\n","         1.0       0.76      0.98      0.86       162\n","\n","    accuracy                           0.83       305\n","   macro avg       0.87      0.82      0.82       305\n","weighted avg       0.86      0.83      0.82       305\n","\n","[[ 94  49]\n"," [  3 159]]\n","training loss: 0.0015103283782351624; time: 0.733243465423584s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.89      0.89       568\n","         1.0       0.89      0.90      0.90       584\n","\n","    accuracy                           0.89      1152\n","   macro avg       0.89      0.89      0.89      1152\n","weighted avg       0.89      0.89      0.89      1152\n","\n","[[505  63]\n"," [ 59 525]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 10%|█         | 3/30 [00:04<00:39,  1.48s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0048524874155638645; time: 0.6722052097320557s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.76      0.84       143\n","         1.0       0.82      0.97      0.89       162\n","\n","    accuracy                           0.87       305\n","   macro avg       0.89      0.86      0.87       305\n","weighted avg       0.88      0.87      0.87       305\n","\n","[[108  35]\n"," [  5 157]]\n","training loss: 0.0007408106111041787; time: 0.7524604797363281s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.93      0.93       565\n","         1.0       0.93      0.93      0.93       587\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[525  40]\n"," [ 43 544]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 13%|█▎        | 4/30 [00:05<00:38,  1.49s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004002583124598519; time: 0.6820027828216553s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.87      0.95      0.91       143\n","         1.0       0.95      0.87      0.91       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.91      0.91      0.91       305\n","weighted avg       0.91      0.91      0.91       305\n","\n","[[136   7]\n"," [ 21 141]]\n","training loss: 0.0004976169568383031; time: 0.757260799407959s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.93      0.93       562\n","         1.0       0.94      0.93      0.93       590\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[524  38]\n"," [ 40 550]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 17%|█▋        | 5/30 [00:07<00:37,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004536157541099142; time: 0.6894986629486084s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.73      0.82       143\n","         1.0       0.80      0.96      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.87      0.85      0.85       305\n","weighted avg       0.87      0.85      0.85       305\n","\n","[[104  39]\n"," [  6 156]]\n","training loss: 0.0006385586586677366; time: 0.7539544105529785s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.91      0.90       559\n","         1.0       0.91      0.90      0.91       593\n","\n","    accuracy                           0.90      1152\n","   macro avg       0.90      0.90      0.90      1152\n","weighted avg       0.90      0.90      0.90      1152\n","\n","[[506  53]\n"," [ 59 534]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 20%|██        | 6/30 [00:08<00:35,  1.50s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.007367252338616574; time: 0.6740777492523193s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.56      0.71       143\n","         1.0       0.72      0.99      0.83       162\n","\n","    accuracy                           0.79       305\n","   macro avg       0.85      0.78      0.77       305\n","weighted avg       0.84      0.79      0.78       305\n","\n","[[ 80  63]\n"," [  1 161]]\n","training loss: 0.0004398901568030909; time: 0.7662642002105713s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.92       571\n","         1.0       0.91      0.92      0.92       581\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[521  50]\n"," [ 44 537]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 23%|██▎       | 7/30 [00:10<00:34,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004303578446145918; time: 0.7126853466033936s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.76      0.84       143\n","         1.0       0.82      0.96      0.88       162\n","\n","    accuracy                           0.87       305\n","   macro avg       0.88      0.86      0.86       305\n","weighted avg       0.88      0.87      0.86       305\n","\n","[[108  35]\n"," [  6 156]]\n","training loss: 0.00029893149783472635; time: 0.7692837715148926s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.93      0.93       573\n","         1.0       0.93      0.93      0.93       579\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[535  38]\n"," [ 41 538]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 27%|██▋       | 8/30 [00:12<00:33,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0037156919475461615; time: 0.6760835647583008s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.89      0.89       143\n","         1.0       0.90      0.91      0.90       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.90      0.90      0.90       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[127  16]\n"," [ 15 147]]\n","training loss: 0.0003554137606162256; time: 0.7585618495941162s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.92       561\n","         1.0       0.92      0.93      0.92       591\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[511  50]\n"," [ 43 548]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 30%|███       | 9/30 [00:13<00:31,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005098454690858966; time: 0.6720373630523682s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.96      0.70      0.81       143\n","         1.0       0.79      0.98      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.87      0.84      0.84       305\n","weighted avg       0.87      0.85      0.84       305\n","\n","[[100  43]\n"," [  4 158]]\n","training loss: 0.00028445614346613485; time: 0.7558026313781738s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.91      0.91       568\n","         1.0       0.91      0.92      0.92       584\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[518  50]\n"," [ 47 537]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 33%|███▎      | 10/30 [00:15<00:30,  1.53s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004253924796815778; time: 0.7089591026306152s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.71      0.81       143\n","         1.0       0.79      0.96      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.87      0.84      0.84       305\n","weighted avg       0.86      0.85      0.84       305\n","\n","[[102  41]\n"," [  6 156]]\n","training loss: 0.00020561237864177487; time: 0.7489414215087891s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94       568\n","         1.0       0.95      0.94      0.95       584\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[538  30]\n"," [ 33 551]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 37%|███▋      | 11/30 [00:16<00:28,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0047325080901872915; time: 0.6750056743621826s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.71      0.81       143\n","         1.0       0.79      0.96      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.84       305\n","weighted avg       0.86      0.84      0.84       305\n","\n","[[101  42]\n"," [  6 156]]\n","training loss: 0.00017462607044122974; time: 0.7497389316558838s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.94       572\n","         1.0       0.95      0.94      0.94       580\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[541  31]\n"," [ 34 546]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 40%|████      | 12/30 [00:18<00:27,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003907783256202448; time: 0.6784110069274902s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.81      0.88       143\n","         1.0       0.85      0.96      0.90       162\n","\n","    accuracy                           0.89       305\n","   macro avg       0.90      0.89      0.89       305\n","weighted avg       0.90      0.89      0.89       305\n","\n","[[116  27]\n"," [  6 156]]\n","training loss: 0.0002495064310586223; time: 0.7585608959197998s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.91      0.92       572\n","         1.0       0.92      0.93      0.92       580\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[522  50]\n"," [ 40 540]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 43%|████▎     | 13/30 [00:19<00:25,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003350176356854986; time: 0.6834032535552979s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.87      0.89       143\n","         1.0       0.89      0.93      0.91       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.90      0.90      0.90       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[124  19]\n"," [ 11 151]]\n","training loss: 0.00019697291177830527; time: 0.7765226364135742s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.91      0.95      0.93       575\n","         1.0       0.95      0.90      0.92       577\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[545  30]\n"," [ 55 522]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 47%|████▋     | 14/30 [00:21<00:24,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003987308041971238; time: 0.6816399097442627s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.79      0.86       143\n","         1.0       0.84      0.96      0.90       162\n","\n","    accuracy                           0.88       305\n","   macro avg       0.89      0.88      0.88       305\n","weighted avg       0.89      0.88      0.88       305\n","\n","[[113  30]\n"," [  6 156]]\n","training loss: 0.00018661273858958373; time: 0.7490098476409912s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.90      0.92       572\n","         1.0       0.91      0.94      0.92       580\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[516  56]\n"," [ 33 547]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 50%|█████     | 15/30 [00:22<00:22,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0036689894365482642; time: 0.6741688251495361s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.84      0.99      0.91       143\n","         1.0       0.99      0.84      0.91       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.91      0.91      0.91       305\n","weighted avg       0.92      0.91      0.91       305\n","\n","[[141   2]\n"," [ 26 136]]\n","training loss: 0.00013996907202656276; time: 0.7673099040985107s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.94      0.94       574\n","         1.0       0.94      0.94      0.94       578\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[540  34]\n"," [ 36 542]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 53%|█████▎    | 16/30 [00:24<00:21,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.006548982431165508; time: 0.6843845844268799s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.62      0.75       143\n","         1.0       0.74      0.98      0.85       162\n","\n","    accuracy                           0.81       305\n","   macro avg       0.86      0.80      0.80       305\n","weighted avg       0.85      0.81      0.80       305\n","\n","[[ 88  55]\n"," [  3 159]]\n","training loss: 0.00016604139419345586; time: 0.7554428577423096s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.92      0.92       567\n","         1.0       0.92      0.92      0.92       585\n","\n","    accuracy                           0.92      1152\n","   macro avg       0.92      0.92      0.92      1152\n","weighted avg       0.92      0.92      0.92      1152\n","\n","[[522  45]\n"," [ 47 538]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 57%|█████▋    | 17/30 [00:25<00:19,  1.52s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0035912910201510444; time: 0.6750311851501465s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.81      0.88       143\n","         1.0       0.85      0.96      0.90       162\n","\n","    accuracy                           0.89       305\n","   macro avg       0.90      0.89      0.89       305\n","weighted avg       0.90      0.89      0.89       305\n","\n","[[116  27]\n"," [  6 156]]\n","training loss: 0.0001271184132129736; time: 0.7559971809387207s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.92      0.93       570\n","         1.0       0.93      0.94      0.93       582\n","\n","    accuracy                           0.93      1152\n","   macro avg       0.93      0.93      0.93      1152\n","weighted avg       0.93      0.93      0.93      1152\n","\n","[[526  44]\n"," [ 33 549]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 60%|██████    | 18/30 [00:27<00:18,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003284229093887767; time: 0.6912915706634521s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.92      0.86      0.89       143\n","         1.0       0.88      0.94      0.91       162\n","\n","    accuracy                           0.90       305\n","   macro avg       0.90      0.90      0.90       305\n","weighted avg       0.90      0.90      0.90       305\n","\n","[[123  20]\n"," [ 10 152]]\n","training loss: 9.675333153848585e-05; time: 0.7546274662017822s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95       567\n","         1.0       0.96      0.94      0.95       585\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[542  25]\n"," [ 36 549]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 63%|██████▎   | 19/30 [00:28<00:16,  1.51s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004796181704665794; time: 0.6882302761077881s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.67      0.79       143\n","         1.0       0.77      0.98      0.86       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.87      0.83      0.83       305\n","weighted avg       0.86      0.84      0.83       305\n","\n","[[ 96  47]\n"," [  3 159]]\n","training loss: 9.759991129006569e-05; time: 0.781897783279419s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.94      0.94       573\n","         1.0       0.94      0.95      0.94       579\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[539  34]\n"," [ 30 549]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 67%|██████▋   | 20/30 [00:30<00:15,  1.54s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.003770901653610292; time: 0.6931331157684326s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.80      0.87       143\n","         1.0       0.85      0.96      0.90       162\n","\n","    accuracy                           0.89       305\n","   macro avg       0.90      0.88      0.89       305\n","weighted avg       0.90      0.89      0.89       305\n","\n","[[115  28]\n"," [  6 156]]\n","training loss: 8.273276573702417e-05; time: 0.7767791748046875s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.96      0.95       571\n","         1.0       0.96      0.95      0.95       581\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[548  23]\n"," [ 30 551]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 70%|███████   | 21/30 [00:31<00:13,  1.54s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0032048963376733125; time: 0.6949915885925293s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.93      0.91       143\n","         1.0       0.94      0.90      0.92       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.91      0.92      0.91       305\n","weighted avg       0.92      0.91      0.91       305\n","\n","[[133  10]\n"," [ 16 146]]\n","training loss: 8.488203559983333e-05; time: 0.7787168025970459s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95       572\n","         1.0       0.95      0.94      0.95       580\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[545  27]\n"," [ 32 548]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 73%|███████▎  | 22/30 [00:33<00:12,  1.54s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0036581744424632337; time: 0.7094824314117432s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.85      0.99      0.92       143\n","         1.0       0.99      0.85      0.91       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.92      0.92      0.91       305\n","weighted avg       0.92      0.91      0.91       305\n","\n","[[141   2]\n"," [ 24 138]]\n","training loss: 7.653754015547642e-05; time: 0.7666471004486084s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95       568\n","         1.0       0.95      0.94      0.95       584\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[542  26]\n"," [ 33 551]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 77%|███████▋  | 23/30 [00:34<00:10,  1.55s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0060224999597326655; time: 0.7012224197387695s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.67      0.80       143\n","         1.0       0.77      0.99      0.87       162\n","\n","    accuracy                           0.84       305\n","   macro avg       0.88      0.83      0.84       305\n","weighted avg       0.88      0.84      0.84       305\n","\n","[[ 96  47]\n"," [  1 161]]\n","training loss: 7.431493402152598e-05; time: 0.7737205028533936s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.95      0.95       572\n","         1.0       0.95      0.94      0.95       580\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[543  29]\n"," [ 33 547]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 80%|████████  | 24/30 [00:36<00:09,  1.55s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0034310420517061576; time: 0.7195286750793457s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.88      0.90       143\n","         1.0       0.90      0.94      0.92       162\n","\n","    accuracy                           0.91       305\n","   macro avg       0.91      0.91      0.91       305\n","weighted avg       0.91      0.91      0.91       305\n","\n","[[126  17]\n"," [ 10 152]]\n","training loss: 7.622361338386934e-05; time: 0.7940750122070312s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94       568\n","         1.0       0.94      0.93      0.94       584\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[536  32]\n"," [ 38 546]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 83%|████████▎ | 25/30 [00:38<00:07,  1.55s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.005109654214294231; time: 0.7007873058319092s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.97      0.70      0.81       143\n","         1.0       0.79      0.98      0.87       162\n","\n","    accuracy                           0.85       305\n","   macro avg       0.88      0.84      0.84       305\n","weighted avg       0.87      0.85      0.85       305\n","\n","[[100  43]\n"," [  3 159]]\n","training loss: 8.509722020890977e-05; time: 0.78900146484375s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.94      0.94       567\n","         1.0       0.95      0.94      0.94       585\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[535  32]\n"," [ 35 550]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 87%|████████▋ | 26/30 [00:39<00:06,  1.56s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0031137992368369806; time: 0.717947244644165s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.89      0.97      0.93       143\n","         1.0       0.97      0.90      0.93       162\n","\n","    accuracy                           0.93       305\n","   macro avg       0.93      0.93      0.93       305\n","weighted avg       0.93      0.93      0.93       305\n","\n","[[138   5]\n"," [ 17 145]]\n","training loss: 8.393416479191601e-05; time: 0.8097784519195557s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.94      0.94       575\n","         1.0       0.94      0.93      0.94       577\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[540  35]\n"," [ 39 538]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 90%|█████████ | 27/30 [00:41<00:04,  1.56s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.004646230892079776; time: 0.7031664848327637s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.72      0.83       143\n","         1.0       0.80      0.99      0.89       162\n","\n","    accuracy                           0.87       305\n","   macro avg       0.90      0.86      0.86       305\n","weighted avg       0.89      0.87      0.86       305\n","\n","[[103  40]\n"," [  1 161]]\n","training loss: 7.362505384085197e-05; time: 0.8281850814819336s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.93      0.94       571\n","         1.0       0.93      0.94      0.94       581\n","\n","    accuracy                           0.94      1152\n","   macro avg       0.94      0.94      0.94      1152\n","weighted avg       0.94      0.94      0.94      1152\n","\n","[[532  39]\n"," [ 32 549]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 93%|█████████▎| 28/30 [00:42<00:03,  1.58s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0029046641510041033; time: 0.7221641540527344s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.93      0.92       143\n","         1.0       0.94      0.91      0.92       162\n","\n","    accuracy                           0.92       305\n","   macro avg       0.92      0.92      0.92       305\n","weighted avg       0.92      0.92      0.92       305\n","\n","[[133  10]\n"," [ 14 148]]\n","training loss: 5.711565252261457e-05; time: 0.7884232997894287s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.94      0.96      0.95       574\n","         1.0       0.96      0.94      0.95       578\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[551  23]\n"," [ 36 542]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"," 97%|█████████▋| 29/30 [00:44<00:01,  1.58s/it]\u001b[A"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.002817165705024219; time: 0.7067050933837891s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.90      0.92      0.91       143\n","         1.0       0.93      0.91      0.92       162\n","\n","    accuracy                           0.92       305\n","   macro avg       0.92      0.92      0.92       305\n","weighted avg       0.92      0.92      0.92       305\n","\n","[[132  11]\n"," [ 14 148]]\n","training loss: 5.667165947940063e-05; time: 0.7872025966644287s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.95      0.95      0.95       571\n","         1.0       0.95      0.95      0.95       581\n","\n","    accuracy                           0.95      1152\n","   macro avg       0.95      0.95      0.95      1152\n","weighted avg       0.95      0.95      0.95      1152\n","\n","[[543  28]\n"," [ 30 551]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n","100%|██████████| 30/30 [00:45<00:00,  1.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["testing loss: 0.0028235229800959104; time: 0.6927411556243896s\n","              precision    recall  f1-score   support\n","\n","         0.0       0.93      0.92      0.93       143\n","         1.0       0.93      0.94      0.94       162\n","\n","    accuracy                           0.93       305\n","   macro avg       0.93      0.93      0.93       305\n","weighted avg       0.93      0.93      0.93       305\n","\n","[[132  11]\n"," [ 10 152]]\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"UmoMuqgewEUo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619910040961,"user_tz":240,"elapsed":350,"user":{"displayName":"Marta Mendez Simon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gg9EqCHVofgov1UnIhH92rSm6vEcl3y0I6ofEhT=s64","userId":"09823525483180080942"}},"outputId":"cb7df7a2-2914-4755-edf2-32f64a584f7b"},"source":["for task_name, error in not_trained:\n","  print(f\"'{task_name}' not trained\")\n","  print(f\"error: {error}\")\n","  print(\"\")"],"execution_count":101,"outputs":[{"output_type":"stream","text":["'1_vowel_vs_consonant' not trained\n","error: class 0 phonemes found (['AE', 'AH', 'AW', 'EE', 'EH', 'IH', 'OO', 'UE', 'UH']) != expected phonemes (['AE', 'AH', 'AW', 'EE', 'EH', 'ER', 'IH', 'OO', 'UE', 'UH'])\n","\n"],"name":"stdout"}]}]}